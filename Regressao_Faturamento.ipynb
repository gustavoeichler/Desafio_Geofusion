{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predição dos valores de faturamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import plotly.express as px\n",
    "\n",
    "def Salva_DB(Caminho,Filename,Arquivo):\n",
    "    open_file = open(f'{Caminho}/{Filename}', \"wb\")\n",
    "    pickle.dump(Arquivo, open_file)\n",
    "    open_file.close()\n",
    "\n",
    "def Abre_DB(Caminho,Filename):\n",
    "    with open(f'{Caminho}/{Filename}','rb') as f:\n",
    "        DB = pickle.load(f)\n",
    "    return DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "out = os.path.basename('C:/Users/guga_/Desafio Geofusion/Dados')\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(Abre_DB(f'{out}/Treino','X_train_faturamento.pkl'))\n",
    "y_train = pd.DataFrame(Abre_DB(f'{out}/Treino','y_train_faturamento.pkl'))\n",
    "X_Test = pd.DataFrame(Abre_DB(f'{out}/Teste','X_test_faturamento.pkl'))\n",
    "y_Test = pd.DataFrame(Abre_DB(f'{out}/Teste','y_test_faturamento.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136, 18)\n",
      "(136, 1)\n",
      "(24, 18)\n",
      "(24, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_Test.shape)\n",
    "print(y_Test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "LR = LinearRegression()\n",
    "LR.fit(X_train, np.array(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse =  8388493375.817291  & mae =  62845.114155561074  & rmse =  91588.71860560826\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "mse = mean_squared_error(y_train, LR.predict(X_train))\n",
    "mae = mean_absolute_error(y_train, LR.predict(X_train))\n",
    "print(\"mse = \",mse,\" & mae = \",mae,\" & rmse = \", sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse =  83451573271.4918  & mae =  129238.72252314421  & rmse =  288879.85958091955\n"
     ]
    }
   ],
   "source": [
    "test_mse = mean_squared_error(y_Test, LR.predict(X_Test))\n",
    "test_mae = mean_absolute_error(y_Test, LR.predict(X_Test))\n",
    "print(\"mse = \",test_mse,\" & mae = \",test_mae,\" & rmse = \", sqrt(test_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 129238.72252314421\n",
      "MSE: 83451573271.4918\n",
      "RMSE: 288879.85958091955\n",
      "VarScore: 0.7875666525438443\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('MAE:', metrics.mean_absolute_error(y_Test.iloc[:,0], LR.predict(X_Test) ))  \n",
    "print('MSE:', metrics.mean_squared_error(y_Test.iloc[:,0], LR.predict(X_Test)))  \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_Test.iloc[:,0], LR.predict(X_Test))))\n",
    "print('VarScore:',metrics.explained_variance_score(y_Test.iloc[:,0],LR.predict(X_Test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = pd.DataFrame(y_Test)\n",
    "teste['previsão_LR'] = LR.predict(X_Test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abordagem com redes neurais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(17, 17), max_iter=10000, random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "model1 = MLPClassifier(max_iter=10000,solver='lbfgs',random_state=1,hidden_layer_sizes=(17,17))\n",
    "model1.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse =  101811089857.875  & mae =  173481.875  & rmse =  319078.50109005306\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "test_mse = mean_squared_error(y_Test.iloc[:,0], model1.predict(X_Test))\n",
    "test_mae = mean_absolute_error(y_Test.iloc[:,0], model1.predict(X_Test))\n",
    "print(\"mse = \",test_mse,\" & mae = \",test_mae,\" & rmse = \", sqrt(test_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 173481.875\n",
      "MSE: 101811089857.875\n",
      "RMSE: 319078.50109005306\n",
      "VarScore: 0.7120332334373064\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('MAE:', metrics.mean_absolute_error(y_Test.iloc[:,0], model1.predict(X_Test) ))  \n",
    "print('MSE:', metrics.mean_squared_error(y_Test.iloc[:,0], model1.predict(X_Test)))  \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_Test.iloc[:,0], model1.predict(X_Test))))\n",
    "print('VarScore:',metrics.explained_variance_score(y_Test.iloc[:,0],model1.predict(X_Test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = pd.DataFrame(y_Test)\n",
    "teste['previsão_NN'] = model1.predict(X_Test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam, SGD,RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136, 18)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(18,input_shape = (18,),activation='relu'))\n",
    "model.add(Dense(36,input_shape = (18,),activation='sigmoid'))\n",
    "model.add(Dense(72,kernel_regularizer='l2'))\n",
    "model.add(Dense(36,input_shape = (18,),activation='sigmoid'))\n",
    "model.add(Dense(18,input_shape = (18,),activation='relu'))\n",
    "model.add(Dense(18,kernel_regularizer='l2'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(1,activation='relu'))\n",
    "model.compile(optimizer='Adam',loss='mse')\n",
    "callback = EarlyStopping(monitor='loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "5/5 [==============================] - 1s 33ms/step - loss: 890315145216.0000 - val_loss: 1427486932992.0000\n",
      "Epoch 2/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 890313637888.0000 - val_loss: 1427485884416.0000\n",
      "Epoch 3/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890312785920.0000 - val_loss: 1427484573696.0000\n",
      "Epoch 4/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 890311671808.0000 - val_loss: 1427483131904.0000\n",
      "Epoch 5/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890310361088.0000 - val_loss: 1427481427968.0000\n",
      "Epoch 6/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890308722688.0000 - val_loss: 1427479461888.0000\n",
      "Epoch 7/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 890307149824.0000 - val_loss: 1427477233664.0000\n",
      "Epoch 8/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 890305118208.0000 - val_loss: 1427474743296.0000\n",
      "Epoch 9/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 890302955520.0000 - val_loss: 1427472252928.0000\n",
      "Epoch 10/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890300792832.0000 - val_loss: 1427469369344.0000\n",
      "Epoch 11/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 890298302464.0000 - val_loss: 1427466354688.0000\n",
      "Epoch 12/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890295812096.0000 - val_loss: 1427463208960.0000\n",
      "Epoch 13/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890293125120.0000 - val_loss: 1427459670016.0000\n",
      "Epoch 14/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890290110464.0000 - val_loss: 1427456000000.0000\n",
      "Epoch 15/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890286964736.0000 - val_loss: 1427452067840.0000\n",
      "Epoch 16/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890283556864.0000 - val_loss: 1427447873536.0000\n",
      "Epoch 17/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890279886848.0000 - val_loss: 1427443417088.0000\n",
      "Epoch 18/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890276085760.0000 - val_loss: 1427438436352.0000\n",
      "Epoch 19/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890271760384.0000 - val_loss: 1427433324544.0000\n",
      "Epoch 20/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 890267435008.0000 - val_loss: 1427427688448.0000\n",
      "Epoch 21/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 890262716416.0000 - val_loss: 1427421921280.0000\n",
      "Epoch 22/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890257604608.0000 - val_loss: 1427415629824.0000\n",
      "Epoch 23/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890252099584.0000 - val_loss: 1427408814080.0000\n",
      "Epoch 24/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 890246397952.0000 - val_loss: 1427401736192.0000\n",
      "Epoch 25/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890240434176.0000 - val_loss: 1427394134016.0000\n",
      "Epoch 26/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890233815040.0000 - val_loss: 1427386269696.0000\n",
      "Epoch 27/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 890226933760.0000 - val_loss: 1427377750016.0000\n",
      "Epoch 28/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 890219724800.0000 - val_loss: 1427368706048.0000\n",
      "Epoch 29/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890212188160.0000 - val_loss: 1427359399936.0000\n",
      "Epoch 30/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 890204192768.0000 - val_loss: 1427349700608.0000\n",
      "Epoch 31/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890195869696.0000 - val_loss: 1427339476992.0000\n",
      "Epoch 32/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890187022336.0000 - val_loss: 1427328335872.0000\n",
      "Epoch 33/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890177585152.0000 - val_loss: 1427316277248.0000\n",
      "Epoch 34/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 890167296000.0000 - val_loss: 1427303825408.0000\n",
      "Epoch 35/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890156482560.0000 - val_loss: 1427290718208.0000\n",
      "Epoch 36/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890145210368.0000 - val_loss: 1427276955648.0000\n",
      "Epoch 37/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890133872640.0000 - val_loss: 1427262275584.0000\n",
      "Epoch 38/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890121093120.0000 - val_loss: 1427247464448.0000\n",
      "Epoch 39/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890108379136.0000 - val_loss: 1427231473664.0000\n",
      "Epoch 40/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890094813184.0000 - val_loss: 1427214827520.0000\n",
      "Epoch 41/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890080657408.0000 - val_loss: 1427197526016.0000\n",
      "Epoch 42/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 890065911808.0000 - val_loss: 1427179044864.0000\n",
      "Epoch 43/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890050117632.0000 - val_loss: 1427160039424.0000\n",
      "Epoch 44/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 890033733632.0000 - val_loss: 1427139854336.0000\n",
      "Epoch 45/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 890016563200.0000 - val_loss: 1427118620672.0000\n",
      "Epoch 46/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 889998606336.0000 - val_loss: 1427096338432.0000\n",
      "Epoch 47/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 889979731968.0000 - val_loss: 1427073531904.0000\n",
      "Epoch 48/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 889960464384.0000 - val_loss: 1427049676800.0000\n",
      "Epoch 49/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 889939623936.0000 - val_loss: 1427024904192.0000\n",
      "Epoch 50/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 889918652416.0000 - val_loss: 1426998820864.0000\n",
      "Epoch 51/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 889896632320.0000 - val_loss: 1426971557888.0000\n",
      "Epoch 52/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 889873432576.0000 - val_loss: 1426943246336.0000\n",
      "Epoch 53/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 889849380864.0000 - val_loss: 1426913624064.0000\n",
      "Epoch 54/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 889824346112.0000 - val_loss: 1426882953216.0000\n",
      "Epoch 55/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 889798459392.0000 - val_loss: 1426851364864.0000\n",
      "Epoch 56/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 889771065344.0000 - val_loss: 1426818859008.0000\n",
      "Epoch 57/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 889743474688.0000 - val_loss: 1426784780288.0000\n",
      "Epoch 58/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 889714769920.0000 - val_loss: 1426749652992.0000\n",
      "Epoch 59/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 889685082112.0000 - val_loss: 1426713477120.0000\n",
      "Epoch 60/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 889654411264.0000 - val_loss: 1426676908032.0000\n",
      "Epoch 61/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 889623674880.0000 - val_loss: 1426638635008.0000\n",
      "Epoch 62/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 889590644736.0000 - val_loss: 1426599837696.0000\n",
      "Epoch 63/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 889558204416.0000 - val_loss: 1426558812160.0000\n",
      "Epoch 64/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 889523208192.0000 - val_loss: 1426516344832.0000\n",
      "Epoch 65/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 889486966784.0000 - val_loss: 1426472828928.0000\n",
      "Epoch 66/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 889450463232.0000 - val_loss: 1426427609088.0000\n",
      "Epoch 67/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 889411796992.0000 - val_loss: 1426381471744.0000\n",
      "Epoch 68/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 889373130752.0000 - val_loss: 1426333499392.0000\n",
      "Epoch 69/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 889332105216.0000 - val_loss: 1426285133824.0000\n",
      "Epoch 70/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 889291014144.0000 - val_loss: 1426234802176.0000\n",
      "Epoch 71/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 889248677888.0000 - val_loss: 1426183028736.0000\n",
      "Epoch 72/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 889205227520.0000 - val_loss: 1426129551360.0000\n",
      "Epoch 73/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 889159417856.0000 - val_loss: 1426075811840.0000\n",
      "Epoch 74/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 889113870336.0000 - val_loss: 1426019581952.0000\n",
      "Epoch 75/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 889065832448.0000 - val_loss: 1425960992768.0000\n",
      "Epoch 76/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 889016549376.0000 - val_loss: 1425901092864.0000\n",
      "Epoch 77/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 888965300224.0000 - val_loss: 1425839620096.0000\n",
      "Epoch 78/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 888914444288.0000 - val_loss: 1425776705536.0000\n",
      "Epoch 79/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 888860573696.0000 - val_loss: 1425713004544.0000\n",
      "Epoch 80/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 888806178816.0000 - val_loss: 1425646419968.0000\n",
      "Epoch 81/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 888750080000.0000 - val_loss: 1425578000384.0000\n",
      "Epoch 82/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 888692211712.0000 - val_loss: 1425508663296.0000\n",
      "Epoch 83/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 888633360384.0000 - val_loss: 1425436966912.0000\n",
      "Epoch 84/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 888573394944.0000 - val_loss: 1425362911232.0000\n",
      "Epoch 85/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 888510808064.0000 - val_loss: 1425287544832.0000\n",
      "Epoch 86/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 888446648320.0000 - val_loss: 1425211260928.0000\n",
      "Epoch 87/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 888382423040.0000 - val_loss: 1425134190592.0000\n",
      "Epoch 88/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 888317345792.0000 - val_loss: 1425054498816.0000\n",
      "Epoch 89/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 888249581568.0000 - val_loss: 1424972709888.0000\n",
      "Epoch 90/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 888179982336.0000 - val_loss: 1424889085952.0000\n",
      "Epoch 91/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 888109596672.0000 - val_loss: 1424804544512.0000\n",
      "Epoch 92/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 888037703680.0000 - val_loss: 1424718168064.0000\n",
      "Epoch 93/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 887965286400.0000 - val_loss: 1424629563392.0000\n",
      "Epoch 94/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 887890706432.0000 - val_loss: 1424537681920.0000\n",
      "Epoch 95/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 887812325376.0000 - val_loss: 1424444489728.0000\n",
      "Epoch 96/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 887734665216.0000 - val_loss: 1424348676096.0000\n",
      "Epoch 97/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 887652155392.0000 - val_loss: 1424252469248.0000\n",
      "Epoch 98/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 887570759680.0000 - val_loss: 1424152461312.0000\n",
      "Epoch 99/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 887486742528.0000 - val_loss: 1424050094080.0000\n",
      "Epoch 100/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 887398662144.0000 - val_loss: 1423945629696.0000\n",
      "Epoch 101/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 887311958016.0000 - val_loss: 1423838806016.0000\n",
      "Epoch 102/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 887221190656.0000 - val_loss: 1423731720192.0000\n",
      "Epoch 103/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 887131734016.0000 - val_loss: 1423622012928.0000\n",
      "Epoch 104/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 887039328256.0000 - val_loss: 1423511126016.0000\n",
      "Epoch 105/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 886945808384.0000 - val_loss: 1423399059456.0000\n",
      "Epoch 106/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 886850060288.0000 - val_loss: 1423283978240.0000\n",
      "Epoch 107/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 886754508800.0000 - val_loss: 1423165620224.0000\n",
      "Epoch 108/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 886653714432.0000 - val_loss: 1423045951488.0000\n",
      "Epoch 109/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 886553182208.0000 - val_loss: 1422922874880.0000\n",
      "Epoch 110/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 886447800320.0000 - val_loss: 1422799011840.0000\n",
      "Epoch 111/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 886344384512.0000 - val_loss: 1422672920576.0000\n",
      "Epoch 112/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 886238281728.0000 - val_loss: 1422546042880.0000\n",
      "Epoch 113/4000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 886131458048.0000 - val_loss: 1422416543744.0000\n",
      "Epoch 114/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 886020964352.0000 - val_loss: 1422284816384.0000\n",
      "Epoch 115/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 885909422080.0000 - val_loss: 1422148370432.0000\n",
      "Epoch 116/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 885793292288.0000 - val_loss: 1422009565184.0000\n",
      "Epoch 117/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 885677424640.0000 - val_loss: 1421867220992.0000\n",
      "Epoch 118/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 885556903936.0000 - val_loss: 1421724221440.0000\n",
      "Epoch 119/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 885435727872.0000 - val_loss: 1421579911168.0000\n",
      "Epoch 120/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 885314027520.0000 - val_loss: 1421432717312.0000\n",
      "Epoch 121/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 885188788224.0000 - val_loss: 1421283426304.0000\n",
      "Epoch 122/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 885064925184.0000 - val_loss: 1421128892416.0000\n",
      "Epoch 123/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 884933853184.0000 - val_loss: 1420975276032.0000\n",
      "Epoch 124/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 884806385664.0000 - val_loss: 1420818513920.0000\n",
      "Epoch 125/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 884673085440.0000 - val_loss: 1420661227520.0000\n",
      "Epoch 126/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 884540375040.0000 - val_loss: 1420498567168.0000\n",
      "Epoch 127/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 884403535872.0000 - val_loss: 1420335120384.0000\n",
      "Epoch 128/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 884266041344.0000 - val_loss: 1420171018240.0000\n",
      "Epoch 129/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 884127367168.0000 - val_loss: 1420002721792.0000\n",
      "Epoch 130/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 883985219584.0000 - val_loss: 1419827085312.0000\n",
      "Epoch 131/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 883836977152.0000 - val_loss: 1419649875968.0000\n",
      "Epoch 132/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 883689127936.0000 - val_loss: 1419472928768.0000\n",
      "Epoch 133/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 883537346560.0000 - val_loss: 1419292835840.0000\n",
      "Epoch 134/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 883383730176.0000 - val_loss: 1419109597184.0000\n",
      "Epoch 135/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 883228606464.0000 - val_loss: 1418918756352.0000\n",
      "Epoch 136/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 883069943808.0000 - val_loss: 1418723196928.0000\n",
      "Epoch 137/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 882905317376.0000 - val_loss: 1418527768576.0000\n",
      "Epoch 138/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 882741477376.0000 - val_loss: 1418329456640.0000\n",
      "Epoch 139/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 882574098432.0000 - val_loss: 1418130096128.0000\n",
      "Epoch 140/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 882406391808.0000 - val_loss: 1417927852032.0000\n",
      "Epoch 141/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 882237243392.0000 - val_loss: 1417724166144.0000\n",
      "Epoch 142/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 882065670144.0000 - val_loss: 1417519431680.0000\n",
      "Epoch 143/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 881890623488.0000 - val_loss: 1417312862208.0000\n",
      "Epoch 144/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 881716953088.0000 - val_loss: 1417100394496.0000\n",
      "Epoch 145/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 881540071424.0000 - val_loss: 1416884649984.0000\n",
      "Epoch 146/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 881360306176.0000 - val_loss: 1416670085120.0000\n",
      "Epoch 147/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 881179623424.0000 - val_loss: 1416452505600.0000\n",
      "Epoch 148/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 880994353152.0000 - val_loss: 1416234926080.0000\n",
      "Epoch 149/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 880810590208.0000 - val_loss: 1416011055104.0000\n",
      "Epoch 150/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 880620797952.0000 - val_loss: 1415785742336.0000\n",
      "Epoch 151/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 880431923200.0000 - val_loss: 1415555579904.0000\n",
      "Epoch 152/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 880237084672.0000 - val_loss: 1415322796032.0000\n",
      "Epoch 153/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 880045064192.0000 - val_loss: 1415087259648.0000\n",
      "Epoch 154/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 879845572608.0000 - val_loss: 1414852378624.0000\n",
      "Epoch 155/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 879645687808.0000 - val_loss: 1414613958656.0000\n",
      "Epoch 156/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 879448162304.0000 - val_loss: 1414370033664.0000\n",
      "Epoch 157/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 879240937472.0000 - val_loss: 1414122700800.0000\n",
      "Epoch 158/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 879033778176.0000 - val_loss: 1413875367936.0000\n",
      "Epoch 159/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 878825504768.0000 - val_loss: 1413625020416.0000\n",
      "Epoch 160/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 878611529728.0000 - val_loss: 1413368512512.0000\n",
      "Epoch 161/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 878399848448.0000 - val_loss: 1413110169600.0000\n",
      "Epoch 162/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 878183448576.0000 - val_loss: 1412854054912.0000\n",
      "Epoch 163/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 877964492800.0000 - val_loss: 1412597547008.0000\n",
      "Epoch 164/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 877749338112.0000 - val_loss: 1412332912640.0000\n",
      "Epoch 165/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 877524615168.0000 - val_loss: 1412065394688.0000\n",
      "Epoch 166/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 877304938496.0000 - val_loss: 1411795386368.0000\n",
      "Epoch 167/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 877073858560.0000 - val_loss: 1411527606272.0000\n",
      "Epoch 168/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 876849922048.0000 - val_loss: 1411253272576.0000\n",
      "Epoch 169/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 876617334784.0000 - val_loss: 1410973827072.0000\n",
      "Epoch 170/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 876382715904.0000 - val_loss: 1410690580480.0000\n",
      "Epoch 171/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 876143378432.0000 - val_loss: 1410404450304.0000\n",
      "Epoch 172/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 875905744896.0000 - val_loss: 1410113863680.0000\n",
      "Epoch 173/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 875662278656.0000 - val_loss: 1409822621696.0000\n",
      "Epoch 174/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 875414421504.0000 - val_loss: 1409530331136.0000\n",
      "Epoch 175/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 875168137216.0000 - val_loss: 1409232142336.0000\n",
      "Epoch 176/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 874917724160.0000 - val_loss: 1408929103872.0000\n",
      "Epoch 177/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 874664427520.0000 - val_loss: 1408623312896.0000\n",
      "Epoch 178/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 874404773888.0000 - val_loss: 1408318439424.0000\n",
      "Epoch 179/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 874152722432.0000 - val_loss: 1408008060928.0000\n",
      "Epoch 180/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 873890381824.0000 - val_loss: 1407695847424.0000\n",
      "Epoch 181/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 873622667264.0000 - val_loss: 1407379439616.0000\n",
      "Epoch 182/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 873358753792.0000 - val_loss: 1407056478208.0000\n",
      "Epoch 183/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 873089204224.0000 - val_loss: 1406733910016.0000\n",
      "Epoch 184/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 872815788032.0000 - val_loss: 1406407016448.0000\n",
      "Epoch 185/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 872541847552.0000 - val_loss: 1406078025728.0000\n",
      "Epoch 186/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 872267841536.0000 - val_loss: 1405746675712.0000\n",
      "Epoch 187/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 871987806208.0000 - val_loss: 1405414539264.0000\n",
      "Epoch 188/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 871709802496.0000 - val_loss: 1405080305664.0000\n",
      "Epoch 189/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 871430422528.0000 - val_loss: 1404738732032.0000\n",
      "Epoch 190/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 871144161280.0000 - val_loss: 1404389949440.0000\n",
      "Epoch 191/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 870842892288.0000 - val_loss: 1404042084352.0000\n",
      "Epoch 192/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 870553550848.0000 - val_loss: 1403685830656.0000\n",
      "Epoch 193/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 870256738304.0000 - val_loss: 1403322368000.0000\n",
      "Epoch 194/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 869949767680.0000 - val_loss: 1402959167488.0000\n",
      "Epoch 195/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 869647056896.0000 - val_loss: 1402594525184.0000\n",
      "Epoch 196/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 869337137152.0000 - val_loss: 1402235387904.0000\n",
      "Epoch 197/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 869036785664.0000 - val_loss: 1401864847360.0000\n",
      "Epoch 198/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 868726145024.0000 - val_loss: 1401489588224.0000\n",
      "Epoch 199/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 868411047936.0000 - val_loss: 1401112494080.0000\n",
      "Epoch 200/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 868091232256.0000 - val_loss: 1400735662080.0000\n",
      "Epoch 201/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 867776921600.0000 - val_loss: 1400353456128.0000\n",
      "Epoch 202/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 867454222336.0000 - val_loss: 1399970463744.0000\n",
      "Epoch 203/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 867132833792.0000 - val_loss: 1399583670272.0000\n",
      "Epoch 204/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 866812559360.0000 - val_loss: 1399188488192.0000\n",
      "Epoch 205/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 866475769856.0000 - val_loss: 1398793043968.0000\n",
      "Epoch 206/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 866141077504.0000 - val_loss: 1398388817920.0000\n",
      "Epoch 207/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 865810644992.0000 - val_loss: 1397981577216.0000\n",
      "Epoch 208/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 865463762944.0000 - val_loss: 1397581938688.0000\n",
      "Epoch 209/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 865131626496.0000 - val_loss: 1397175484416.0000\n",
      "Epoch 210/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 864790904832.0000 - val_loss: 1396767588352.0000\n",
      "Epoch 211/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 864443105280.0000 - val_loss: 1396359954432.0000\n",
      "Epoch 212/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 864107167744.0000 - val_loss: 1395941441536.0000\n",
      "Epoch 213/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 863751241728.0000 - val_loss: 1395530006528.0000\n",
      "Epoch 214/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 863409733632.0000 - val_loss: 1395108741120.0000\n",
      "Epoch 215/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 863047516160.0000 - val_loss: 1394685116416.0000\n",
      "Epoch 216/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 862699061248.0000 - val_loss: 1394250219520.0000\n",
      "Epoch 217/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 862331535360.0000 - val_loss: 1393820565504.0000\n",
      "Epoch 218/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 861971480576.0000 - val_loss: 1393385537536.0000\n",
      "Epoch 219/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 861602119680.0000 - val_loss: 1392942907392.0000\n",
      "Epoch 220/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 861235511296.0000 - val_loss: 1392494379008.0000\n",
      "Epoch 221/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 860858417152.0000 - val_loss: 1392046899200.0000\n",
      "Epoch 222/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 860482830336.0000 - val_loss: 1391592603648.0000\n",
      "Epoch 223/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 860105539584.0000 - val_loss: 1391135948800.0000\n",
      "Epoch 224/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 859723595776.0000 - val_loss: 1390678114304.0000\n",
      "Epoch 225/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 859333459968.0000 - val_loss: 1390220279808.0000\n",
      "Epoch 226/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 858952237056.0000 - val_loss: 1389754974208.0000\n",
      "Epoch 227/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 858562625536.0000 - val_loss: 1389288620032.0000\n",
      "Epoch 228/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 858177601536.0000 - val_loss: 1388820430848.0000\n",
      "Epoch 229/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 857780584448.0000 - val_loss: 1388351979520.0000\n",
      "Epoch 230/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 857385467904.0000 - val_loss: 1387880120320.0000\n",
      "Epoch 231/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 856990547968.0000 - val_loss: 1387400003584.0000\n",
      "Epoch 232/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 856590843904.0000 - val_loss: 1386913857536.0000\n",
      "Epoch 233/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 856176132096.0000 - val_loss: 1386432561152.0000\n",
      "Epoch 234/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 855778066432.0000 - val_loss: 1385934880768.0000\n",
      "Epoch 235/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 855361716224.0000 - val_loss: 1385434054656.0000\n",
      "Epoch 236/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 854939140096.0000 - val_loss: 1384930476032.0000\n",
      "Epoch 237/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 854515580928.0000 - val_loss: 1384426110976.0000\n",
      "Epoch 238/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 854093987840.0000 - val_loss: 1383920697344.0000\n",
      "Epoch 239/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 853670297600.0000 - val_loss: 1383409254400.0000\n",
      "Epoch 240/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 853234941952.0000 - val_loss: 1382900826112.0000\n",
      "Epoch 241/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 852812693504.0000 - val_loss: 1382385582080.0000\n",
      "Epoch 242/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 852383956992.0000 - val_loss: 1381862866944.0000\n",
      "Epoch 243/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 851947159552.0000 - val_loss: 1381337268224.0000\n",
      "Epoch 244/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 851505643520.0000 - val_loss: 1380812587008.0000\n",
      "Epoch 245/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 851066290176.0000 - val_loss: 1380288167936.0000\n",
      "Epoch 246/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 850627985408.0000 - val_loss: 1379762831360.0000\n",
      "Epoch 247/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 850195120128.0000 - val_loss: 1379235135488.0000\n",
      "Epoch 248/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 849751375872.0000 - val_loss: 1378710716416.0000\n",
      "Epoch 249/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 849309990912.0000 - val_loss: 1378181840896.0000\n",
      "Epoch 250/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 848868737024.0000 - val_loss: 1377642348544.0000\n",
      "Epoch 251/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 848410902528.0000 - val_loss: 1377101545472.0000\n",
      "Epoch 252/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 847963422720.0000 - val_loss: 1376546848768.0000\n",
      "Epoch 253/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 847495561216.0000 - val_loss: 1375993724928.0000\n",
      "Epoch 254/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 847034384384.0000 - val_loss: 1375437193216.0000\n",
      "Epoch 255/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 846563311616.0000 - val_loss: 1374877253632.0000\n",
      "Epoch 256/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 846094467072.0000 - val_loss: 1374303813632.0000\n",
      "Epoch 257/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 845610745856.0000 - val_loss: 1373730635776.0000\n",
      "Epoch 258/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 845137117184.0000 - val_loss: 1373153394688.0000\n",
      "Epoch 259/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 844654116864.0000 - val_loss: 1372574842880.0000\n",
      "Epoch 260/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 844166791168.0000 - val_loss: 1371990786048.0000\n",
      "Epoch 261/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 843680055296.0000 - val_loss: 1371395194880.0000\n",
      "Epoch 262/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 843180277760.0000 - val_loss: 1370797113344.0000\n",
      "Epoch 263/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 842687381504.0000 - val_loss: 1370198507520.0000\n",
      "Epoch 264/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 842182688768.0000 - val_loss: 1369606062080.0000\n",
      "Epoch 265/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 841683042304.0000 - val_loss: 1368999985152.0000\n",
      "Epoch 266/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 841173565440.0000 - val_loss: 1368388141056.0000\n",
      "Epoch 267/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 840666185728.0000 - val_loss: 1367773020160.0000\n",
      "Epoch 268/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 840149041152.0000 - val_loss: 1367159472128.0000\n",
      "Epoch 269/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 839626850304.0000 - val_loss: 1366543433728.0000\n",
      "Epoch 270/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 839119863808.0000 - val_loss: 1365919137792.0000\n",
      "Epoch 271/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 838603374592.0000 - val_loss: 1365295890432.0000\n",
      "Epoch 272/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 838078431232.0000 - val_loss: 1364668579840.0000\n",
      "Epoch 273/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 837558140928.0000 - val_loss: 1364036026368.0000\n",
      "Epoch 274/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 837024481280.0000 - val_loss: 1363403472896.0000\n",
      "Epoch 275/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 836496195584.0000 - val_loss: 1362763448320.0000\n",
      "Epoch 276/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 835959062528.0000 - val_loss: 1362126962688.0000\n",
      "Epoch 277/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 835435102208.0000 - val_loss: 1361482219520.0000\n",
      "Epoch 278/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 834890760192.0000 - val_loss: 1360839180288.0000\n",
      "Epoch 279/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 834353692672.0000 - val_loss: 1360201383936.0000\n",
      "Epoch 280/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 833827635200.0000 - val_loss: 1359564111872.0000\n",
      "Epoch 281/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 833293582336.0000 - val_loss: 1358915043328.0000\n",
      "Epoch 282/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 832753172480.0000 - val_loss: 1358259290112.0000\n",
      "Epoch 283/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 832214401024.0000 - val_loss: 1357603930112.0000\n",
      "Epoch 284/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 831655706624.0000 - val_loss: 1356961021952.0000\n",
      "Epoch 285/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 831123357696.0000 - val_loss: 1356303826944.0000\n",
      "Epoch 286/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 830576066560.0000 - val_loss: 1355646894080.0000\n",
      "Epoch 287/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 830027202560.0000 - val_loss: 1354987864064.0000\n",
      "Epoch 288/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 829472833536.0000 - val_loss: 1354317561856.0000\n",
      "Epoch 289/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 828911124480.0000 - val_loss: 1353641492480.0000\n",
      "Epoch 290/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 828342337536.0000 - val_loss: 1352954413056.0000\n",
      "Epoch 291/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 827764506624.0000 - val_loss: 1352263008256.0000\n",
      "Epoch 292/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 827186610176.0000 - val_loss: 1351559282688.0000\n",
      "Epoch 293/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 826602881024.0000 - val_loss: 1350845988864.0000\n",
      "Epoch 294/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 826011156480.0000 - val_loss: 1350134923264.0000\n",
      "Epoch 295/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 825413337088.0000 - val_loss: 1349422022656.0000\n",
      "Epoch 296/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 824823185408.0000 - val_loss: 1348707418112.0000\n",
      "Epoch 297/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 824227463168.0000 - val_loss: 1348000546816.0000\n",
      "Epoch 298/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 823636721664.0000 - val_loss: 1347290005504.0000\n",
      "Epoch 299/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 823034380288.0000 - val_loss: 1346571075584.0000\n",
      "Epoch 300/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 822448357376.0000 - val_loss: 1345841528832.0000\n",
      "Epoch 301/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 821836644352.0000 - val_loss: 1345124171776.0000\n",
      "Epoch 302/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 821240659968.0000 - val_loss: 1344392396800.0000\n",
      "Epoch 303/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 820623245312.0000 - val_loss: 1343679758336.0000\n",
      "Epoch 304/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 820044627968.0000 - val_loss: 1342955454464.0000\n",
      "Epoch 305/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 819438551040.0000 - val_loss: 1342240063488.0000\n",
      "Epoch 306/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 818833195008.0000 - val_loss: 1341518643200.0000\n",
      "Epoch 307/4000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 818228363264.0000 - val_loss: 1340774940672.0000\n",
      "Epoch 308/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 817606623232.0000 - val_loss: 1340025339904.0000\n",
      "Epoch 309/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 816981671936.0000 - val_loss: 1339269971968.0000\n",
      "Epoch 310/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 816369696768.0000 - val_loss: 1338509230080.0000\n",
      "Epoch 311/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 815718793216.0000 - val_loss: 1337760808960.0000\n",
      "Epoch 312/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 815103868928.0000 - val_loss: 1336997838848.0000\n",
      "Epoch 313/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 814465941504.0000 - val_loss: 1336241684480.0000\n",
      "Epoch 314/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 813836861440.0000 - val_loss: 1335479107584.0000\n",
      "Epoch 315/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 813186547712.0000 - val_loss: 1334707093504.0000\n",
      "Epoch 316/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 812550979584.0000 - val_loss: 1333919219712.0000\n",
      "Epoch 317/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 811890900992.0000 - val_loss: 1333130690560.0000\n",
      "Epoch 318/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 811236917248.0000 - val_loss: 1332334821376.0000\n",
      "Epoch 319/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 810573561856.0000 - val_loss: 1331546685440.0000\n",
      "Epoch 320/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 809916497920.0000 - val_loss: 1330752126976.0000\n",
      "Epoch 321/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 809255108608.0000 - val_loss: 1329953636352.0000\n",
      "Epoch 322/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 808594833408.0000 - val_loss: 1329161699328.0000\n",
      "Epoch 323/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 807941439488.0000 - val_loss: 1328373170176.0000\n",
      "Epoch 324/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 807282671616.0000 - val_loss: 1327587131392.0000\n",
      "Epoch 325/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 806617481216.0000 - val_loss: 1326807384064.0000\n",
      "Epoch 326/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 805976932352.0000 - val_loss: 1326005092352.0000\n",
      "Epoch 327/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 805323407360.0000 - val_loss: 1325191790592.0000\n",
      "Epoch 328/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 804633247744.0000 - val_loss: 1324395659264.0000\n",
      "Epoch 329/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 803982278656.0000 - val_loss: 1323591925760.0000\n",
      "Epoch 330/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 803301359616.0000 - val_loss: 1322792255488.0000\n",
      "Epoch 331/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 802630205440.0000 - val_loss: 1321974366208.0000\n",
      "Epoch 332/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 801945419776.0000 - val_loss: 1321140092928.0000\n",
      "Epoch 333/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 801263321088.0000 - val_loss: 1320298872832.0000\n",
      "Epoch 334/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 800562741248.0000 - val_loss: 1319449919488.0000\n",
      "Epoch 335/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 799856721920.0000 - val_loss: 1318596640768.0000\n",
      "Epoch 336/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 799144411136.0000 - val_loss: 1317752406016.0000\n",
      "Epoch 337/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 798449598464.0000 - val_loss: 1316916166656.0000\n",
      "Epoch 338/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 797745938432.0000 - val_loss: 1316075470848.0000\n",
      "Epoch 339/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 797059514368.0000 - val_loss: 1315224289280.0000\n",
      "Epoch 340/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 796343402496.0000 - val_loss: 1314376908800.0000\n",
      "Epoch 341/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 795633516544.0000 - val_loss: 1313532674048.0000\n",
      "Epoch 342/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 794940997632.0000 - val_loss: 1312669302784.0000\n",
      "Epoch 343/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 794214531072.0000 - val_loss: 1311811174400.0000\n",
      "Epoch 344/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 793497829376.0000 - val_loss: 1310941118464.0000\n",
      "Epoch 345/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 792778702848.0000 - val_loss: 1310054023168.0000\n",
      "Epoch 346/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 792049483776.0000 - val_loss: 1309167452160.0000\n",
      "Epoch 347/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 791319412736.0000 - val_loss: 1308287959040.0000\n",
      "Epoch 348/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 790579642368.0000 - val_loss: 1307419738112.0000\n",
      "Epoch 349/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 789856452608.0000 - val_loss: 1306537623552.0000\n",
      "Epoch 350/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 789110980608.0000 - val_loss: 1305653280768.0000\n",
      "Epoch 351/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 788395393024.0000 - val_loss: 1304754520064.0000\n",
      "Epoch 352/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 787649658880.0000 - val_loss: 1303859167232.0000\n",
      "Epoch 353/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 786906677248.0000 - val_loss: 1302964600832.0000\n",
      "Epoch 354/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 786158518272.0000 - val_loss: 1302071214080.0000\n",
      "Epoch 355/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 785415929856.0000 - val_loss: 1301176385536.0000\n",
      "Epoch 356/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 784689725440.0000 - val_loss: 1300268580864.0000\n",
      "Epoch 357/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 783942221824.0000 - val_loss: 1299371130880.0000\n",
      "Epoch 358/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 783183380480.0000 - val_loss: 1298480889856.0000\n",
      "Epoch 359/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 782440333312.0000 - val_loss: 1297575182336.0000\n",
      "Epoch 360/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 781687783424.0000 - val_loss: 1296668688384.0000\n",
      "Epoch 361/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 780943884288.0000 - val_loss: 1295760359424.0000\n",
      "Epoch 362/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 780197101568.0000 - val_loss: 1294854651904.0000\n",
      "Epoch 363/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 779442716672.0000 - val_loss: 1293935312896.0000\n",
      "Epoch 364/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 778662707200.0000 - val_loss: 1293012566016.0000\n",
      "Epoch 365/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 777906946048.0000 - val_loss: 1292067799040.0000\n",
      "Epoch 366/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 777121366016.0000 - val_loss: 1291142168576.0000\n",
      "Epoch 367/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 776347713536.0000 - val_loss: 1290205528064.0000\n",
      "Epoch 368/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 775584612352.0000 - val_loss: 1289262858240.0000\n",
      "Epoch 369/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 774800539648.0000 - val_loss: 1288317829120.0000\n",
      "Epoch 370/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 774008537088.0000 - val_loss: 1287368212480.0000\n",
      "Epoch 371/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 773222629376.0000 - val_loss: 1286422396928.0000\n",
      "Epoch 372/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 772434624512.0000 - val_loss: 1285467013120.0000\n",
      "Epoch 373/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 771641180160.0000 - val_loss: 1284499701760.0000\n",
      "Epoch 374/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 770848784384.0000 - val_loss: 1283526098944.0000\n",
      "Epoch 375/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 770047541248.0000 - val_loss: 1282554331136.0000\n",
      "Epoch 376/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 769240793088.0000 - val_loss: 1281578893312.0000\n",
      "Epoch 377/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 768429326336.0000 - val_loss: 1280593756160.0000\n",
      "Epoch 378/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 767611895808.0000 - val_loss: 1279613468672.0000\n",
      "Epoch 379/4000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 766807113728.0000 - val_loss: 1278627545088.0000\n",
      "Epoch 380/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 765994336256.0000 - val_loss: 1277636771840.0000\n",
      "Epoch 381/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 765183000576.0000 - val_loss: 1276647047168.0000\n",
      "Epoch 382/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 764362752000.0000 - val_loss: 1275667546112.0000\n",
      "Epoch 383/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 763550892032.0000 - val_loss: 1274683588608.0000\n",
      "Epoch 384/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 762735493120.0000 - val_loss: 1273699500032.0000\n",
      "Epoch 385/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 761915703296.0000 - val_loss: 1272706629632.0000\n",
      "Epoch 386/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 761079267328.0000 - val_loss: 1271698685952.0000\n",
      "Epoch 387/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 760252661760.0000 - val_loss: 1270681698304.0000\n",
      "Epoch 388/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 759414063104.0000 - val_loss: 1269669953536.0000\n",
      "Epoch 389/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 758576316416.0000 - val_loss: 1268644839424.0000\n",
      "Epoch 390/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 757732474880.0000 - val_loss: 1267616710656.0000\n",
      "Epoch 391/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 756878802944.0000 - val_loss: 1266595921920.0000\n",
      "Epoch 392/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 756035354624.0000 - val_loss: 1265576706048.0000\n",
      "Epoch 393/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 755193675776.0000 - val_loss: 1264558669824.0000\n",
      "Epoch 394/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 754338234368.0000 - val_loss: 1263532113920.0000\n",
      "Epoch 395/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 753494786048.0000 - val_loss: 1262474493952.0000\n",
      "Epoch 396/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 752632004608.0000 - val_loss: 1261419757568.0000\n",
      "Epoch 397/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 751760048128.0000 - val_loss: 1260374196224.0000\n",
      "Epoch 398/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 750903689216.0000 - val_loss: 1259337809920.0000\n",
      "Epoch 399/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 750050607104.0000 - val_loss: 1258307584000.0000\n",
      "Epoch 400/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 749203619840.0000 - val_loss: 1257277620224.0000\n",
      "Epoch 401/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 748369149952.0000 - val_loss: 1256244510720.0000\n",
      "Epoch 402/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 747498766336.0000 - val_loss: 1255211008000.0000\n",
      "Epoch 403/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 746645487616.0000 - val_loss: 1254171082752.0000\n",
      "Epoch 404/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 745789194240.0000 - val_loss: 1253132337152.0000\n",
      "Epoch 405/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 744934735872.0000 - val_loss: 1252082450432.0000\n",
      "Epoch 406/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 744075886592.0000 - val_loss: 1251020505088.0000\n",
      "Epoch 407/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 743194755072.0000 - val_loss: 1249976647680.0000\n",
      "Epoch 408/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 742331318272.0000 - val_loss: 1248915488768.0000\n",
      "Epoch 409/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 741466570752.0000 - val_loss: 1247827066880.0000\n",
      "Epoch 410/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 740555030528.0000 - val_loss: 1246749655040.0000\n",
      "Epoch 411/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 739666427904.0000 - val_loss: 1245668048896.0000\n",
      "Epoch 412/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 738774810624.0000 - val_loss: 1244587229184.0000\n",
      "Epoch 413/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 737875263488.0000 - val_loss: 1243509948416.0000\n",
      "Epoch 414/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 737000947712.0000 - val_loss: 1242427817984.0000\n",
      "Epoch 415/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 736105332736.0000 - val_loss: 1241359712256.0000\n",
      "Epoch 416/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 735220334592.0000 - val_loss: 1240282824704.0000\n",
      "Epoch 417/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 734347460608.0000 - val_loss: 1239192829952.0000\n",
      "Epoch 418/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 733439393792.0000 - val_loss: 1238097723392.0000\n",
      "Epoch 419/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 732532441088.0000 - val_loss: 1236981645312.0000\n",
      "Epoch 420/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 731608842240.0000 - val_loss: 1235870547968.0000\n",
      "Epoch 421/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 730693894144.0000 - val_loss: 1234753421312.0000\n",
      "Epoch 422/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 729797033984.0000 - val_loss: 1233648222208.0000\n",
      "Epoch 423/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 728873369600.0000 - val_loss: 1232566878208.0000\n",
      "Epoch 424/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 727985225728.0000 - val_loss: 1231459844096.0000\n",
      "Epoch 425/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 727079452672.0000 - val_loss: 1230335508480.0000\n",
      "Epoch 426/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 726149300224.0000 - val_loss: 1229208682496.0000\n",
      "Epoch 427/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 725231337472.0000 - val_loss: 1228085526528.0000\n",
      "Epoch 428/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 724292665344.0000 - val_loss: 1226971283456.0000\n",
      "Epoch 429/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 723385188352.0000 - val_loss: 1225826238464.0000\n",
      "Epoch 430/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 722427510784.0000 - val_loss: 1224679751680.0000\n",
      "Epoch 431/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 721477107712.0000 - val_loss: 1223533920256.0000\n",
      "Epoch 432/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 720544923648.0000 - val_loss: 1222363971584.0000\n",
      "Epoch 433/4000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 719595765760.0000 - val_loss: 1221195857920.0000\n",
      "Epoch 434/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 718640709632.0000 - val_loss: 1220055662592.0000\n",
      "Epoch 435/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 717717569536.0000 - val_loss: 1218904457216.0000\n",
      "Epoch 436/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 716764151808.0000 - val_loss: 1217770815488.0000\n",
      "Epoch 437/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 715821219840.0000 - val_loss: 1216635731968.0000\n",
      "Epoch 438/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 714904633344.0000 - val_loss: 1215478235136.0000\n",
      "Epoch 439/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 713948200960.0000 - val_loss: 1214328209408.0000\n",
      "Epoch 440/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 713019686912.0000 - val_loss: 1213194829824.0000\n",
      "Epoch 441/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 712084684800.0000 - val_loss: 1212063416320.0000\n",
      "Epoch 442/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 711164690432.0000 - val_loss: 1210904346624.0000\n",
      "Epoch 443/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 710191022080.0000 - val_loss: 1209759301632.0000\n",
      "Epoch 444/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 709245534208.0000 - val_loss: 1208599838720.0000\n",
      "Epoch 445/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 708318527488.0000 - val_loss: 1207431069696.0000\n",
      "Epoch 446/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 707341516800.0000 - val_loss: 1206264659968.0000\n",
      "Epoch 447/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 706389344256.0000 - val_loss: 1205092745216.0000\n",
      "Epoch 448/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 705422950400.0000 - val_loss: 1203917160448.0000\n",
      "Epoch 449/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 704456949760.0000 - val_loss: 1202735546368.0000\n",
      "Epoch 450/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 703507070976.0000 - val_loss: 1201557602304.0000\n",
      "Epoch 451/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 702548475904.0000 - val_loss: 1200388440064.0000\n",
      "Epoch 452/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 701592764416.0000 - val_loss: 1199238938624.0000\n",
      "Epoch 453/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 700644327424.0000 - val_loss: 1198086291456.0000\n",
      "Epoch 454/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 699710439424.0000 - val_loss: 1196920668160.0000\n",
      "Epoch 455/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 698760298496.0000 - val_loss: 1195749277696.0000\n",
      "Epoch 456/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 697780076544.0000 - val_loss: 1194579066880.0000\n",
      "Epoch 457/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 696824168448.0000 - val_loss: 1193388933120.0000\n",
      "Epoch 458/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 695854301184.0000 - val_loss: 1192169046016.0000\n",
      "Epoch 459/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 694857170944.0000 - val_loss: 1190955450368.0000\n",
      "Epoch 460/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 693837496320.0000 - val_loss: 1189741461504.0000\n",
      "Epoch 461/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 692849934336.0000 - val_loss: 1188499685376.0000\n",
      "Epoch 462/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 691828555776.0000 - val_loss: 1187272065024.0000\n",
      "Epoch 463/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 690843090944.0000 - val_loss: 1186051260416.0000\n",
      "Epoch 464/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 689846878208.0000 - val_loss: 1184842252288.0000\n",
      "Epoch 465/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 688861806592.0000 - val_loss: 1183632195584.0000\n",
      "Epoch 466/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 687870246912.0000 - val_loss: 1182417682432.0000\n",
      "Epoch 467/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 686866038784.0000 - val_loss: 1181216145408.0000\n",
      "Epoch 468/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 685880836096.0000 - val_loss: 1179993112576.0000\n",
      "Epoch 469/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 684890521600.0000 - val_loss: 1178761297920.0000\n",
      "Epoch 470/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 683898568704.0000 - val_loss: 1177514934272.0000\n",
      "Epoch 471/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 682876272640.0000 - val_loss: 1176271716352.0000\n",
      "Epoch 472/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 681863610368.0000 - val_loss: 1175021420544.0000\n",
      "Epoch 473/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 680852389888.0000 - val_loss: 1173794848768.0000\n",
      "Epoch 474/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 679834877952.0000 - val_loss: 1172559233024.0000\n",
      "Epoch 475/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 678836633600.0000 - val_loss: 1171294519296.0000\n",
      "Epoch 476/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 677776654336.0000 - val_loss: 1170032427008.0000\n",
      "Epoch 477/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 676749901824.0000 - val_loss: 1168756703232.0000\n",
      "Epoch 478/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 675722100736.0000 - val_loss: 1167459745792.0000\n",
      "Epoch 479/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 674663170048.0000 - val_loss: 1166173798400.0000\n",
      "Epoch 480/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 673607057408.0000 - val_loss: 1164894535680.0000\n",
      "Epoch 481/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 672576831488.0000 - val_loss: 1163619598336.0000\n",
      "Epoch 482/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 671539003392.0000 - val_loss: 1162371661824.0000\n",
      "Epoch 483/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 670517559296.0000 - val_loss: 1161120841728.0000\n",
      "Epoch 484/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 669517414400.0000 - val_loss: 1159849705472.0000\n",
      "Epoch 485/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 668462678016.0000 - val_loss: 1158580666368.0000\n",
      "Epoch 486/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 667429830656.0000 - val_loss: 1157315035136.0000\n",
      "Epoch 487/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 666403078144.0000 - val_loss: 1156029218816.0000\n",
      "Epoch 488/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 665342246912.0000 - val_loss: 1154740781056.0000\n",
      "Epoch 489/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 664296751104.0000 - val_loss: 1153438711808.0000\n",
      "Epoch 490/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 663250927616.0000 - val_loss: 1152132972544.0000\n",
      "Epoch 491/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 662194880512.0000 - val_loss: 1150828806144.0000\n",
      "Epoch 492/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 661122252800.0000 - val_loss: 1149503668224.0000\n",
      "Epoch 493/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 660024459264.0000 - val_loss: 1148197666816.0000\n",
      "Epoch 494/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 658997182464.0000 - val_loss: 1146890354688.0000\n",
      "Epoch 495/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 657936809984.0000 - val_loss: 1145604800512.0000\n",
      "Epoch 496/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 656876175360.0000 - val_loss: 1144318984192.0000\n",
      "Epoch 497/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 655837298688.0000 - val_loss: 1143010361344.0000\n",
      "Epoch 498/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 654779875328.0000 - val_loss: 1141708554240.0000\n",
      "Epoch 499/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 653728415744.0000 - val_loss: 1140417757184.0000\n",
      "Epoch 500/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 652677939200.0000 - val_loss: 1139128532992.0000\n",
      "Epoch 501/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 651643584512.0000 - val_loss: 1137839177728.0000\n",
      "Epoch 502/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 650581377024.0000 - val_loss: 1136577609728.0000\n",
      "Epoch 503/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 649561112576.0000 - val_loss: 1135290220544.0000\n",
      "Epoch 504/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 648517910528.0000 - val_loss: 1133998112768.0000\n",
      "Epoch 505/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 647467499520.0000 - val_loss: 1132697092096.0000\n",
      "Epoch 506/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 646411255808.0000 - val_loss: 1131393449984.0000\n",
      "Epoch 507/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 645354553344.0000 - val_loss: 1130103963648.0000\n",
      "Epoch 508/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 644304535552.0000 - val_loss: 1128797437952.0000\n",
      "Epoch 509/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 643259432960.0000 - val_loss: 1127471906816.0000\n",
      "Epoch 510/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 642172190720.0000 - val_loss: 1126155026432.0000\n",
      "Epoch 511/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 641144979456.0000 - val_loss: 1124838277120.0000\n",
      "Epoch 512/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 640063176704.0000 - val_loss: 1123561504768.0000\n",
      "Epoch 513/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 639016828928.0000 - val_loss: 1122283683840.0000\n",
      "Epoch 514/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 637967138816.0000 - val_loss: 1120987512832.0000\n",
      "Epoch 515/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 636915482624.0000 - val_loss: 1119633801216.0000\n",
      "Epoch 516/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 635820965888.0000 - val_loss: 1118284414976.0000\n",
      "Epoch 517/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 634722385920.0000 - val_loss: 1116920610816.0000\n",
      "Epoch 518/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 633631670272.0000 - val_loss: 1115570700288.0000\n",
      "Epoch 519/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 632548687872.0000 - val_loss: 1114231668736.0000\n",
      "Epoch 520/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 631454498816.0000 - val_loss: 1112908759040.0000\n",
      "Epoch 521/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 630398517248.0000 - val_loss: 1111591092224.0000\n",
      "Epoch 522/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 629330345984.0000 - val_loss: 1110252716032.0000\n",
      "Epoch 523/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 628247560192.0000 - val_loss: 1108900708352.0000\n",
      "Epoch 524/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 627143606272.0000 - val_loss: 1107553288192.0000\n",
      "Epoch 525/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 626050793472.0000 - val_loss: 1106176770048.0000\n",
      "Epoch 526/4000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 624927571968.0000 - val_loss: 1104801300480.0000\n",
      "Epoch 527/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 623840067584.0000 - val_loss: 1103411937280.0000\n",
      "Epoch 528/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 622743191552.0000 - val_loss: 1102036992000.0000\n",
      "Epoch 529/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 621635174400.0000 - val_loss: 1100700581888.0000\n",
      "Epoch 530/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 620553961472.0000 - val_loss: 1099384684544.0000\n",
      "Epoch 531/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 619497586688.0000 - val_loss: 1098051223552.0000\n",
      "Epoch 532/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 618409033728.0000 - val_loss: 1096708259840.0000\n",
      "Epoch 533/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 617330311168.0000 - val_loss: 1095355793408.0000\n",
      "Epoch 534/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 616221507584.0000 - val_loss: 1094014795776.0000\n",
      "Epoch 535/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 615162249216.0000 - val_loss: 1092664426496.0000\n",
      "Epoch 536/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 614084378624.0000 - val_loss: 1091318775808.0000\n",
      "Epoch 537/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 612964106240.0000 - val_loss: 1089994686464.0000\n",
      "Epoch 538/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 611892592640.0000 - val_loss: 1088641826816.0000\n",
      "Epoch 539/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 610804367360.0000 - val_loss: 1087229460480.0000\n",
      "Epoch 540/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 609668431872.0000 - val_loss: 1085826859008.0000\n",
      "Epoch 541/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 608542982144.0000 - val_loss: 1084411412480.0000\n",
      "Epoch 542/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 607415631872.0000 - val_loss: 1083007369216.0000\n",
      "Epoch 543/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 606295490560.0000 - val_loss: 1081630064640.0000\n",
      "Epoch 544/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 605199400960.0000 - val_loss: 1080260100096.0000\n",
      "Epoch 545/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 604079849472.0000 - val_loss: 1078904487936.0000\n",
      "Epoch 546/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 603026096128.0000 - val_loss: 1077545533440.0000\n",
      "Epoch 547/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 601917030400.0000 - val_loss: 1076214169600.0000\n",
      "Epoch 548/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 600844140544.0000 - val_loss: 1074866421760.0000\n",
      "Epoch 549/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 599762731008.0000 - val_loss: 1073458249728.0000\n",
      "Epoch 550/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 598615785472.0000 - val_loss: 1072064102400.0000\n",
      "Epoch 551/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 597503508480.0000 - val_loss: 1070668972032.0000\n",
      "Epoch 552/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 596387823616.0000 - val_loss: 1069275873280.0000\n",
      "Epoch 553/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 595264274432.0000 - val_loss: 1067886510080.0000\n",
      "Epoch 554/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 594145378304.0000 - val_loss: 1066474143744.0000\n",
      "Epoch 555/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 593034018816.0000 - val_loss: 1065070166016.0000\n",
      "Epoch 556/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 591905882112.0000 - val_loss: 1063671562240.0000\n",
      "Epoch 557/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 590796095488.0000 - val_loss: 1062283771904.0000\n",
      "Epoch 558/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 589668024320.0000 - val_loss: 1060907778048.0000\n",
      "Epoch 559/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 588566364160.0000 - val_loss: 1059522412544.0000\n",
      "Epoch 560/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 587459985408.0000 - val_loss: 1058114306048.0000\n",
      "Epoch 561/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 586330734592.0000 - val_loss: 1056733593600.0000\n",
      "Epoch 562/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 585241329664.0000 - val_loss: 1055362449408.0000\n",
      "Epoch 563/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 584141438976.0000 - val_loss: 1053990518784.0000\n",
      "Epoch 564/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 583019528192.0000 - val_loss: 1052609085440.0000\n",
      "Epoch 565/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 581926322176.0000 - val_loss: 1051195539456.0000\n",
      "Epoch 566/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 580780228608.0000 - val_loss: 1049820921856.0000\n",
      "Epoch 567/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 579672735744.0000 - val_loss: 1048431099904.0000\n",
      "Epoch 568/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 578588246016.0000 - val_loss: 1047017226240.0000\n",
      "Epoch 569/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 577441431552.0000 - val_loss: 1045616132096.0000\n",
      "Epoch 570/4000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 576338657280.0000 - val_loss: 1044185153536.0000\n",
      "Epoch 571/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 575187910656.0000 - val_loss: 1042766561280.0000\n",
      "Epoch 572/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 574059315200.0000 - val_loss: 1041337876480.0000\n",
      "Epoch 573/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 572909879296.0000 - val_loss: 1039913517056.0000\n",
      "Epoch 574/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 571767848960.0000 - val_loss: 1038462222336.0000\n",
      "Epoch 575/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 570624638976.0000 - val_loss: 1037008633856.0000\n",
      "Epoch 576/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 569467994112.0000 - val_loss: 1035565989888.0000\n",
      "Epoch 577/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 568319410176.0000 - val_loss: 1034118758400.0000\n",
      "Epoch 578/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 567158571008.0000 - val_loss: 1032681881600.0000\n",
      "Epoch 579/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 566003564544.0000 - val_loss: 1031240155136.0000\n",
      "Epoch 580/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 564874641408.0000 - val_loss: 1029804326912.0000\n",
      "Epoch 581/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 563734970368.0000 - val_loss: 1028388618240.0000\n",
      "Epoch 582/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 562593726464.0000 - val_loss: 1026960326656.0000\n",
      "Epoch 583/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 561444814848.0000 - val_loss: 1025510473728.0000\n",
      "Epoch 584/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 560318382080.0000 - val_loss: 1024068354048.0000\n",
      "Epoch 585/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 559181398016.0000 - val_loss: 1022644191232.0000\n",
      "Epoch 586/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 558034649088.0000 - val_loss: 1021204299776.0000\n",
      "Epoch 587/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 556890849280.0000 - val_loss: 1019779678208.0000\n",
      "Epoch 588/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 555772411904.0000 - val_loss: 1018359447552.0000\n",
      "Epoch 589/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 554625990656.0000 - val_loss: 1016951275520.0000\n",
      "Epoch 590/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 553539731456.0000 - val_loss: 1015509483520.0000\n",
      "Epoch 591/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 552395800576.0000 - val_loss: 1014091677696.0000\n",
      "Epoch 592/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 551281491968.0000 - val_loss: 1012705787904.0000\n",
      "Epoch 593/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 550173081600.0000 - val_loss: 1011314130944.0000\n",
      "Epoch 594/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 549068701696.0000 - val_loss: 1009918869504.0000\n",
      "Epoch 595/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 547937878016.0000 - val_loss: 1008548380672.0000\n",
      "Epoch 596/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 546883764224.0000 - val_loss: 1007112355840.0000\n",
      "Epoch 597/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 545739767808.0000 - val_loss: 1005717618688.0000\n",
      "Epoch 598/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 544631488512.0000 - val_loss: 1004318228480.0000\n",
      "Epoch 599/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 543502303232.0000 - val_loss: 1002928865280.0000\n",
      "Epoch 600/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 542397104128.0000 - val_loss: 1001522659328.0000\n",
      "Epoch 601/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 541304029184.0000 - val_loss: 1000086503424.0000\n",
      "Epoch 602/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 540134506496.0000 - val_loss: 998652051456.0000\n",
      "Epoch 603/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 539025604608.0000 - val_loss: 997169364992.0000\n",
      "Epoch 604/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 537822101504.0000 - val_loss: 995706798080.0000\n",
      "Epoch 605/4000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 536664211456.0000 - val_loss: 994221948928.0000\n",
      "Epoch 606/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 535539089408.0000 - val_loss: 992763510784.0000\n",
      "Epoch 607/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 534349086720.0000 - val_loss: 991321653248.0000\n",
      "Epoch 608/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 533206073344.0000 - val_loss: 989837197312.0000\n",
      "Epoch 609/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 532058701824.0000 - val_loss: 988364865536.0000\n",
      "Epoch 610/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 530909331456.0000 - val_loss: 986905903104.0000\n",
      "Epoch 611/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 529760452608.0000 - val_loss: 985477087232.0000\n",
      "Epoch 612/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 528639393792.0000 - val_loss: 984058888192.0000\n",
      "Epoch 613/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 527526133760.0000 - val_loss: 982636625920.0000\n",
      "Epoch 614/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 526383611904.0000 - val_loss: 981217050624.0000\n",
      "Epoch 615/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 525281067008.0000 - val_loss: 979758678016.0000\n",
      "Epoch 616/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 524102467584.0000 - val_loss: 978318262272.0000\n",
      "Epoch 617/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 522995466240.0000 - val_loss: 976881188864.0000\n",
      "Epoch 618/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 521840918528.0000 - val_loss: 975454535680.0000\n",
      "Epoch 619/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 520717598720.0000 - val_loss: 973993148416.0000\n",
      "Epoch 620/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 519597916160.0000 - val_loss: 972492308480.0000\n",
      "Epoch 621/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 518412566528.0000 - val_loss: 971022073856.0000\n",
      "Epoch 622/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 517240717312.0000 - val_loss: 969555771392.0000\n",
      "Epoch 623/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 516106616832.0000 - val_loss: 968088354816.0000\n",
      "Epoch 624/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 514953117696.0000 - val_loss: 966645317632.0000\n",
      "Epoch 625/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 513825177600.0000 - val_loss: 965201100800.0000\n",
      "Epoch 626/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 512686030848.0000 - val_loss: 963746725888.0000\n",
      "Epoch 627/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 511556222976.0000 - val_loss: 962288484352.0000\n",
      "Epoch 628/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 510385029120.0000 - val_loss: 960855277568.0000\n",
      "Epoch 629/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 509283237888.0000 - val_loss: 959399002112.0000\n",
      "Epoch 630/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 508135079936.0000 - val_loss: 957953343488.0000\n",
      "Epoch 631/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 506993770496.0000 - val_loss: 956528263168.0000\n",
      "Epoch 632/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 505908494336.0000 - val_loss: 955073495040.0000\n",
      "Epoch 633/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 504753782784.0000 - val_loss: 953619644416.0000\n",
      "Epoch 634/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 503608737792.0000 - val_loss: 952163434496.0000\n",
      "Epoch 635/4000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 502470475776.0000 - val_loss: 950728130560.0000\n",
      "Epoch 636/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 501356462080.0000 - val_loss: 949268578304.0000\n",
      "Epoch 637/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 500235960320.0000 - val_loss: 947808174080.0000\n",
      "Epoch 638/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 499068370944.0000 - val_loss: 946358976512.0000\n",
      "Epoch 639/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 497918640128.0000 - val_loss: 944920920064.0000\n",
      "Epoch 640/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 496844668928.0000 - val_loss: 943455469568.0000\n",
      "Epoch 641/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 495702867968.0000 - val_loss: 941996834816.0000\n",
      "Epoch 642/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 494526038016.0000 - val_loss: 940571033600.0000\n",
      "Epoch 643/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 493447413760.0000 - val_loss: 939109711872.0000\n",
      "Epoch 644/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 492287492096.0000 - val_loss: 937684041728.0000\n",
      "Epoch 645/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 491143266304.0000 - val_loss: 936247623680.0000\n",
      "Epoch 646/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 490053894144.0000 - val_loss: 934754189312.0000\n",
      "Epoch 647/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 488888958976.0000 - val_loss: 933233164288.0000\n",
      "Epoch 648/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 487688601600.0000 - val_loss: 931762995200.0000\n",
      "Epoch 649/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 486550503424.0000 - val_loss: 930301673472.0000\n",
      "Epoch 650/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 485434327040.0000 - val_loss: 928846708736.0000\n",
      "Epoch 651/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 484290396160.0000 - val_loss: 927405703168.0000\n",
      "Epoch 652/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 483180773376.0000 - val_loss: 925935665152.0000\n",
      "Epoch 653/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 482046935040.0000 - val_loss: 924465692672.0000\n",
      "Epoch 654/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 480911818752.0000 - val_loss: 923029471232.0000\n",
      "Epoch 655/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 479769919488.0000 - val_loss: 921585909760.0000\n",
      "Epoch 656/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 478638505984.0000 - val_loss: 920112332800.0000\n",
      "Epoch 657/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 477508075520.0000 - val_loss: 918631481344.0000\n",
      "Epoch 658/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 476366012416.0000 - val_loss: 917159084032.0000\n",
      "Epoch 659/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 475225718784.0000 - val_loss: 915716702208.0000\n",
      "Epoch 660/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 474100662272.0000 - val_loss: 914250072064.0000\n",
      "Epoch 661/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 472978325504.0000 - val_loss: 912789405696.0000\n",
      "Epoch 662/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 471882498048.0000 - val_loss: 911329263616.0000\n",
      "Epoch 663/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 470711140352.0000 - val_loss: 909898481664.0000\n",
      "Epoch 664/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 469637890048.0000 - val_loss: 908472614912.0000\n",
      "Epoch 665/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 468511653888.0000 - val_loss: 907069947904.0000\n",
      "Epoch 666/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 467435257856.0000 - val_loss: 905651748864.0000\n",
      "Epoch 667/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 466326519808.0000 - val_loss: 904216444928.0000\n",
      "Epoch 668/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 465196810240.0000 - val_loss: 902783238144.0000\n",
      "Epoch 669/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 464113631232.0000 - val_loss: 901354553344.0000\n",
      "Epoch 670/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 462993948672.0000 - val_loss: 899929538560.0000\n",
      "Epoch 671/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 461897924608.0000 - val_loss: 898487353344.0000\n",
      "Epoch 672/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 460793544704.0000 - val_loss: 897019019264.0000\n",
      "Epoch 673/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 459665670144.0000 - val_loss: 895550160896.0000\n",
      "Epoch 674/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 458522361856.0000 - val_loss: 894097620992.0000\n",
      "Epoch 675/4000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 457404055552.0000 - val_loss: 892608380928.0000\n",
      "Epoch 676/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 456274477056.0000 - val_loss: 891139850240.0000\n",
      "Epoch 677/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 455115276288.0000 - val_loss: 889699958784.0000\n",
      "Epoch 678/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 454017253376.0000 - val_loss: 888191582208.0000\n",
      "Epoch 679/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 452871061504.0000 - val_loss: 886705225728.0000\n",
      "Epoch 680/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 451724836864.0000 - val_loss: 885253996544.0000\n",
      "Epoch 681/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 450629206016.0000 - val_loss: 883793920000.0000\n",
      "Epoch 682/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 449505656832.0000 - val_loss: 882353635328.0000\n",
      "Epoch 683/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 448421101568.0000 - val_loss: 880938909696.0000\n",
      "Epoch 684/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 447308234752.0000 - val_loss: 879522480128.0000\n",
      "Epoch 685/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 446218993664.0000 - val_loss: 878077345792.0000\n",
      "Epoch 686/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 445087350784.0000 - val_loss: 876629131264.0000\n",
      "Epoch 687/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 443985297408.0000 - val_loss: 875152539648.0000\n",
      "Epoch 688/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 442881802240.0000 - val_loss: 873735651328.0000\n",
      "Epoch 689/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 441800818688.0000 - val_loss: 872350220288.0000\n",
      "Epoch 690/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 440749195264.0000 - val_loss: 870934183936.0000\n",
      "Epoch 691/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 439636295680.0000 - val_loss: 869523783680.0000\n",
      "Epoch 692/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 438600728576.0000 - val_loss: 868083040256.0000\n",
      "Epoch 693/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 437506342912.0000 - val_loss: 866681094144.0000\n",
      "Epoch 694/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 436439449600.0000 - val_loss: 865290682368.0000\n",
      "Epoch 695/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 435381469184.0000 - val_loss: 863877726208.0000\n",
      "Epoch 696/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 434276368384.0000 - val_loss: 862480171008.0000\n",
      "Epoch 697/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 433215504384.0000 - val_loss: 861033988096.0000\n",
      "Epoch 698/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 432116498432.0000 - val_loss: 859621228544.0000\n",
      "Epoch 699/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 431030173696.0000 - val_loss: 858213908480.0000\n",
      "Epoch 700/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 429977534464.0000 - val_loss: 856787058688.0000\n",
      "Epoch 701/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 428878397440.0000 - val_loss: 855383539712.0000\n",
      "Epoch 702/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 427788894208.0000 - val_loss: 853944303616.0000\n",
      "Epoch 703/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 426680221696.0000 - val_loss: 852486717440.0000\n",
      "Epoch 704/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 425585573888.0000 - val_loss: 851032473600.0000\n",
      "Epoch 705/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 424494170112.0000 - val_loss: 849589108736.0000\n",
      "Epoch 706/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 423403061248.0000 - val_loss: 848167501824.0000\n",
      "Epoch 707/4000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 422351241216.0000 - val_loss: 846755332096.0000\n",
      "Epoch 708/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 421299224576.0000 - val_loss: 845347094528.0000\n",
      "Epoch 709/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 420202905600.0000 - val_loss: 843950391296.0000\n",
      "Epoch 710/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 419144171520.0000 - val_loss: 842526425088.0000\n",
      "Epoch 711/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 418074034176.0000 - val_loss: 841112289280.0000\n",
      "Epoch 712/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 416997277696.0000 - val_loss: 839727382528.0000\n",
      "Epoch 713/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 415956008960.0000 - val_loss: 838315540480.0000\n",
      "Epoch 714/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 414880464896.0000 - val_loss: 836924538880.0000\n",
      "Epoch 715/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 413829595136.0000 - val_loss: 835540156416.0000\n",
      "Epoch 716/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 412786491392.0000 - val_loss: 834167177216.0000\n",
      "Epoch 717/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 411721072640.0000 - val_loss: 832790528000.0000\n",
      "Epoch 718/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 410722992128.0000 - val_loss: 831339102208.0000\n",
      "Epoch 719/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 409618251776.0000 - val_loss: 829919789056.0000\n",
      "Epoch 720/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 408554405888.0000 - val_loss: 828528459776.0000\n",
      "Epoch 721/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 407482040320.0000 - val_loss: 827131101184.0000\n",
      "Epoch 722/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 406449324032.0000 - val_loss: 825730596864.0000\n",
      "Epoch 723/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 405392097280.0000 - val_loss: 824355520512.0000\n",
      "Epoch 724/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 404386676736.0000 - val_loss: 822945316864.0000\n",
      "Epoch 725/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 403295535104.0000 - val_loss: 821537079296.0000\n",
      "Epoch 726/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 402246991872.0000 - val_loss: 820120584192.0000\n",
      "Epoch 727/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 401201627136.0000 - val_loss: 818720735232.0000\n",
      "Epoch 728/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 400135749632.0000 - val_loss: 817343823872.0000\n",
      "Epoch 729/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 399087370240.0000 - val_loss: 815957475328.0000\n",
      "Epoch 730/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 398041612288.0000 - val_loss: 814555660288.0000\n",
      "Epoch 731/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 396987465728.0000 - val_loss: 813162758144.0000\n",
      "Epoch 732/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 395958812672.0000 - val_loss: 811742461952.0000\n",
      "Epoch 733/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 394865967104.0000 - val_loss: 810295689216.0000\n",
      "Epoch 734/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 393795928064.0000 - val_loss: 808881750016.0000\n",
      "Epoch 735/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 392772878336.0000 - val_loss: 807483736064.0000\n",
      "Epoch 736/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 391738261504.0000 - val_loss: 806116917248.0000\n",
      "Epoch 737/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 390705217536.0000 - val_loss: 804745969664.0000\n",
      "Epoch 738/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 389668110336.0000 - val_loss: 803354443776.0000\n",
      "Epoch 739/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 388620222464.0000 - val_loss: 801959641088.0000\n",
      "Epoch 740/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 387583967232.0000 - val_loss: 800557891584.0000\n",
      "Epoch 741/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 386546466816.0000 - val_loss: 799186157568.0000\n",
      "Epoch 742/4000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 385560444928.0000 - val_loss: 797819535360.0000\n",
      "Epoch 743/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 384532774912.0000 - val_loss: 796485025792.0000\n",
      "Epoch 744/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 383536463872.0000 - val_loss: 795125022720.0000\n",
      "Epoch 745/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 382515904512.0000 - val_loss: 793778520064.0000\n",
      "Epoch 746/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 381503176704.0000 - val_loss: 792421269504.0000\n",
      "Epoch 747/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 380498083840.0000 - val_loss: 791044489216.0000\n",
      "Epoch 748/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 379479130112.0000 - val_loss: 789647785984.0000\n",
      "Epoch 749/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 378442055680.0000 - val_loss: 788256784384.0000\n",
      "Epoch 750/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 377414090752.0000 - val_loss: 786862112768.0000\n",
      "Epoch 751/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 376385896448.0000 - val_loss: 785477271552.0000\n",
      "Epoch 752/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 375342432256.0000 - val_loss: 784091774976.0000\n",
      "Epoch 753/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 374340419584.0000 - val_loss: 782653784064.0000\n",
      "Epoch 754/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 373249277952.0000 - val_loss: 781234405376.0000\n",
      "Epoch 755/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 372198998016.0000 - val_loss: 779831803904.0000\n",
      "Epoch 756/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 371216187392.0000 - val_loss: 778457317376.0000\n",
      "Epoch 757/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 370163580928.0000 - val_loss: 777101574144.0000\n",
      "Epoch 758/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 369158651904.0000 - val_loss: 775731609600.0000\n",
      "Epoch 759/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 368179314688.0000 - val_loss: 774362365952.0000\n",
      "Epoch 760/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 367167078400.0000 - val_loss: 773002362880.0000\n",
      "Epoch 761/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 366164639744.0000 - val_loss: 771647930368.0000\n",
      "Epoch 762/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 365157318656.0000 - val_loss: 770282291200.0000\n",
      "Epoch 763/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 364169068544.0000 - val_loss: 768877592576.0000\n",
      "Epoch 764/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 363140612096.0000 - val_loss: 767508676608.0000\n",
      "Epoch 765/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 362089316352.0000 - val_loss: 766160207872.0000\n",
      "Epoch 766/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 361109880832.0000 - val_loss: 764785721344.0000\n",
      "Epoch 767/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 360124219392.0000 - val_loss: 763426308096.0000\n",
      "Epoch 768/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 359150845952.0000 - val_loss: 762094878720.0000\n",
      "Epoch 769/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 358168559616.0000 - val_loss: 760777015296.0000\n",
      "Epoch 770/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 357196726272.0000 - val_loss: 759448272896.0000\n",
      "Epoch 771/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 356217159680.0000 - val_loss: 758124904448.0000\n",
      "Epoch 772/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 355309879296.0000 - val_loss: 756804747264.0000\n",
      "Epoch 773/4000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 354315927552.0000 - val_loss: 755540426752.0000\n",
      "Epoch 774/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 353377058816.0000 - val_loss: 754270601216.0000\n",
      "Epoch 775/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 352464240640.0000 - val_loss: 752954114048.0000\n",
      "Epoch 776/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 351486738432.0000 - val_loss: 751654993920.0000\n",
      "Epoch 777/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 350564450304.0000 - val_loss: 750343487488.0000\n",
      "Epoch 778/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 349607297024.0000 - val_loss: 749003931648.0000\n",
      "Epoch 779/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 348601843712.0000 - val_loss: 747662671872.0000\n",
      "Epoch 780/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 347617230848.0000 - val_loss: 746322395136.0000\n",
      "Epoch 781/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 346653491200.0000 - val_loss: 744946335744.0000\n",
      "Epoch 782/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 345681657856.0000 - val_loss: 743577944064.0000\n",
      "Epoch 783/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 344704385024.0000 - val_loss: 742245531648.0000\n",
      "Epoch 784/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 343737761792.0000 - val_loss: 740948246528.0000\n",
      "Epoch 785/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 342792372224.0000 - val_loss: 739660529664.0000\n",
      "Epoch 786/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 341863727104.0000 - val_loss: 738368749568.0000\n",
      "Epoch 787/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 340916535296.0000 - val_loss: 737075855360.0000\n",
      "Epoch 788/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 340002177024.0000 - val_loss: 735739904000.0000\n",
      "Epoch 789/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 338992300032.0000 - val_loss: 734458347520.0000\n",
      "Epoch 790/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 338070339584.0000 - val_loss: 733165649920.0000\n",
      "Epoch 791/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 337184260096.0000 - val_loss: 731855192064.0000\n",
      "Epoch 792/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 336261808128.0000 - val_loss: 730576060416.0000\n",
      "Epoch 793/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 335349055488.0000 - val_loss: 729303154688.0000\n",
      "Epoch 794/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 334387478528.0000 - val_loss: 728045912064.0000\n",
      "Epoch 795/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 333471481856.0000 - val_loss: 726740631552.0000\n",
      "Epoch 796/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 332527828992.0000 - val_loss: 725401796608.0000\n",
      "Epoch 797/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 331581718528.0000 - val_loss: 724091469824.0000\n",
      "Epoch 798/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 330647109632.0000 - val_loss: 722812993536.0000\n",
      "Epoch 799/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 329727377408.0000 - val_loss: 721561387008.0000\n",
      "Epoch 800/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 328859025408.0000 - val_loss: 720311156736.0000\n",
      "Epoch 801/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 327945191424.0000 - val_loss: 719072526336.0000\n",
      "Epoch 802/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 327068352512.0000 - val_loss: 717841563648.0000\n",
      "Epoch 803/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 326196297728.0000 - val_loss: 716591726592.0000\n",
      "Epoch 804/4000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 325288919040.0000 - val_loss: 715352506368.0000\n",
      "Epoch 805/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 324425318400.0000 - val_loss: 714046636032.0000\n",
      "Epoch 806/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 323497164800.0000 - val_loss: 712771043328.0000\n",
      "Epoch 807/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 322568323072.0000 - val_loss: 711510261760.0000\n",
      "Epoch 808/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 321645281280.0000 - val_loss: 710220054528.0000\n",
      "Epoch 809/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 320730300416.0000 - val_loss: 708935352320.0000\n",
      "Epoch 810/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 319829606400.0000 - val_loss: 707665920000.0000\n",
      "Epoch 811/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 318914396160.0000 - val_loss: 706415427584.0000\n",
      "Epoch 812/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 318045356032.0000 - val_loss: 705125613568.0000\n",
      "Epoch 813/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 317134307328.0000 - val_loss: 703816597504.0000\n",
      "Epoch 814/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 316211298304.0000 - val_loss: 702558175232.0000\n",
      "Epoch 815/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 315320696832.0000 - val_loss: 701297655808.0000\n",
      "Epoch 816/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 314445889536.0000 - val_loss: 700019834880.0000\n",
      "Epoch 817/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 313540837376.0000 - val_loss: 698764427264.0000\n",
      "Epoch 818/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 312636211200.0000 - val_loss: 697506463744.0000\n",
      "Epoch 819/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 311747870720.0000 - val_loss: 696226152448.0000\n",
      "Epoch 820/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 310835183616.0000 - val_loss: 694963666944.0000\n",
      "Epoch 821/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 309965619200.0000 - val_loss: 693714550784.0000\n",
      "Epoch 822/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 309079212032.0000 - val_loss: 692526055424.0000\n",
      "Epoch 823/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 308231438336.0000 - val_loss: 691297648640.0000\n",
      "Epoch 824/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 307381207040.0000 - val_loss: 690028216320.0000\n",
      "Epoch 825/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 306498961408.0000 - val_loss: 688807936000.0000\n",
      "Epoch 826/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 305631526912.0000 - val_loss: 687578021888.0000\n",
      "Epoch 827/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 304782049280.0000 - val_loss: 686299086848.0000\n",
      "Epoch 828/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 303876898816.0000 - val_loss: 685011304448.0000\n",
      "Epoch 829/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 302998585344.0000 - val_loss: 683750260736.0000\n",
      "Epoch 830/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 302115323904.0000 - val_loss: 682550034432.0000\n",
      "Epoch 831/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 301289701376.0000 - val_loss: 681349021696.0000\n",
      "Epoch 832/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 300464865280.0000 - val_loss: 680125661184.0000\n",
      "Epoch 833/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 299581112320.0000 - val_loss: 678936772608.0000\n",
      "Epoch 834/4000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 298746642432.0000 - val_loss: 677700829184.0000\n",
      "Epoch 835/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 297905127424.0000 - val_loss: 676457611264.0000\n",
      "Epoch 836/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 297061842944.0000 - val_loss: 675248603136.0000\n",
      "Epoch 837/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 296186281984.0000 - val_loss: 674097463296.0000\n",
      "Epoch 838/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 295383891968.0000 - val_loss: 672896057344.0000\n",
      "Epoch 839/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 294550044672.0000 - val_loss: 671703040000.0000\n",
      "Epoch 840/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 293743853568.0000 - val_loss: 670487281664.0000\n",
      "Epoch 841/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 292928651264.0000 - val_loss: 669275586560.0000\n",
      "Epoch 842/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 292085301248.0000 - val_loss: 668092137472.0000\n",
      "Epoch 843/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 291267149824.0000 - val_loss: 666936082432.0000\n",
      "Epoch 844/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 290489303040.0000 - val_loss: 665773080576.0000\n",
      "Epoch 845/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 289665974272.0000 - val_loss: 664617680896.0000\n",
      "Epoch 846/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 288877019136.0000 - val_loss: 663411490816.0000\n",
      "Epoch 847/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 288020889600.0000 - val_loss: 662272409600.0000\n",
      "Epoch 848/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 287283281920.0000 - val_loss: 661050621952.0000\n",
      "Epoch 849/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 286414602240.0000 - val_loss: 659910754304.0000\n",
      "Epoch 850/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 285654712320.0000 - val_loss: 658767151104.0000\n",
      "Epoch 851/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 284869230592.0000 - val_loss: 657634689024.0000\n",
      "Epoch 852/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 284087681024.0000 - val_loss: 656490889216.0000\n",
      "Epoch 853/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 283307507712.0000 - val_loss: 655358164992.0000\n",
      "Epoch 854/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 282531037184.0000 - val_loss: 654213709824.0000\n",
      "Epoch 855/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 281756729344.0000 - val_loss: 653042188288.0000\n",
      "Epoch 856/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 280941297664.0000 - val_loss: 651860967424.0000\n",
      "Epoch 857/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 280146149376.0000 - val_loss: 650690363392.0000\n",
      "Epoch 858/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 279378657280.0000 - val_loss: 649541124096.0000\n",
      "Epoch 859/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 278584426496.0000 - val_loss: 648413446144.0000\n",
      "Epoch 860/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 277813952512.0000 - val_loss: 647296385024.0000\n",
      "Epoch 861/4000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 277078966272.0000 - val_loss: 646174277632.0000\n",
      "Epoch 862/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 276295417856.0000 - val_loss: 645075435520.0000\n",
      "Epoch 863/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 275563118592.0000 - val_loss: 643932422144.0000\n",
      "Epoch 864/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 274811469824.0000 - val_loss: 642804154368.0000\n",
      "Epoch 865/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 274006720512.0000 - val_loss: 641717436416.0000\n",
      "Epoch 866/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 273278763008.0000 - val_loss: 640596901888.0000\n",
      "Epoch 867/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 272528818176.0000 - val_loss: 639496814592.0000\n",
      "Epoch 868/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 271791046656.0000 - val_loss: 638377197568.0000\n",
      "Epoch 869/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 271052029952.0000 - val_loss: 637271277568.0000\n",
      "Epoch 870/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 270308802560.0000 - val_loss: 636154019840.0000\n",
      "Epoch 871/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 269568753664.0000 - val_loss: 635005239296.0000\n",
      "Epoch 872/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 268788400128.0000 - val_loss: 633849053184.0000\n",
      "Epoch 873/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 268037767168.0000 - val_loss: 632735858688.0000\n",
      "Epoch 874/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 267296243712.0000 - val_loss: 631631380480.0000\n",
      "Epoch 875/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 266557554688.0000 - val_loss: 630580772864.0000\n",
      "Epoch 876/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 265843032064.0000 - val_loss: 629526822912.0000\n",
      "Epoch 877/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 265131950080.0000 - val_loss: 628451442688.0000\n",
      "Epoch 878/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 264422064128.0000 - val_loss: 627341524992.0000\n",
      "Epoch 879/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 263698366464.0000 - val_loss: 626222694400.0000\n",
      "Epoch 880/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 262957826048.0000 - val_loss: 625125687296.0000\n",
      "Epoch 881/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 262218317824.0000 - val_loss: 624027959296.0000\n",
      "Epoch 882/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 261493669888.0000 - val_loss: 622948188160.0000\n",
      "Epoch 883/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 260762402816.0000 - val_loss: 621903609856.0000\n",
      "Epoch 884/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 260098375680.0000 - val_loss: 620837928960.0000\n",
      "Epoch 885/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 259389243392.0000 - val_loss: 619798790144.0000\n",
      "Epoch 886/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 258727608320.0000 - val_loss: 618741301248.0000\n",
      "Epoch 887/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 258028339200.0000 - val_loss: 617686302720.0000\n",
      "Epoch 888/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 257321992192.0000 - val_loss: 616654766080.0000\n",
      "Epoch 889/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 256665714688.0000 - val_loss: 615588102144.0000\n",
      "Epoch 890/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 255947554816.0000 - val_loss: 614553354240.0000\n",
      "Epoch 891/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 255299207168.0000 - val_loss: 613498028032.0000\n",
      "Epoch 892/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 254586322944.0000 - val_loss: 612502798336.0000\n",
      "Epoch 893/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 253937287168.0000 - val_loss: 611518447616.0000\n",
      "Epoch 894/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 253294542848.0000 - val_loss: 610506309632.0000\n",
      "Epoch 895/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 252644425728.0000 - val_loss: 609456226304.0000\n",
      "Epoch 896/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 251948662784.0000 - val_loss: 608469778432.0000\n",
      "Epoch 897/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 251309211648.0000 - val_loss: 607488770048.0000\n",
      "Epoch 898/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 250664222720.0000 - val_loss: 606489280512.0000\n",
      "Epoch 899/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 250022182912.0000 - val_loss: 605477535744.0000\n",
      "Epoch 900/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 249401638912.0000 - val_loss: 604429549568.0000\n",
      "Epoch 901/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 248712724480.0000 - val_loss: 603410726912.0000\n",
      "Epoch 902/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 248047681536.0000 - val_loss: 602439090176.0000\n",
      "Epoch 903/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 247419666432.0000 - val_loss: 601445040128.0000\n",
      "Epoch 904/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 246774153216.0000 - val_loss: 600421498880.0000\n",
      "Epoch 905/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 246117646336.0000 - val_loss: 599365844992.0000\n",
      "Epoch 906/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 245417033728.0000 - val_loss: 598359343104.0000\n",
      "Epoch 907/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 244793589760.0000 - val_loss: 597304082432.0000\n",
      "Epoch 908/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 244120453120.0000 - val_loss: 596247314432.0000\n",
      "Epoch 909/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 243463127040.0000 - val_loss: 595209486336.0000\n",
      "Epoch 910/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 242754191360.0000 - val_loss: 594194137088.0000\n",
      "Epoch 911/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 242126929920.0000 - val_loss: 593140056064.0000\n",
      "Epoch 912/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 241453318144.0000 - val_loss: 592142204928.0000\n",
      "Epoch 913/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 240818192384.0000 - val_loss: 591162769408.0000\n",
      "Epoch 914/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 240197697536.0000 - val_loss: 590134181888.0000\n",
      "Epoch 915/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 239521792000.0000 - val_loss: 589133512704.0000\n",
      "Epoch 916/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 238907031552.0000 - val_loss: 588101910528.0000\n",
      "Epoch 917/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 238246002688.0000 - val_loss: 587063427072.0000\n",
      "Epoch 918/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 237593657344.0000 - val_loss: 586027171840.0000\n",
      "Epoch 919/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 236946882560.0000 - val_loss: 585011888128.0000\n",
      "Epoch 920/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 236302516224.0000 - val_loss: 584014036992.0000\n",
      "Epoch 921/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 235697520640.0000 - val_loss: 582987546624.0000\n",
      "Epoch 922/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 235056594944.0000 - val_loss: 582017286144.0000\n",
      "Epoch 923/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 234457235456.0000 - val_loss: 581064523776.0000\n",
      "Epoch 924/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 233882468352.0000 - val_loss: 580137910272.0000\n",
      "Epoch 925/4000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 233268264960.0000 - val_loss: 579235151872.0000\n",
      "Epoch 926/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 232699330560.0000 - val_loss: 578336849920.0000\n",
      "Epoch 927/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 232192868352.0000 - val_loss: 577433501696.0000\n",
      "Epoch 928/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 231616905216.0000 - val_loss: 576539394048.0000\n",
      "Epoch 929/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 231046266880.0000 - val_loss: 575661932544.0000\n",
      "Epoch 930/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 230491586560.0000 - val_loss: 574784733184.0000\n",
      "Epoch 931/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 229948768256.0000 - val_loss: 573846716416.0000\n",
      "Epoch 932/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 229379129344.0000 - val_loss: 572912631808.0000\n",
      "Epoch 933/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 228797677568.0000 - val_loss: 571974025216.0000\n",
      "Epoch 934/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 228204118016.0000 - val_loss: 571064647680.0000\n",
      "Epoch 935/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 227686039552.0000 - val_loss: 570150420480.0000\n",
      "Epoch 936/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 227133063168.0000 - val_loss: 569223610368.0000\n",
      "Epoch 937/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 226534801408.0000 - val_loss: 568342544384.0000\n",
      "Epoch 938/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 225997946880.0000 - val_loss: 567453155328.0000\n",
      "Epoch 939/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 225452687360.0000 - val_loss: 566600073216.0000\n",
      "Epoch 940/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 224947388416.0000 - val_loss: 565760163840.0000\n",
      "Epoch 941/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 224420642816.0000 - val_loss: 564941488128.0000\n",
      "Epoch 942/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 223926845440.0000 - val_loss: 564059963392.0000\n",
      "Epoch 943/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 223407079424.0000 - val_loss: 563199279104.0000\n",
      "Epoch 944/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 222875009024.0000 - val_loss: 562401705984.0000\n",
      "Epoch 945/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 222395777024.0000 - val_loss: 561562320896.0000\n",
      "Epoch 946/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 221866311680.0000 - val_loss: 560694034432.0000\n",
      "Epoch 947/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 221362192384.0000 - val_loss: 559783084032.0000\n",
      "Epoch 948/4000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 220817506304.0000 - val_loss: 558904639488.0000\n",
      "Epoch 949/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 220275965952.0000 - val_loss: 558079934464.0000\n",
      "Epoch 950/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 219778940928.0000 - val_loss: 557230391296.0000\n",
      "Epoch 951/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 219290976256.0000 - val_loss: 556384649216.0000\n",
      "Epoch 952/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 218789642240.0000 - val_loss: 555535630336.0000\n",
      "Epoch 953/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 218278182912.0000 - val_loss: 554723704832.0000\n",
      "Epoch 954/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 217806159872.0000 - val_loss: 553920954368.0000\n",
      "Epoch 955/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 217327648768.0000 - val_loss: 553132556288.0000\n",
      "Epoch 956/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 216852611072.0000 - val_loss: 552354512896.0000\n",
      "Epoch 957/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 216386781184.0000 - val_loss: 551555956736.0000\n",
      "Epoch 958/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 215949983744.0000 - val_loss: 550735511552.0000\n",
      "Epoch 959/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 215434330112.0000 - val_loss: 549932498944.0000\n",
      "Epoch 960/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 214984916992.0000 - val_loss: 549151735808.0000\n",
      "Epoch 961/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 214501490688.0000 - val_loss: 548422025216.0000\n",
      "Epoch 962/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 214058500096.0000 - val_loss: 547696541696.0000\n",
      "Epoch 963/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 213654405120.0000 - val_loss: 546918006784.0000\n",
      "Epoch 964/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 213188739072.0000 - val_loss: 546145042432.0000\n",
      "Epoch 965/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 212724006912.0000 - val_loss: 545390198784.0000\n",
      "Epoch 966/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 212290338816.0000 - val_loss: 544610222080.0000\n",
      "Epoch 967/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 211827458048.0000 - val_loss: 543821922304.0000\n",
      "Epoch 968/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 211385188352.0000 - val_loss: 542978179072.0000\n",
      "Epoch 969/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 210899582976.0000 - val_loss: 542182637568.0000\n",
      "Epoch 970/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 210415616000.0000 - val_loss: 541400334336.0000\n",
      "Epoch 971/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 209968103424.0000 - val_loss: 540588376064.0000\n",
      "Epoch 972/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 209513824256.0000 - val_loss: 539799552000.0000\n",
      "Epoch 973/4000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 209058742272.0000 - val_loss: 539030618112.0000\n",
      "Epoch 974/4000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 208609411072.0000 - val_loss: 538277314560.0000\n",
      "Epoch 975/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 208174448640.0000 - val_loss: 537524600832.0000\n",
      "Epoch 976/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 207733538816.0000 - val_loss: 536759664640.0000\n",
      "Epoch 977/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 207322710016.0000 - val_loss: 535964942336.0000\n",
      "Epoch 978/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 206862352384.0000 - val_loss: 535197548544.0000\n",
      "Epoch 979/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 206405189632.0000 - val_loss: 534424059904.0000\n",
      "Epoch 980/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 205977632768.0000 - val_loss: 533657190400.0000\n",
      "Epoch 981/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 205543211008.0000 - val_loss: 532907556864.0000\n",
      "Epoch 982/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 205120700416.0000 - val_loss: 532146257920.0000\n",
      "Epoch 983/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 204710592512.0000 - val_loss: 531383451648.0000\n",
      "Epoch 984/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 204265160704.0000 - val_loss: 530631753728.0000\n",
      "Epoch 985/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 203832033280.0000 - val_loss: 529909055488.0000\n",
      "Epoch 986/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 203438440448.0000 - val_loss: 529178132480.0000\n",
      "Epoch 987/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 202993893376.0000 - val_loss: 528425156608.0000\n",
      "Epoch 988/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 202589782016.0000 - val_loss: 527665823744.0000\n",
      "Epoch 989/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 202170007552.0000 - val_loss: 526896037888.0000\n",
      "Epoch 990/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 201724182528.0000 - val_loss: 526100987904.0000\n",
      "Epoch 991/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 201288105984.0000 - val_loss: 525323501568.0000\n",
      "Epoch 992/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 200860663808.0000 - val_loss: 524521996288.0000\n",
      "Epoch 993/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 200436416512.0000 - val_loss: 523726749696.0000\n",
      "Epoch 994/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 199974240256.0000 - val_loss: 522971774976.0000\n",
      "Epoch 995/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 199571423232.0000 - val_loss: 522218668032.0000\n",
      "Epoch 996/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 199169720320.0000 - val_loss: 521488957440.0000\n",
      "Epoch 997/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 198779682816.0000 - val_loss: 520775696384.0000\n",
      "Epoch 998/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 198374965248.0000 - val_loss: 520080195584.0000\n",
      "Epoch 999/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 197985058816.0000 - val_loss: 519379517440.0000\n",
      "Epoch 1000/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 197633900544.0000 - val_loss: 518654820352.0000\n",
      "Epoch 1001/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 197242159104.0000 - val_loss: 517951684608.0000\n",
      "Epoch 1002/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 196880908288.0000 - val_loss: 517281120256.0000\n",
      "Epoch 1003/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 196505878528.0000 - val_loss: 516683988992.0000\n",
      "Epoch 1004/4000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 196147773440.0000 - val_loss: 516038885376.0000\n",
      "Epoch 1005/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 195808165888.0000 - val_loss: 515361472512.0000\n",
      "Epoch 1006/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 195476307968.0000 - val_loss: 514684747776.0000\n",
      "Epoch 1007/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 195124019200.0000 - val_loss: 514053144576.0000\n",
      "Epoch 1008/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 194770239488.0000 - val_loss: 513467252736.0000\n",
      "Epoch 1009/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 194465054720.0000 - val_loss: 512846823424.0000\n",
      "Epoch 1010/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 194126807040.0000 - val_loss: 512227278848.0000\n",
      "Epoch 1011/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 193818705920.0000 - val_loss: 511591317504.0000\n",
      "Epoch 1012/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 193460551680.0000 - val_loss: 511006834688.0000\n",
      "Epoch 1013/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 193136263168.0000 - val_loss: 510362681344.0000\n",
      "Epoch 1014/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 192795000832.0000 - val_loss: 509637918720.0000\n",
      "Epoch 1015/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 192411926528.0000 - val_loss: 508945760256.0000\n",
      "Epoch 1016/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 192067239936.0000 - val_loss: 508249767936.0000\n",
      "Epoch 1017/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 191713787904.0000 - val_loss: 507608465408.0000\n",
      "Epoch 1018/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 191386894336.0000 - val_loss: 507018477568.0000\n",
      "Epoch 1019/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 191072452608.0000 - val_loss: 506445266944.0000\n",
      "Epoch 1020/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 190765580288.0000 - val_loss: 505881133056.0000\n",
      "Epoch 1021/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 190474633216.0000 - val_loss: 505273516032.0000\n",
      "Epoch 1022/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 190164369408.0000 - val_loss: 504637423616.0000\n",
      "Epoch 1023/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 189818732544.0000 - val_loss: 504040423424.0000\n",
      "Epoch 1024/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 189513482240.0000 - val_loss: 503422812160.0000\n",
      "Epoch 1025/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 189188980736.0000 - val_loss: 502779183104.0000\n",
      "Epoch 1026/4000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 188851535872.0000 - val_loss: 502120677376.0000\n",
      "Epoch 1027/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 188525297664.0000 - val_loss: 501392965632.0000\n",
      "Epoch 1028/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 188179955712.0000 - val_loss: 500697759744.0000\n",
      "Epoch 1029/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 187848540160.0000 - val_loss: 500058980352.0000\n",
      "Epoch 1030/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 187488337920.0000 - val_loss: 499467943936.0000\n",
      "Epoch 1031/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 187190935552.0000 - val_loss: 498865799168.0000\n",
      "Epoch 1032/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 186915618816.0000 - val_loss: 498254970880.0000\n",
      "Epoch 1033/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 186584629248.0000 - val_loss: 497674092544.0000\n",
      "Epoch 1034/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 186324090880.0000 - val_loss: 497045209088.0000\n",
      "Epoch 1035/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 185993052160.0000 - val_loss: 496453025792.0000\n",
      "Epoch 1036/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 185700745216.0000 - val_loss: 495832891392.0000\n",
      "Epoch 1037/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 185400737792.0000 - val_loss: 495199485952.0000\n",
      "Epoch 1038/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 185086967808.0000 - val_loss: 494616313856.0000\n",
      "Epoch 1039/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 184769626112.0000 - val_loss: 494078787584.0000\n",
      "Epoch 1040/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 184511987712.0000 - val_loss: 493491748864.0000\n",
      "Epoch 1041/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 184248680448.0000 - val_loss: 492878528512.0000\n",
      "Epoch 1042/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 183947739136.0000 - val_loss: 492282478592.0000\n",
      "Epoch 1043/4000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 183648124928.0000 - val_loss: 491716247552.0000\n",
      "Epoch 1044/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 183370448896.0000 - val_loss: 491153883136.0000\n",
      "Epoch 1045/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 183121854464.0000 - val_loss: 490574839808.0000\n",
      "Epoch 1046/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 182820765696.0000 - val_loss: 490020700160.0000\n",
      "Epoch 1047/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 182559260672.0000 - val_loss: 489492578304.0000\n",
      "Epoch 1048/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 182305292288.0000 - val_loss: 488946892800.0000\n",
      "Epoch 1049/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 182055927808.0000 - val_loss: 488364670976.0000\n",
      "Epoch 1050/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 181747826688.0000 - val_loss: 487802896384.0000\n",
      "Epoch 1051/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 181521776640.0000 - val_loss: 487240237056.0000\n",
      "Epoch 1052/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 181252915200.0000 - val_loss: 486706151424.0000\n",
      "Epoch 1053/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 180974403584.0000 - val_loss: 486115475456.0000\n",
      "Epoch 1054/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 180686110720.0000 - val_loss: 485534040064.0000\n",
      "Epoch 1055/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 180438876160.0000 - val_loss: 484945166336.0000\n",
      "Epoch 1056/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 180173537280.0000 - val_loss: 484377231360.0000\n",
      "Epoch 1057/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 179912622080.0000 - val_loss: 483837444096.0000\n",
      "Epoch 1058/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 179629604864.0000 - val_loss: 483344875520.0000\n",
      "Epoch 1059/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 179444449280.0000 - val_loss: 482803351552.0000\n",
      "Epoch 1060/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 179171852288.0000 - val_loss: 482317074432.0000\n",
      "Epoch 1061/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 178944212992.0000 - val_loss: 481797701632.0000\n",
      "Epoch 1062/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 178705219584.0000 - val_loss: 481308442624.0000\n",
      "Epoch 1063/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 178497290240.0000 - val_loss: 480793296896.0000\n",
      "Epoch 1064/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 178264064000.0000 - val_loss: 480296796160.0000\n",
      "Epoch 1065/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 178031394816.0000 - val_loss: 479844859904.0000\n",
      "Epoch 1066/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 177852268544.0000 - val_loss: 479354847232.0000\n",
      "Epoch 1067/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 177610457088.0000 - val_loss: 478888984576.0000\n",
      "Epoch 1068/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 177424236544.0000 - val_loss: 478452350976.0000\n",
      "Epoch 1069/4000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 177213407232.0000 - val_loss: 478050680832.0000\n",
      "Epoch 1070/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 177035575296.0000 - val_loss: 477632561152.0000\n",
      "Epoch 1071/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 176848142336.0000 - val_loss: 477172727808.0000\n",
      "Epoch 1072/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 176647307264.0000 - val_loss: 476703358976.0000\n",
      "Epoch 1073/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 176446554112.0000 - val_loss: 476235300864.0000\n",
      "Epoch 1074/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 176218226688.0000 - val_loss: 475783364608.0000\n",
      "Epoch 1075/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 176025731072.0000 - val_loss: 475333918720.0000\n",
      "Epoch 1076/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 175826927616.0000 - val_loss: 474904952832.0000\n",
      "Epoch 1077/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 175616737280.0000 - val_loss: 474406322176.0000\n",
      "Epoch 1078/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 175431188480.0000 - val_loss: 473876758528.0000\n",
      "Epoch 1079/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 175203418112.0000 - val_loss: 473402441728.0000\n",
      "Epoch 1080/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 175012216832.0000 - val_loss: 472944312320.0000\n",
      "Epoch 1081/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 174824112128.0000 - val_loss: 472506826752.0000\n",
      "Epoch 1082/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 174627864576.0000 - val_loss: 472132452352.0000\n",
      "Epoch 1083/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 174468890624.0000 - val_loss: 471760371712.0000\n",
      "Epoch 1084/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 174296629248.0000 - val_loss: 471347625984.0000\n",
      "Epoch 1085/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 174122401792.0000 - val_loss: 470916497408.0000\n",
      "Epoch 1086/4000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 173950156800.0000 - val_loss: 470473768960.0000\n",
      "Epoch 1087/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 173759594496.0000 - val_loss: 470030385152.0000\n",
      "Epoch 1088/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 173562249216.0000 - val_loss: 469607284736.0000\n",
      "Epoch 1089/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 173378289664.0000 - val_loss: 469161574400.0000\n",
      "Epoch 1090/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 173188677632.0000 - val_loss: 468690239488.0000\n",
      "Epoch 1091/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 173009666048.0000 - val_loss: 468211892224.0000\n",
      "Epoch 1092/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 172812238848.0000 - val_loss: 467766771712.0000\n",
      "Epoch 1093/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 172641763328.0000 - val_loss: 467318571008.0000\n",
      "Epoch 1094/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 172453740544.0000 - val_loss: 466874695680.0000\n",
      "Epoch 1095/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 172271566848.0000 - val_loss: 466462867456.0000\n",
      "Epoch 1096/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 172107333632.0000 - val_loss: 466058051584.0000\n",
      "Epoch 1097/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 171927175168.0000 - val_loss: 465646780416.0000\n",
      "Epoch 1098/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 171784503296.0000 - val_loss: 465186848768.0000\n",
      "Epoch 1099/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 171589222400.0000 - val_loss: 464772923392.0000\n",
      "Epoch 1100/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 171433656320.0000 - val_loss: 464375775232.0000\n",
      "Epoch 1101/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 171280269312.0000 - val_loss: 463989538816.0000\n",
      "Epoch 1102/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 171120230400.0000 - val_loss: 463597371392.0000\n",
      "Epoch 1103/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 170972168192.0000 - val_loss: 463194685440.0000\n",
      "Epoch 1104/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 170818027520.0000 - val_loss: 462806843392.0000\n",
      "Epoch 1105/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 170648879104.0000 - val_loss: 462445838336.0000\n",
      "Epoch 1106/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 170506764288.0000 - val_loss: 462049509376.0000\n",
      "Epoch 1107/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 170364993536.0000 - val_loss: 461671858176.0000\n",
      "Epoch 1108/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 170231218176.0000 - val_loss: 461306363904.0000\n",
      "Epoch 1109/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 170082795520.0000 - val_loss: 460952010752.0000\n",
      "Epoch 1110/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 169974513664.0000 - val_loss: 460578717696.0000\n",
      "Epoch 1111/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 169812606976.0000 - val_loss: 460222988288.0000\n",
      "Epoch 1112/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 169692774400.0000 - val_loss: 459876237312.0000\n",
      "Epoch 1113/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 169564553216.0000 - val_loss: 459545509888.0000\n",
      "Epoch 1114/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 169421651968.0000 - val_loss: 459238834176.0000\n",
      "Epoch 1115/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 169314271232.0000 - val_loss: 458914693120.0000\n",
      "Epoch 1116/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 169176481792.0000 - val_loss: 458558111744.0000\n",
      "Epoch 1117/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 169041264640.0000 - val_loss: 458200612864.0000\n",
      "Epoch 1118/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 168916221952.0000 - val_loss: 457858514944.0000\n",
      "Epoch 1119/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 168814313472.0000 - val_loss: 457534242816.0000\n",
      "Epoch 1120/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 168686108672.0000 - val_loss: 457208070144.0000\n",
      "Epoch 1121/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 168555036672.0000 - val_loss: 456875933696.0000\n",
      "Epoch 1122/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 168437612544.0000 - val_loss: 456520531968.0000\n",
      "Epoch 1123/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 168317059072.0000 - val_loss: 456139997184.0000\n",
      "Epoch 1124/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 168160280576.0000 - val_loss: 455811104768.0000\n",
      "Epoch 1125/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 168050622464.0000 - val_loss: 455485718528.0000\n",
      "Epoch 1126/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 167935606784.0000 - val_loss: 455157121024.0000\n",
      "Epoch 1127/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 167823540224.0000 - val_loss: 454822100992.0000\n",
      "Epoch 1128/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 167713062912.0000 - val_loss: 454430916608.0000\n",
      "Epoch 1129/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 167584514048.0000 - val_loss: 454041796608.0000\n",
      "Epoch 1130/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 167450263552.0000 - val_loss: 453702680576.0000\n",
      "Epoch 1131/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 167308378112.0000 - val_loss: 453385879552.0000\n",
      "Epoch 1132/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 167193083904.0000 - val_loss: 453013241856.0000\n",
      "Epoch 1133/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 167076724736.0000 - val_loss: 452686544896.0000\n",
      "Epoch 1134/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 166970294272.0000 - val_loss: 452340842496.0000\n",
      "Epoch 1135/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 166860455936.0000 - val_loss: 452011851776.0000\n",
      "Epoch 1136/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 166759497728.0000 - val_loss: 451683778560.0000\n",
      "Epoch 1137/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 166636683264.0000 - val_loss: 451433725952.0000\n",
      "Epoch 1138/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 166545670144.0000 - val_loss: 451145498624.0000\n",
      "Epoch 1139/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 166473891840.0000 - val_loss: 450861858816.0000\n",
      "Epoch 1140/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 166369935360.0000 - val_loss: 450615672832.0000\n",
      "Epoch 1141/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 166278987776.0000 - val_loss: 450361196544.0000\n",
      "Epoch 1142/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 166197854208.0000 - val_loss: 450078277632.0000\n",
      "Epoch 1143/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 166091948032.0000 - val_loss: 449822556160.0000\n",
      "Epoch 1144/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 166002196480.0000 - val_loss: 449498480640.0000\n",
      "Epoch 1145/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 165887688704.0000 - val_loss: 449203830784.0000\n",
      "Epoch 1146/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 165835145216.0000 - val_loss: 448863895552.0000\n",
      "Epoch 1147/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 165699616768.0000 - val_loss: 448594673664.0000\n",
      "Epoch 1148/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 165627428864.0000 - val_loss: 448323649536.0000\n",
      "Epoch 1149/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 165532942336.0000 - val_loss: 448046661632.0000\n",
      "Epoch 1150/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 165449515008.0000 - val_loss: 447699582976.0000\n",
      "Epoch 1151/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 165343444992.0000 - val_loss: 447363678208.0000\n",
      "Epoch 1152/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 165245632512.0000 - val_loss: 447044812800.0000\n",
      "Epoch 1153/4000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 165150588928.0000 - val_loss: 446719590400.0000\n",
      "Epoch 1154/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 165042061312.0000 - val_loss: 446410424320.0000\n",
      "Epoch 1155/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 164954767360.0000 - val_loss: 446156079104.0000\n",
      "Epoch 1156/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 164877156352.0000 - val_loss: 445921525760.0000\n",
      "Epoch 1157/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 164800856064.0000 - val_loss: 445709975552.0000\n",
      "Epoch 1158/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 164730601472.0000 - val_loss: 445434920960.0000\n",
      "Epoch 1159/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 164651646976.0000 - val_loss: 445181460480.0000\n",
      "Epoch 1160/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 164582260736.0000 - val_loss: 444941959168.0000\n",
      "Epoch 1161/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 164503437312.0000 - val_loss: 444707373056.0000\n",
      "Epoch 1162/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 164438917120.0000 - val_loss: 444340928512.0000\n",
      "Epoch 1163/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 164323786752.0000 - val_loss: 443969175552.0000\n",
      "Epoch 1164/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 164230316032.0000 - val_loss: 443663745024.0000\n",
      "Epoch 1165/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 164140793856.0000 - val_loss: 443416838144.0000\n",
      "Epoch 1166/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 164066443264.0000 - val_loss: 443219017728.0000\n",
      "Epoch 1167/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 164015734784.0000 - val_loss: 443033485312.0000\n",
      "Epoch 1168/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 163966746624.0000 - val_loss: 442871808000.0000\n",
      "Epoch 1169/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 163920478208.0000 - val_loss: 442696204288.0000\n",
      "Epoch 1170/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 163862298624.0000 - val_loss: 442476429312.0000\n",
      "Epoch 1171/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 163799400448.0000 - val_loss: 442261831680.0000\n",
      "Epoch 1172/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 163744792576.0000 - val_loss: 442043498496.0000\n",
      "Epoch 1173/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 163673014272.0000 - val_loss: 441836273664.0000\n",
      "Epoch 1174/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 163634610176.0000 - val_loss: 441594642432.0000\n",
      "Epoch 1175/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 163561193472.0000 - val_loss: 441404751872.0000\n",
      "Epoch 1176/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 163499163648.0000 - val_loss: 441185730560.0000\n",
      "Epoch 1177/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 163443441664.0000 - val_loss: 440955666432.0000\n",
      "Epoch 1178/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 163393650688.0000 - val_loss: 440710496256.0000\n",
      "Epoch 1179/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 163313418240.0000 - val_loss: 440470437888.0000\n",
      "Epoch 1180/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 163263774720.0000 - val_loss: 440230379520.0000\n",
      "Epoch 1181/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 163194322944.0000 - val_loss: 440030068736.0000\n",
      "Epoch 1182/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 163154919424.0000 - val_loss: 439836082176.0000\n",
      "Epoch 1183/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 163108929536.0000 - val_loss: 439666475008.0000\n",
      "Epoch 1184/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 163057369088.0000 - val_loss: 439526359040.0000\n",
      "Epoch 1185/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 163023863808.0000 - val_loss: 439372840960.0000\n",
      "Epoch 1186/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 162986328064.0000 - val_loss: 439255040000.0000\n",
      "Epoch 1187/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 162950266880.0000 - val_loss: 439080550400.0000\n",
      "Epoch 1188/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 162903785472.0000 - val_loss: 438888857600.0000\n",
      "Epoch 1189/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 162859024384.0000 - val_loss: 438670622720.0000\n",
      "Epoch 1190/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 162805760000.0000 - val_loss: 438462054400.0000\n",
      "Epoch 1191/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 162750201856.0000 - val_loss: 438299262976.0000\n",
      "Epoch 1192/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 162701754368.0000 - val_loss: 438130606080.0000\n",
      "Epoch 1193/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 162670854144.0000 - val_loss: 437944844288.0000\n",
      "Epoch 1194/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 162623143936.0000 - val_loss: 437773238272.0000\n",
      "Epoch 1195/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 162590130176.0000 - val_loss: 437627158528.0000\n",
      "Epoch 1196/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 162552414208.0000 - val_loss: 437468430336.0000\n",
      "Epoch 1197/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 162499706880.0000 - val_loss: 437268348928.0000\n",
      "Epoch 1198/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 162453471232.0000 - val_loss: 437051359232.0000\n",
      "Epoch 1199/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 162416738304.0000 - val_loss: 436864188416.0000\n",
      "Epoch 1200/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 162364899328.0000 - val_loss: 436694319104.0000\n",
      "Epoch 1201/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 162317762560.0000 - val_loss: 436493975552.0000\n",
      "Epoch 1202/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 162273280000.0000 - val_loss: 436306313216.0000\n",
      "Epoch 1203/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 162234236928.0000 - val_loss: 436088963072.0000\n",
      "Epoch 1204/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 162187706368.0000 - val_loss: 435901857792.0000\n",
      "Epoch 1205/4000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 162135851008.0000 - val_loss: 435726024704.0000\n",
      "Epoch 1206/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 162106163200.0000 - val_loss: 435558809600.0000\n",
      "Epoch 1207/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 162067415040.0000 - val_loss: 435430916096.0000\n",
      "Epoch 1208/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 162033090560.0000 - val_loss: 435280412672.0000\n",
      "Epoch 1209/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 161991983104.0000 - val_loss: 435069943808.0000\n",
      "Epoch 1210/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 161954037760.0000 - val_loss: 434849808384.0000\n",
      "Epoch 1211/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 161895366656.0000 - val_loss: 434672861184.0000\n",
      "Epoch 1212/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 161878016000.0000 - val_loss: 434468323328.0000\n",
      "Epoch 1213/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 161819000832.0000 - val_loss: 434299076608.0000\n",
      "Epoch 1214/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 161794572288.0000 - val_loss: 434090180608.0000\n",
      "Epoch 1215/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 161748975616.0000 - val_loss: 433920507904.0000\n",
      "Epoch 1216/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 161704886272.0000 - val_loss: 433789861888.0000\n",
      "Epoch 1217/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 161701609472.0000 - val_loss: 433559207936.0000\n",
      "Epoch 1218/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 161643479040.0000 - val_loss: 433391665152.0000\n",
      "Epoch 1219/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 161606320128.0000 - val_loss: 433224941568.0000\n",
      "Epoch 1220/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 161564180480.0000 - val_loss: 433051664384.0000\n",
      "Epoch 1221/4000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 161531248640.0000 - val_loss: 432889692160.0000\n",
      "Epoch 1222/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 161497055232.0000 - val_loss: 432672440320.0000\n",
      "Epoch 1223/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 161459273728.0000 - val_loss: 432422649856.0000\n",
      "Epoch 1224/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 161410383872.0000 - val_loss: 432221978624.0000\n",
      "Epoch 1225/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 161363181568.0000 - val_loss: 432068263936.0000\n",
      "Epoch 1226/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 161336049664.0000 - val_loss: 431908356096.0000\n",
      "Epoch 1227/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 161310277632.0000 - val_loss: 431797731328.0000\n",
      "Epoch 1228/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 161292402688.0000 - val_loss: 431687827456.0000\n",
      "Epoch 1229/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 161270923264.0000 - val_loss: 431588212736.0000\n",
      "Epoch 1230/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 161255129088.0000 - val_loss: 431432925184.0000\n",
      "Epoch 1231/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 161234419712.0000 - val_loss: 431282847744.0000\n",
      "Epoch 1232/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 161187790848.0000 - val_loss: 431169306624.0000\n",
      "Epoch 1233/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 161181777920.0000 - val_loss: 430993539072.0000\n",
      "Epoch 1234/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 161150058496.0000 - val_loss: 430865219584.0000\n",
      "Epoch 1235/4000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 161120665600.0000 - val_loss: 430799749120.0000\n",
      "Epoch 1236/4000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 161109114880.0000 - val_loss: 430698561536.0000\n",
      "Epoch 1237/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 161093074944.0000 - val_loss: 430610677760.0000\n",
      "Epoch 1238/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 161080901632.0000 - val_loss: 430520041472.0000\n",
      "Epoch 1239/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 161062715392.0000 - val_loss: 430474264576.0000\n",
      "Epoch 1240/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 161051230208.0000 - val_loss: 430408990720.0000\n",
      "Epoch 1241/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 161034027008.0000 - val_loss: 430277754880.0000\n",
      "Epoch 1242/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 161037549568.0000 - val_loss: 430119616512.0000\n",
      "Epoch 1243/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 160990560256.0000 - val_loss: 430037794816.0000\n",
      "Epoch 1244/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160977977344.0000 - val_loss: 429947355136.0000\n",
      "Epoch 1245/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160967901184.0000 - val_loss: 429787873280.0000\n",
      "Epoch 1246/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160931807232.0000 - val_loss: 429648609280.0000\n",
      "Epoch 1247/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160906035200.0000 - val_loss: 429530284032.0000\n",
      "Epoch 1248/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160899383296.0000 - val_loss: 429395279872.0000\n",
      "Epoch 1249/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160871776256.0000 - val_loss: 429322928128.0000\n",
      "Epoch 1250/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160857456640.0000 - val_loss: 429209321472.0000\n",
      "Epoch 1251/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160835551232.0000 - val_loss: 429102825472.0000\n",
      "Epoch 1252/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160816578560.0000 - val_loss: 428950323200.0000\n",
      "Epoch 1253/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160794722304.0000 - val_loss: 428849790976.0000\n",
      "Epoch 1254/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160781320192.0000 - val_loss: 428783534080.0000\n",
      "Epoch 1255/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160772833280.0000 - val_loss: 428678807552.0000\n",
      "Epoch 1256/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160751812608.0000 - val_loss: 428554846208.0000\n",
      "Epoch 1257/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160727203840.0000 - val_loss: 428378423296.0000\n",
      "Epoch 1258/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160699285504.0000 - val_loss: 428230148096.0000\n",
      "Epoch 1259/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160678674432.0000 - val_loss: 428075483136.0000\n",
      "Epoch 1260/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160659439616.0000 - val_loss: 427951685632.0000\n",
      "Epoch 1261/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160643448832.0000 - val_loss: 427834114048.0000\n",
      "Epoch 1262/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160622116864.0000 - val_loss: 427740266496.0000\n",
      "Epoch 1263/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160609452032.0000 - val_loss: 427593793536.0000\n",
      "Epoch 1264/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160594280448.0000 - val_loss: 427477172224.0000\n",
      "Epoch 1265/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160574291968.0000 - val_loss: 427410849792.0000\n",
      "Epoch 1266/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160563855360.0000 - val_loss: 427311366144.0000\n",
      "Epoch 1267/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160549257216.0000 - val_loss: 427180130304.0000\n",
      "Epoch 1268/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160535478272.0000 - val_loss: 427084578816.0000\n",
      "Epoch 1269/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160525156352.0000 - val_loss: 427019894784.0000\n",
      "Epoch 1270/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160515244032.0000 - val_loss: 427008950272.0000\n",
      "Epoch 1271/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160514670592.0000 - val_loss: 426984734720.0000\n",
      "Epoch 1272/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160513196032.0000 - val_loss: 427010293760.0000\n",
      "Epoch 1273/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160514162688.0000 - val_loss: 427001282560.0000\n",
      "Epoch 1274/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160511655936.0000 - val_loss: 426965204992.0000\n",
      "Epoch 1275/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160508084224.0000 - val_loss: 426890067968.0000\n",
      "Epoch 1276/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160496451584.0000 - val_loss: 426814734336.0000\n",
      "Epoch 1277/4000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 160482541568.0000 - val_loss: 426706960384.0000\n",
      "Epoch 1278/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 160467124224.0000 - val_loss: 426624942080.0000\n",
      "Epoch 1279/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 160460472320.0000 - val_loss: 426515726336.0000\n",
      "Epoch 1280/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 160443514880.0000 - val_loss: 426445766656.0000\n",
      "Epoch 1281/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 160437633024.0000 - val_loss: 426379706368.0000\n",
      "Epoch 1282/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160426967040.0000 - val_loss: 426327572480.0000\n",
      "Epoch 1283/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160413745152.0000 - val_loss: 426220453888.0000\n",
      "Epoch 1284/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160397836288.0000 - val_loss: 426095017984.0000\n",
      "Epoch 1285/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160397672448.0000 - val_loss: 425916399616.0000\n",
      "Epoch 1286/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160373686272.0000 - val_loss: 425775955968.0000\n",
      "Epoch 1287/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 160352075776.0000 - val_loss: 425691283456.0000\n",
      "Epoch 1288/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160347799552.0000 - val_loss: 425591832576.0000\n",
      "Epoch 1289/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160331841536.0000 - val_loss: 425560473600.0000\n",
      "Epoch 1290/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160328056832.0000 - val_loss: 425529409536.0000\n",
      "Epoch 1291/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160326090752.0000 - val_loss: 425509879808.0000\n",
      "Epoch 1292/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 160323551232.0000 - val_loss: 425495625728.0000\n",
      "Epoch 1293/4000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 160321044480.0000 - val_loss: 425465643008.0000\n",
      "Epoch 1294/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 160317505536.0000 - val_loss: 425431957504.0000\n",
      "Epoch 1295/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160311918592.0000 - val_loss: 425372516352.0000\n",
      "Epoch 1296/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160301613056.0000 - val_loss: 425295347712.0000\n",
      "Epoch 1297/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160292454400.0000 - val_loss: 425217720320.0000\n",
      "Epoch 1298/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160295403520.0000 - val_loss: 425045786624.0000\n",
      "Epoch 1299/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160272367616.0000 - val_loss: 424908259328.0000\n",
      "Epoch 1300/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160257802240.0000 - val_loss: 424815984640.0000\n",
      "Epoch 1301/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160243040256.0000 - val_loss: 424782069760.0000\n",
      "Epoch 1302/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160241942528.0000 - val_loss: 424767553536.0000\n",
      "Epoch 1303/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 160239534080.0000 - val_loss: 424729640960.0000\n",
      "Epoch 1304/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160231161856.0000 - val_loss: 424661221376.0000\n",
      "Epoch 1305/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160225296384.0000 - val_loss: 424618459136.0000\n",
      "Epoch 1306/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160220807168.0000 - val_loss: 424529461248.0000\n",
      "Epoch 1307/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160205668352.0000 - val_loss: 424418476032.0000\n",
      "Epoch 1308/4000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 160193150976.0000 - val_loss: 424310636544.0000\n",
      "Epoch 1309/4000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 160187678720.0000 - val_loss: 424178778112.0000\n",
      "Epoch 1310/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160178536448.0000 - val_loss: 424093777920.0000\n",
      "Epoch 1311/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 160167460864.0000 - val_loss: 424019132416.0000\n",
      "Epoch 1312/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160164724736.0000 - val_loss: 423903199232.0000\n",
      "Epoch 1313/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160147734528.0000 - val_loss: 423855751168.0000\n",
      "Epoch 1314/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160136085504.0000 - val_loss: 423740997632.0000\n",
      "Epoch 1315/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160132366336.0000 - val_loss: 423638761472.0000\n",
      "Epoch 1316/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160122912768.0000 - val_loss: 423589838848.0000\n",
      "Epoch 1317/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160122601472.0000 - val_loss: 423511719936.0000\n",
      "Epoch 1318/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160112820224.0000 - val_loss: 423487766528.0000\n",
      "Epoch 1319/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 160112803840.0000 - val_loss: 423426883584.0000\n",
      "Epoch 1320/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160106627072.0000 - val_loss: 423377666048.0000\n",
      "Epoch 1321/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160100581376.0000 - val_loss: 423319994368.0000\n",
      "Epoch 1322/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160095469568.0000 - val_loss: 423269138432.0000\n",
      "Epoch 1323/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160095059968.0000 - val_loss: 423279198208.0000\n",
      "Epoch 1324/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160092766208.0000 - val_loss: 423269924864.0000\n",
      "Epoch 1325/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160091652096.0000 - val_loss: 423235584000.0000\n",
      "Epoch 1326/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160089702400.0000 - val_loss: 423156940800.0000\n",
      "Epoch 1327/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160080609280.0000 - val_loss: 423108280320.0000\n",
      "Epoch 1328/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160077398016.0000 - val_loss: 423075086336.0000\n",
      "Epoch 1329/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160076136448.0000 - val_loss: 423030030336.0000\n",
      "Epoch 1330/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160072204288.0000 - val_loss: 422998605824.0000\n",
      "Epoch 1331/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160069648384.0000 - val_loss: 422938935296.0000\n",
      "Epoch 1332/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160062980096.0000 - val_loss: 422876938240.0000\n",
      "Epoch 1333/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160066191360.0000 - val_loss: 422887653376.0000\n",
      "Epoch 1334/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160059359232.0000 - val_loss: 422830833664.0000\n",
      "Epoch 1335/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160056295424.0000 - val_loss: 422802980864.0000\n",
      "Epoch 1336/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160053198848.0000 - val_loss: 422798589952.0000\n",
      "Epoch 1337/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160053493760.0000 - val_loss: 422797672448.0000\n",
      "Epoch 1338/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160062177280.0000 - val_loss: 422719619072.0000\n",
      "Epoch 1339/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160047644672.0000 - val_loss: 422737084416.0000\n",
      "Epoch 1340/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160047513600.0000 - val_loss: 422732988416.0000\n",
      "Epoch 1341/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160044302336.0000 - val_loss: 422677676032.0000\n",
      "Epoch 1342/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160034144256.0000 - val_loss: 422550863872.0000\n",
      "Epoch 1343/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160025903104.0000 - val_loss: 422432374784.0000\n",
      "Epoch 1344/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160020496384.0000 - val_loss: 422257885184.0000\n",
      "Epoch 1345/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160011894784.0000 - val_loss: 422119768064.0000\n",
      "Epoch 1346/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 159996837888.0000 - val_loss: 422027362304.0000\n",
      "Epoch 1347/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 159994970112.0000 - val_loss: 421931352064.0000\n",
      "Epoch 1348/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 159988580352.0000 - val_loss: 421915099136.0000\n",
      "Epoch 1349/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 159988711424.0000 - val_loss: 421847924736.0000\n",
      "Epoch 1350/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 159981748224.0000 - val_loss: 421826920448.0000\n",
      "Epoch 1351/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 159985287168.0000 - val_loss: 421838225408.0000\n",
      "Epoch 1352/4000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 159978078208.0000 - val_loss: 421779996672.0000\n",
      "Epoch 1353/4000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 159985156096.0000 - val_loss: 421700665344.0000\n",
      "Epoch 1354/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 159973523456.0000 - val_loss: 421709086720.0000\n",
      "Epoch 1355/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 159971000320.0000 - val_loss: 421648793600.0000\n",
      "Epoch 1356/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 159967526912.0000 - val_loss: 421497831424.0000\n",
      "Epoch 1357/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 159952502784.0000 - val_loss: 421390974976.0000\n",
      "Epoch 1358/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 159949930496.0000 - val_loss: 421287428096.0000\n",
      "Epoch 1359/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 159942508544.0000 - val_loss: 421218320384.0000\n",
      "Epoch 1360/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 159939936256.0000 - val_loss: 421103108096.0000\n",
      "Epoch 1361/4000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 159942508544.0000 - val_loss: 421004738560.0000\n",
      "Epoch 1362/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 159931432960.0000 - val_loss: 421018697728.0000\n",
      "Epoch 1363/4000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 159933677568.0000 - val_loss: 421044060160.0000\n",
      "Epoch 1364/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 159932841984.0000 - val_loss: 421019648000.0000\n",
      "Epoch 1365/4000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 159932366848.0000 - val_loss: 421007097856.0000\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 18)                342       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 36)                684       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 72)                2664      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 36)                2628      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 18)                666       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 18)                342       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 19        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,345\n",
      "Trainable params: 7,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history =model.fit(x=X_train,y=y_train,\n",
    "          validation_data=(X_Test,y_Test),\n",
    "          epochs=4000,callbacks = callback)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1365"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsIAAAHdCAYAAAAXeh8KAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAABX4UlEQVR4nO3dd3hUVeLG8e+ZmVRCSCD00EF6D9KLSpdiR0UUBQuK5WdZXd1dd1133V3X3rAhRVAQcUUBEZEqRQLSQXoJNXRISD+/P+5QFUggyU0y7+d55pmZOzczb+4zy76enHuusdYiIiIiIhJoPG4HEBERERFxg4qwiIiIiAQkFWERERERCUgqwiIiIiISkFSERURERCQgqQiLiIiISEBytQgbY4YbY/YZY1ZlY98OxpilxpgMY8xNZ2xvYoxZYIxZbYxZYYzpl7epRURERKQocHtEeATQPZv7bgcGAmPP2Z4M3Gmtre9/r9eNMVG5lE9EREREiiifmx9urZ1jjKl65jZjTA3gHaA0Tsm911q7zlq71f961jnvsf6Mx7uMMfv8P3s4T8OLiIiISKHmahE+jw+AB6y1G4wxLYF3gauz84PGmCuBYGBTHuYTERERkSKgQBVhY0wE0Ab4whhzcnNINn+2PDAauMtam3Wx/UVEREQksBWoIowzZ/mwtbZJTn7IGBMJTAaes9YuzItgIiIiIlK0uH2y3FmstUeBLcaYmwGMo/GFfsYYEwx8BYyy1k7Ih5giIiIiUgQYa617H27MZ0AnIAbYCzwP/Ai8B5QHgoDPrbUvGGNa4BTeaCAF2GOtrW+MuQP4BFh9xlsPtNYuy6/fQ0REREQKH1eLsIiIiIiIWwrU1AgRERERkfyiIiwiIiIiAcm1VSNiYmJs1apV3fp4EREREQkQS5Ys2W+tLX3udteKcNWqVYmPj3fr40VEREQkQBhjtv3edk2NEBEREZGApCIsIiIiIgFJRVhEREREAlJBu8SyiIiIiJwjPT2dhIQEUlJS3I5SoIWGhhIbG0tQUFC29lcRFhERESngEhISKF68OFWrVsUY43acAslay4EDB0hISKBatWrZ+hlNjRAREREp4FJSUihVqpRK8AUYYyhVqlSORs1VhEVEREQKAZXgi8vpMVIRFhEREZGLioiIcDtCrlMRFhEREZGApCIsIiIiItlmreWpp56iQYMGNGzYkHHjxgGwe/duOnToQJMmTWjQoAFz584lMzOTgQMHntr3tddeczn92bRqhIiIiEgh8rdvVrNm19Fcfc96FSJ5vnf9bO07ceJEli1bxvLly9m/fz8tWrSgQ4cOjB07lm7duvHcc8+RmZlJcnIyy5YtY+fOnaxatQqAw4cP52ruy6URYRERERHJtnnz5nHbbbfh9XopW7YsHTt2ZPHixbRo0YJPPvmEv/71r6xcuZLixYtTvXp1Nm/ezMMPP8x3331HZGSk2/HPohFhERERkUIkuyO3+a1Dhw7MmTOHyZMnM3DgQB5//HHuvPNOli9fzrRp0xg2bBjjx49n+PDhbkc9RSPCIiIiIpJt7du3Z9y4cWRmZpKYmMicOXO48sor2bZtG2XLluXee+9l8ODBLF26lP3795OVlcWNN97Iiy++yNKlS92OfxaNCIuIiIhItl1//fUsWLCAxo0bY4zhP//5D+XKlWPkyJG8/PLLBAUFERERwahRo9i5cyd33303WVlZALz00ksupz+bsda68sFxcXE2Pj7elc8WERERKUzWrl1L3bp13Y5RKPzesTLGLLHWxp27b2CNCGdlQeoRMB7AOPfG/P7zk49FREREpEgKrCJ8dCe83iCHP2TOX5ZPPvf6wBsC3mDwBTv3J2++kDMeB0NQOAQXg+AI5xYS4X9eDIKLO/ehkRAWDWElITg8Dw6EiIiIiARWEQ4tAd1eAizYLLD++7Oe/9628z33P85Mh8xU5z4jFTLTTt8y0iD9iPN6Rhqkn4C0484tM+3imX2hEF7KKcXh/nJcLAYiykHxclC8/On78JIaxRYRERHJpgArwpHQ+kG3U5yWkeYvxUmn71OPQepRSD4IJw767w+dfr53NSQlQsrh376fN9gpyCViIboKRFd1blH+xxFlwaOFQkREREQg0IpwQeMLBl9JZyQ3p9JT4PgeOLYHju2GY3v997vh8A7YMgeWfw6ccTKkLxRK1YSYK6B0bYipBTG1nW1Bobn2a4mIiIgUBirChVVQ6OkR3/NJT4EjO+DQNji0BQ5thf3rYddSWP0Vp0qy8TijxmXrQ7lGUL4RlGsIkRU11UJERESKLBXhoiwo1D/qW+u3r6WfgAMbnWKcuB4S18HeVbBuMqcKcljJ06W4QjOodKUz7UJERESkCLhoETbGDAd6AfusteddcsEY0wJYANxqrZ2QexElTwSFOQW3XMOzt6ced+Yh71nh3HavgEXvnz6xr3gFqNQCKrWE2CudouwLyf/8IiIiUmBFRERw/Pjx331t69at9OrVi1WrVuVzqt/KzojwCOBtYNT5djDGeIF/A9/nTixxTUgEVG7p3E7KTIc9KyFhMez42bmt+dp5zRvijBRX6wjVOkDFZuANcie7iIiISA5ctAhba+cYY6peZLeHgS+BFrkRSgoYb5BTcCs2g5b3O9uO7fGX4kWwZTbMfBFm4qyNXKXN6WJctoFWqhAREclNU59xBqhyU7mG0ONf5335mWeeoVKlSjz00EMA/PWvf8Xn8zFz5kwOHTpEeno6L774In379s3Rx6akpDBkyBDi4+Px+Xy8+uqrXHXVVaxevZq7776btLQ0srKy+PLLL6lQoQK33HILCQkJZGZm8uc//5l+/fpd1q992XOEjTEVgeuBq7hIETbG3AfcB1C5cuXL/WhxU/FyUK+PcwNIOgBb5zqrVWyZDRv8fxyIKAe1usAV3aF6J2fEWURERAqVfv368dhjj50qwuPHj2fatGk88sgjREZGsn//flq1akWfPn0wOTjR/p133sEYw8qVK1m3bh1du3Zl/fr1DBs2jEcffZT+/fuTlpZGZmYmU6ZMoUKFCkyePBmAI0eOXPbvlRsny70OPG2tzbrYL26t/QD4ACAuLs5ecGcpXIqVgvrXOTeAIztPF+I1X8Mvo511jqu2d0rxFV0vvOKFiIiI/L4LjNzmlaZNm7Jv3z527dpFYmIi0dHRlCtXjv/7v/9jzpw5eDwedu7cyd69eylXrly233fevHk8/PDDANSpU4cqVaqwfv16WrduzT/+8Q8SEhK44YYbqFWrFg0bNuSJJ57g6aefplevXrRv3/6yf6/cKMJxwOf+EhwD9DTGZFhr/5cL7y2FVYmK0OR255aZDtsXwPppzm3qU86tdF1/eb7eWddYRERECqybb76ZCRMmsGfPHvr168eYMWNITExkyZIlBAUFUbVqVVJSUnLls26//XZatmzJ5MmT6dmzJ++//z5XX301S5cuZcqUKfzpT3/immuu4S9/+ctlfc5lF2FrbbWTj40xI4BvVYLlLN4gZ75wtQ7Q7R9wYJNTiNd9C7P+BbNegjL1oN51/lJ8hduJRURE5Bz9+vXj3nvvZf/+/cyePZvx48dTpkwZgoKCmDlzJtu2bcvxe7Zv354xY8Zw9dVXs379erZv307t2rXZvHkz1atX55FHHmH79u2sWLGCOnXqULJkSe644w6ioqL46KOPLvt3ys7yaZ8BnYAYY0wC8DwQBGCtHXbZCSTwlKrhXOq69YPOSXdrJjkX+Jj1Esz6p1OK618PjW7R9AkREZECon79+hw7doyKFStSvnx5+vfvT+/evWnYsCFxcXHUqVMnx+/54IMPMmTIEBo2bIjP52PEiBGEhIQwfvx4Ro8eTVBQEOXKlePZZ59l8eLFPPXUU3g8HoKCgnjvvfcu+3cy1rozVTcuLs7Gx8e78tlSQB3d5ZTiNf9zplIAVGkHTW6Den0hpLir8URERNyydu1a6tat63aMQuH3jpUxZom1Nu7cfbWulRQckRWg1QNwz3fw2Eq46k9wbBd8/RD89wqYeD9sngVZWW4nFRERkSJAl1iWgimqMnR8Cjo86axXvHwsrJoIKz6HyFho2h+aD3TKs4iIiBQ4K1euZMCAAWdtCwkJYdGiRS4l+i0VYSnYjDl9pbvu/4J1k2H5ZzD7PzDnv1DnWrjyXmdZthysWygiIiJ5q2HDhixbtsztGBekIiyFR1AYNLzJuR3cAvHDnfWJ106C0nWgxWBo1A9CI91OKiIikuustTm6WEUgyum5b5ojLIVTyWrQ9e/w+Fro+65Tkqc8Ca/WhalPw6GtbicUERHJNaGhoRw4cCDHRS+QWGs5cOAAoaGh2f4ZrRohRcfOJbDoA1j1JdhMqNsb2jwCsb85SVRERKRQSU9PJyEhIdcuWFFUhYaGEhsbS1BQ0Fnbz7dqhIqwFD1Hd8Gi9yH+E0g9ApVaQZuhULsneLxupxMREZF8puXTJHBEVoAuf4PHVzsn2B3bBePugLfj4OcPIS3Z7YQiIiJSAKgIS9EVUhxaDYGHf4GbR0BYtDOP+I3GMP8tSEtyO6GIiIi4SEVYij6vz7lk8+AZMHAKlK0H3/8JXm8E816H1ONuJxQREREXqAhL4DAGqraFO7+Ge76H8o3hh+fh9YYw9xUVYhERkQCjIiyBqXJLGDDRGSWOjYMZL8CbTWDBu5CuM3JFREQCgYqwBLbYOOj/BQyaDmXqwrQ/wlvNnBUnMtPdTiciIiJ5SEVYBKDSlXDXN3DnJGfViW8fc1aZWP45ZGW6nU5ERETygIqwyJmqd3RGh28f76w68dX98H4H2DzL7WQiIiKSy1SERc5lDFzRDe6bAzcNh9SjMKovjO0HievdTiciIiK5REVY5Hw8HmhwIzy0GDr/DbbNh3dbwZSnIPmg2+lERETkMqkIi1xMUCi0ewweXgrNB8Lij5wVJua/DRmpLocTERGRS6UiLJJdEaWh16swZD7EXgnfPwfvtIQ1k8Bat9OJiIhIDqkIi+RUmbpwxwS440vwhcL4ATCqDyT+6nYyERERyQEVYZFLVbMzPDAPrn0Fdi+H99rCD3+FtCS3k4mIiEg2qAiLXA6vD1oMhqFLoNEtMO81Z7rE2m80XUJERKSAUxEWyQ0RpeG6d+Hu7yAkEsbdAWNuhoOb3U4mIiIi56EiLJKbqrSG++dAt3/C9oXwTiuY9S+tLiEiIlIAqQiL5DavD1o/BEMXQ91eMOslGNbOKcYiIiJSYKgIi+SVyPLOlen6fwnpKTC8G0x+AlKOup1MREREUBEWyXu1OsODC6DVg7D4Y+dkunVT3E4lIiIS8FSERfJDSAR0fwkG/wBh0fD5bfDFQDi+z+1kIiIiAUtFWCQ/xcbB/bPh6j87o8Jvt4BfPtVSayIiIi5QERbJb94g6PAkDPkJytaHrx+CsbfA0d1uJxMREQkoKsIibompBXd9Cz1ehi1z4d1WsHKCRodFRETyiYqwiJs8Hmh5n3Op5pha8OUgZ+5w0gG3k4mIiBR5KsIiBUFMTeeqdNc8D+smO6PDv051O5WIiEiRpiIsUlB4fdD+cbhvFkSUhc9uhW//D9KS3U4mIiJSJKkIixQ05RrAvTOgzSMQPxze7wC7lrmdSkREpMhRERYpiHwh0PXvcOfXkHYcPuoMP70BWVluJxMRESkyVIRFCrLqnWDIfKjdHab/BUb10TJrIiIiuURFWKSgCy8Jt4yGPm/BziUwrB1s/MHtVCIiIoWeirBIYWAMNLsT7p0JxUrDpzfCjBcgM8PtZCIiIoWWirBIYVKmDtz7IzQdAHNfgZG94chOt1OJiIgUSirCIoVNcDj0fRuu/wB2L3emSmyY7nYqERGRQkdFWKSwatzPWXO4eHkYcxNMfx4y091OJSIiUmioCIsUZqWvcNYcbnYX/PQ6jLgWjiS4nUpERKRQUBEWKeyCwqDPm3Djx7B3tTNVYv00t1OJiIgUeCrCIkVFw5vgvtkQGQtjb4Hv/6ypEiIiIhegIixSlMTUhME/QNw9MP9N+KQnHN7hdioREZECSUVYpKgJCoVer8FNw2HfWl2AQ0RE5DxUhEWKqgY3wv2zIbIijLkZ5r0G1rqdSkREpMBQERYpykrVgMHToV5f+OGv8MVASD3udioREZECQUVYpKgLLgY3fQKd/wZrJ8HHXeHgZrdTiYiIuE5FWCQQGAPtHoP+E+DoTvjgKs0bFhGRgKciLBJIal7jXI2uRKzmDYuISMBTERYJNCWrwaDvod51mjcsIiIB7aJF2Bgz3Bizzxiz6jyv9zfGrDDGrDTGzDfGNM79mCKSq4KLOcurdXlB84ZFRCRgZWdEeATQ/QKvbwE6WmsbAn8HPsiFXCKS14yBto/CHV/CsV3w4dWwZa7bqURERPLNRYuwtXYOcPACr8+31h7yP10IxOZSNhHJDzWuhnt/hGJlYPR1sGSE24lERETyRW7PER4ETM3l9xSRvFayurPecPWr4JtHYerTkJnhdioREZE8lWtF2BhzFU4RfvoC+9xnjIk3xsQnJibm1keLSG4ILQG3j4PWQ2HRMBh7M5w47HYqERGRPJMrRdgY0wj4COhrrT1wvv2stR9Ya+OstXGlS5fOjY8Wkdzk8UK3f0Cft5z5wh91hgOb3E4lIiKSJy67CBtjKgMTgQHW2vWXH0lEXNfsTrjzazhx0DmJbvMstxOJiIjkuuwsn/YZsACobYxJMMYMMsY8YIx5wL/LX4BSwLvGmGXGmPg8zCsi+aVqW+ckuuLlYfQNsPgjtxOJiIjkKmNduqpUXFycjY9XZxYp8FKOwsR7Yf130Ooh6Pp3ZwqFiIhIIWGMWWKtjTt3u64sJyIXFhoJt46Flg/Awndg/J2Qlux2KhERkcumIiwiF+fxQo9/Q/d/wbrJMLIXHNfKLyIiUripCItI9rUaAv0+hb1r4KNrIFHnx4qISOGlIiwiOVO3FwycDOnJ8HEX2DrP7UQiIiKXREVYRHIutjkM/gEiysCo62DVl24nEhERyTEVYRG5NNFVYdD3EBsHEwbBovfdTiQiIpIjKsIicunComHAV1C7J0z9A8x4AVxaklFERCSnVIRF5PIEhcEto5yr0c19BSY9DJkZbqcSERG5KJ/bAUSkCPD6oPebEFEW5rwMyQfgpuFOSRYRESmgNCIsIrnDGLj6T9DjZfh1Koy+Hk4ccjuViIjIeakIi0juanmfMxq8cwkM7wFHd7mdSERE5HepCItI7mtwA/SfAEcS4OOuuvCGiIgUSCrCIpI3qneEgd9CRgoM7wYJ8W4nEhEROYuKsIjknQpNnLWGQyNhZG/YMN3tRCIiIqeoCItI3ipZHQZNh1I14bNbYdlnbicSEREBVIRFJD9ElIGBk6FKG/jfA/DTm24nEhERUREWkXwSGumcQFfvOpj+Z5j2HGRluZ1KREQCmC6oISL5xxfiLK02tTQseBuSEqHvO+ANcjuZiIgEIBVhEclfHi/0fNm5Ct3MF52r0N0yCoKLuZ1MREQCjKZGiEj+MwY6PgW934BNPzorSiQdcDuViIgEGBVhEXFP84Fwy2jYu9pZa/hIgtuJREQkgKgIi4i76vaCAV/B8b3OJZkPbnY7kYiIBAgVYRFxX5U2cNckSDvulOF9a91OJCIiAUBFWEQKhgpN4e4pzuNPesKuX9zNIyIiRZ6KsIgUHGXqOmU4OAJG9oFtC9xOJCIiRZiKsIgULKVqwD1TnavRjb7eWVVCREQkD6gIi0jBUyIW7p7qlOKx/WDdZLcTiYhIEaQiLCIFU0QZuOsbKNcQxg2AFV+4nUhERIoYFWERKbjCS8KdXzurSky8F+I/cTuRiIgUISrCIlKwhRSH/l9Azc7w7WMw/y23E4mISBGhIiwiBV9QGNw6Fur1he//BLP+Bda6nUpERAo5n9sBRESyxRcMNw6HoIdh1kuQlgRdXgBj3E4mIiKFlIqwiBQeXh/0fccZIZ7/JmSkQo9/qwyLiMglUREWkcLF44FrXwFfCCx8FzJT4drXnO0iIiI5oCIsIoWPMdDtn04ZnvcaZKRB37fB43U7mYiIFCIqwiJSOBkD1zwPvlBnznBmKlz/PniD3E4mIiKFhIqwiBRexkCnZ8AbDDP+Bplpzgl1vmC3k4mISCGgSXUiUvi1fxy6vQRrv4Fxd0B6ituJRESkEFARFpGiofWDcO2rsGEafH4bpCW7nUhERAo4FWERKTpaDHKWV9s0E8beAqnH3U4kIiIFmIqwiBQtTe+AGz6EbfPh0xsg5YjbiUREpIBSERaRoqfRzXDTcNi5BEb1heSDbicSEZECSEVYRIqm+tdBv09h72oY2QeSDridSEREChgVYREpumr3gNs+gwMbYJTKsIiInE1FWESKtpqd4daxcGCjyrCIiJxFRVhEir6a16gMi4jIb6gIi0hgUBkWEZFzqAiLSOBQGRYRkTOoCItIYFEZFhERPxVhEQk8KsMiIoKKsIgEKpVhEZGApyIsIoFLZVhEJKCpCItIYDurDPdVGRYRCSAXLcLGmOHGmH3GmFXned0YY940xmw0xqwwxjTL/ZgiInnoVBneoDIsIhJAsjMiPALofoHXewC1/Lf7gPcuP5aISD5TGRYRCTgXLcLW2jnAwQvs0hcYZR0LgShjTPncCigikm9UhkVEAkpuzBGuCOw443mCf5uISOGjMiwiEjDy9WQ5Y8x9xph4Y0x8YmJifn60iEj2qQyLiASE3CjCO4FKZzyP9W/7DWvtB9baOGttXOnSpXPho0VE8ojKsIhIkZcbRXgScKd/9YhWwBFr7e5ceF8REXepDIuIFGnZWT7tM2ABUNsYk2CMGWSMecAY84B/lynAZmAj8CHwYJ6lFRHJb+eW4eQLnTssIiKFibHWuvLBcXFxNj4+3pXPFhHJsY0z4LPboHRtuGsShEW7nUhERLLJGLPEWht37nZdWU5EJDtqXgO3joHEdTD6ejhx2O1EIiJymVSERUSyq1YXuGU07FkFn94AKUfcTiQiIpdBRVhEJCdqd4dbRsHu5fDpjZBy1O1EIiJyiVSERURyqk5PuHkE7PoFxtwEqcfcTiQiIpdARVhE5FLU7Q03fgwJ8TDmFkg97nYiERHJIRVhEZFLVf86uPFD2LEQxvaDtCS3E4mISA6oCIuIXI4GN8L1H8D2+fDZrZCW7HYiERHJJhVhEZHL1ehmuG4YbJkLn98G6SfcTiQiItmgIiwikhsa94Pr3oXNs+Hz/pCe4nYiERG5CBVhEZHc0uR26PMWbJoB4wdARqrbiURE5AJUhEVEclOzAdDrddjwPYy/CzLS3E4kIiLnoSIsIpLb4u6Ga1+B9VPhi4GQme52IhER+R0qwiIieaHFYOjxMvw6GSbcrTIsIlIAqQiLiOSVlvdB93/B2m/gy8GQmeF2IhEROYPP7QAiIkVaqyGQlQnfPwcer7PmsFf/9IqIFAT611hEJK+1GQpZGfDD82C8cP0wpxSLiIirVIRFRPJDu8fAZsKMF5wS3PcdlWEREZepCIuI5Jf2TzjTJGb+wxkZ7vMWeHSqhoiIW1SERUTyU8c/OGV49r+cEtzrDZVhERGXqAiLiOS3Ts84c4bn/tcZGe71GhjjdioRkYCjIiwikt+Mgav/5MwZnveaM1e4539VhkVE8pmKsIiIG4yBa553RobnvwUen7PmsMqwiEi+UREWEXGLMdDl75CVBQvfcaZJdPuHyrCISD5RERYRcZMxTvm1mU4Z9niccqwyLCKS51SERUTcZowzLSIr8/Q0iWueVxkWEcljKsIiIgWBMdDz5dMn0IHKsIhIHlMRFhEpKIyBnq84j+e9BjYLOv9NZVhEJI+oCIuIFCQej78MG/jpDbAWurygMiwikgcCqggfTUln2KxNeIzBGDDGYOD0c8Djcf7P5uQ2jwHD6f09Z+xn8L+Hcfb3egzBXg/BPg9Bp+4NIT4PwV4vQT7n9SCvhxCfh5AgL8WCvfi8uqqUiJzB44FrXwHjgflvOiPDXV9UGRYRyWUBVYSPp2Tw4dzNWAtZ1mJxBlvcFuLzUCzER3iwlwj/fbEQH8WCfYSHeIkMDSI6PJio8CCiwk8/PnkfEeLD6P8gRYqWk3OGjYEFbzv/WGlpNRGRXBVQRbhCVBgb/tHzN9uttWTZM+6xWMtZhTnLntxmT20/c98sa8nMsqRlZJGe6dynZWb5n59x73+clplFSnoWSakZJKVlkJyaefpxWibHUzPYdzSV46kZHE1J51hKxnl/L5/HEBMRQtnIEEoXD6VsZAhlTt77H1eMCiMqPEiFWaQwMQZ6/McZGV74DmCh2z9VhkVEcklAFeHzMcbgNeBMeiiY0jOzOHIincPJ6RxOTuOQ//5wcjqHktNIPJbKvmOpJBxKZun2QxxMSvvNe0SE+IiNDqNSyXAqRYdTqWSY/955HB6sr4NIgXNyaTUMLHzXmSahK9CJiOQKNZ9CIsjrISYihJiIkGztn5aRReLxVPYdTWHv0RQSDp0g4dAJdhxMZtuBJOZt2M+J9MyzfqZCiVBqlImgRukIap5xHxMRrJFkETcZA91fOj0ybC30+LfKsIjIZVIRLqKCfR4qRoVRMSrsd1+31nIgKY0dB5PZcegE2/YnsXl/Ehv3HWd8/A6S006X5MhQH7XKFqde+UjqVYikfoVIrihbnNAgb379OiJy8gp0p+YMZ52eQywiIpdERThAGWNOjTA3rRx91mvWWnYfSWFT4nE27jvOpsTjrN9znP/9spPRC7cB4PUYapaOOFWMG1YsQaPYKMKCVY5F8owxp1ePmP+Wvwz/11llQkREckxFWH7DGEOFqDAqRIXRvlbpU9uzsiw7DiWzZtdRVu86yupdR5i/aT9f/bITcE7aq1s+kmaVo2hWJZpmlaOJjQ7TtAqR3GQMdPm7M03ipzcA66w7rDIsIpJjKsKSbR6PoUqpYlQpVYweDcuf2p54LJXlOw6zdPshlm4/xPj4BEYucEaOYyJCiKsSTavqJWlVoxRXlCl+aq1mEblExvivOOfxX4HOwrWvqgyLiOSQirBcttLFQ+hcryyd65UFICMzi3V7jvHL9kMs3X6YxVsP8t3qPQBEhQfRslpJWlYrResapahTrrhGjEUuhTFwzfOAgXmvOtMker2uMiwikgMqwpLrfF4PDSqWoEHFEgxo7WzbcTCZRVsOsmjzARZuOcC01XsBKFM8hA5XlKbDFaVpXzOG6GLBLiYXKWSMgWv+4owMz/2vU4Z7v6kyLCKSTSrCki+ctYrDual5LAA7D5/gp437mbM+kR/W7mXCkgSMgUaxUXSsFUPH2qVpUikar6ZRiFyYMXD1n5wyPOc/gIXeb6kMi4hkg7EuXWM4Li7OxsfHu/LZUrBkZllWJBxmzvr9zF6/j2U7DpNloVSxYK6pW4au9crRrlaMlmsTuRBrYdZLMPvf0KQ/9HkLPPrfjIgIgDFmibU27jfbVYSloDmSnM7sDYlMX7OXWev2cSw1g7AgL+1rxdClXlmuqVuWkppCIfL7Zv3LKcSNb4e+b6sMi4hw/iKsqRFS4JQID6JP4wr0aVyBtIwsFm05wPQ1e5m+Zi/fr9mLx0DLaqXo3bgCPRqU07xikTN1egYwMOufzpzh695VGRYROQ+NCEuhYa1l1c6jTF+zh29X7mZzYhI+j6F9rRj6NKlAl3rliAjRf9uJADD7PzDzH9CoH1z3nsqwiAQ0TY2QIsVay+pdR/lmxS6+Xb6bnYdPEOLz0LluWW5oVpEOV5QmyKuThSTAzXkZfnwRGt4M1w0Dr/5DUUQCk6ZGSJFijDm1RNvT3eqwdPshJi3fxbcrdjN55W5iIoLp26QiNzaLpV6FSLfjirijw1POahIzXnBOprv+fZVhEZEzaERYipS0jCxm/bqPL5cm8OO6faRnWuqWj+TGZhW5rmlFYiJC3I4okv/mvQY//BUa3AjXf6AyLCIBR1MjJOAcTErjm+W7mLAkgZU7jxDkNXSpV5ZbW1SmXc0YXepZAsu81+GH56H+9XDDRyrDIhJQNDVCAk7JYsHc1aYqd7Wpyvq9xxi3eAdfLk1gyso9xEaH0S+uErdeWZnSxTVKLAGg3WPONInpf3amSdz4EXiD3E4lIuIqjQhLQElJz2Ta6j2MW7yD+ZsOEOz10KtReQa2rUqj2Ci344nkvflvw/fPQb2+cOPHKsMiEhA0IiwChAZ56dukIn2bVGTjvuOMWrCVL5ckMPGXnTSrHMXAttXo0aCcVpyQoqvNUOeyzNOeddYZvukTlWERCVgaEZaAdzQlnQnxCYxcsJVtB5IpGxlC/5ZVuE3TJqQoW/gefPcM1OnllGGfLkwjIkWXTpYTuYisLMus9fsYMX8bc9YnOtMmGpfn7jbVaBhbwu14Irlv4TD47mmofS3cPEJlWESKLBVhkRw4OW1iwpIEktMyaVmtJA9eVZMOtWIwRqtNSBGy6AOY+hTU7gk3j1QZFpEi6bKKsDGmO/AG4AU+stb+65zXKwMjgSj/Ps9Ya6dc6D1VhKUwOJqSzvjFO/ho7hb2HE2hXvlIhnSqQc+G5fFq+TUpKn7+EKY8CVf0gFtGgk9TgkSkaLnkImyM8QLrgS5AArAYuM1au+aMfT4AfrHWvmeMqQdMsdZWvdD7qghLYZKWkcX/ftnJsDmb2JyYRJVS4dzfoQY3NKtIaJDX7Xgil2/xRzD5CajZGW4ZDcHhbicSEck15yvC2Tk1/kpgo7V2s7U2Dfgc6HvOPhY4eR3bEsCuywkrUtAE+zzc0qIS0/+vI8PuaEaJsCCe/Wol7f8zk2GzN3EsJd3tiCKXp8Vg6PMWbJwBY26ClKNuJxIRyXPZGRG+CehurR3sfz4AaGmtHXrGPuWB74FooBjQ2Vq75Hfe6z7gPoDKlSs337ZtW279HiL5ylrLgk0HeHfWJuZt3E/xUB/3tK3GPe2qUSJMS1FJIbZyAnx1P5RrBHd8CeEl3U4kInLZLmdEODtuA0ZYa2OBnsBoY8xv3tta+4G1Ns5aG1e6dOlc+miR/GeMoU3NGD4d3JJJQ9vSpkYp3pixgfb//pE3Z2zQCLEUXg1vcqZG7F0FI3rB8X1uJxIRyTPZKcI7gUpnPI/1bzvTIGA8gLV2ARAKxORGQJGCrlFsFO8PiOPbh9txZbVSvDp9Pe3/M5N3Zm7keGqG2/FEcq5OT7h9PBzaAsO7w5EEtxOJiOSJ7BThxUAtY0w1Y0wwcCsw6Zx9tgPXABhj6uIU4cTcDCpS0DWoWIKP7opj0tC2NKsczcvTfqX9v3/kvVmbSFIhlsKmxlUw4CtISoThPeDAJrcTiYjkuuwun9YTeB1nabTh1tp/GGNeAOKttZP8K0V8CETgnDj3B2vt9xd6T60aIUXdsh2HeW36emavT6RUsWCGdKrBHa2qaJUJKVx2LYPR1zuXYb7zayhT1+1EIiI5pgtqiLhkybZDvDZ9PfM27qdCiVAe71qb65tW1DrEUnjsWwujroPMNBgwESo0dTuRiEiO5PXJciJyHs2rRPPp4JaMGdySmOIhPPnFcnq+MZcZa/fi1n+IiuRImbpwz1QIjoCRfWDbArcTiYjkChVhkXzStmYMXz/Ulndub0ZqRiaDRsbT7/2FLNl2yO1oIhdXsrpThiPKwKc3wKaZbicSEblsKsIi+cgYw7WNyjP98Y68eF0DNu9P4sb35nPfqHg27jvmdjyRCysRC3dPhehqMPYWWDfZ7UQiIpdFc4RFXJSclsHweVsYNnszJ9IzGdCqCo91rkVUeLDb0UTOL/mgc/W5Xcvghg+ctYdFRAowzREWKYDCg30MvboWc/5wFbddWYlRC7bS6b+zGDl/KxmZWW7HE/l94SWdFSQqt4IvB8OSkW4nEhG5JCrCIgVAyWLBvHhdQ6Y82p565SN5ftJqerwxl7kbtBy3FFAhxaH/BKh5DXzzCCx41+1EIiI5piIsUoDUKRfJmMEteX9Ac1Izshjw8c8MHrmYLfuT3I4m8lvB4XDrWKjbG6b9EWb/B7QSiogUIirCIgWMMYZu9csx/fEOPNOjDgs2HaDra7P555S1umSzFDy+ELhpBDS6FWb+A6b/RWVYRAoNFWGRAirE5+WBjjWY+VQnrmtSkQ/mbOaaV2bxzfJdWn9YChavD657D+LugflvwuQnIEtz3EWk4FMRFingyhQP5eWbGzPxwTaULh7Cw5/9Qv+PFmm5NSlYPB649lVo8wjEfwxfPwiZ+guGiBRsKsIihUSzytF8/VA7/t63Pqt2HqH763N5aepakjRdQgoKY6DLC3DVc7D8Mxg/ANJPuJ1KROS8VIRFChGvxzCgdVV+fLIT1zetyPuzN9P51dlMXrFb0yWkYDAGOv4BerwMv06FT2+ElCNupxIR+V0qwiKFUExECC/f3Jgvh7QmOjyYh8YuZcDHP2t1CSk4Wt4HN34EOxbBiGvh+D63E4mI/IaKsEgh1rxKSSYNbcvf+tRnecJhur0+h3dmbiRdF+OQgqDhTXD7ODiwCT7uCge3uJ1IROQsKsIihZzP6+GuNlWZ8XhHrqlThpen/Urvt+bxy/ZDbkcTgZqd4c5JkHIYhneDPavcTiQicoqKsEgRUSYylPfuaM4HA5pzODmdG96bz18nrdbaw+K+Si3g7u/AeGFET9i2wO1EIiKAirBIkdPVfzGOAa2qMHLBVrq+Opsf1+11O5YEujJ1YNA0KFYaRvWFNV+7nUhEREVYpCgqHhrEC30bMOGB1hQL8XHPiHiGjl1K4rFUt6NJIIuqDPd8D+Ubw/i7YME7ugqdiLhKRVikCGtepSSTH2nP412u4PvVe7nmlVmMj9+hpdbEPcVKwV2ToG5vmPYsTH0asjLdTiUiAUpFWKSIC/Z5eOSaWkx5tD11ykXyhwkruGfEYvYcSXE7mgSqoDC4eSS0Hgo/vw/jBkBastupRCQAqQiLBIiaZSL4/L5WPN+7Hgs2H6Dra7OZuDRBo8PiDo8Huv0DevwHfp0CI3vB8US3U4lIgFERFgkgHo/h7rbVmPpoB64oW5zHxy/n3lFL2HdMo8Pikpb3w61jYO8a+Oga2L/B7UQiEkBUhEUCULWYYoy7vzV/urYuczck0vW1OXy9bKdGh8Udda6FgZMhLQk+7qLl1UQk36gIiwQor8cwuH11Jj/SnqqlivHo58t44NMlWllC3BHbHAb/AOExzvJqqya6nUhEAoCKsEiAq1kmgi+HtOGZHnWYuS6Rrq/N5tsVu9yOJYGoZDUY9D1UbAYT7oZ5r2t5NRHJUyrCIoLXY3igYw0mP9KOSiXDGTr2Fx4as5QDxzU6LPksvCQM+B/UvwF+eB4mPwGZujqiiOQNFWEROaVW2eJMHNKGp7rV5vs1e+j62hy+W7Xb7VgSaIJC4caPoe2jEP8xjOvvzB8WEcllKsIichaf18NDV9Xkm4fbUT4qlAc+Xcojn/3CoaQ0t6NJIPF4oMsLcO0rsOF7+KQnHNOlwkUkd6kIi8jvqlMukq8ebMvjXa5gysrddHltDtPXqIhIPmsxGG79DPavh486Q+KvbicSkSJERVhEzivI61yV7uuhbSldPIR7R8Xzx4krSU7TnE3JR7W7O8urZaQ4y6ttned2IhEpIlSEReSi6lcowdcPteX+DtX57Oft9HprHqt2HnE7lgSSis2c5dUiysGo62DFF24nEpEiQEVYRLIl2Ofhjz3rMmZwS5JSM7j+3Z/4YM4msrK0vJXkk+gqMGgaVGoJEwfD3Fe0vJqIXBYVYRHJkbY1Y/ju0Q5cVbsM/5yyjjuH/8zeo7pEs+STsGgYMBEa3gwzXoBvHtXyaiJyyVSERSTHoosF8/6A5vzz+obEbztI99fn8P3qPW7HkkDhC4EbPoT2T8LSkfBZP0g95nYqESmEVIRF5JIYY7i9ZWW+fbg9FaLCuG/0Ep79aiUn0jLdjiaBwBi45s/Q+w3YNBM+6QFHtea1iOSMirCIXJaaZSKY+GAb7u9QnbGLttPrrbms3X3U7VgSKJoPhNvHwcEt8OFVsGOx24lEpBBRERaRyxbi8546ke5YSgZ93/mJsYu2Y3Uik+SHWl3gnmngDYYRPWHJSLcTiUghoSIsIrmmbc0YpjzanpbVSvLsVyt55PNlHEtJdzuWBIJyDeC+WVC1HXzzCHzzGGSkup1KRAo4FWERyVUxESGMvPtKnupWm8krdtFbaw5LfgkvCf0nQLv/gyWfwIhemjcsIhekIiwiuc7jMTx0VU0+u7cVJ9IzueG9+YxeuE1TJSTvebzQ+a9w8wjYuxo+6AjbF7mdSkQKKBVhEckzLauXYsoj7WldvRR//t8qhn72C0c1VULyQ/3rnSvRBYXDiGshfrguviEiv6EiLCJ5qlRECJ8MbMHT3evw3ao99H5rHisTNFVC8kHZenDfTKjeCb79P2fusOYNi8gZVIRFJM95PIYhnWow7r5WpGVkceN78xk5f6umSkjeC4t2lldr/yQsHQWf9ISju9xOJSIFhIqwiOSbuKolmfJIe9rViuH5Sat5cMxSjpzQVAnJYx6vc/GNW0ZD4jp4vyNsm+92KhEpAFSERSRfRRcL5qM743i2Zx2mr9lLr7fmsiLhsNuxJBDU6wODZ0BIcRjZG37+UPOGRQKcirCI5DuPx3BfhxqMu781mZmWG9+bz/B5WzRVQvJemTpw749QszNMeRK+fgjST7idSkRcoiIsIq5pXiWaKY+2p+MVpXnh2zXcP3oJR5I1VULyWFgU3PoZdHwalo2BjzrD/o1upxIRF6gIi4irosKD+fDOOP50bV1+XLePa9+ay7Idh92OJUWdxwNXPetcgOPoLme94VVfup1KRPKZirCIuM4Yw+D21fnigdZYCze9N5+P5m7WVAnJe7W6wANzoWx9mHAPfPs4pKe4nUpE8omKsIgUGE0rRzPlkfZcXacML05ey72jlnA4Oc3tWFLUlYiFgZOhzcMQ/zF83AUObnY7lYjkAxVhESlQSoQH8f6A5jzfux6z1+/j2jfnsWTbIbdjSVHnDYKuLzpzhw9vg2EdYMV4t1OJSB5TERaRAscYw91tqzHhgTZ4PNDv/QV8MGcTWVmaKiF5rE5PuN8/VWLivfDlvZCiKyGKFFUqwiJSYDWuFMW3D7enS72y/HPKOgaPiudQkqZKSB6LruJMlej0R1g1AYa1g+2L3E4lInkgW0XYGNPdGPOrMWajMeaZ8+xzizFmjTFmtTFmbO7GFJFAVSIsiHf7N+OFvvWZt2E/vd6apwtwSN7z+qDTM3D3d87zT3rArH9DZoa7uUQkV120CBtjvMA7QA+gHnCbMabeOfvUAv4ItLXW1gcey/2oIhKojDHc2boqXzzQGoCb3lvAZz9v16oSkvcqt4QH5kGDG2HWP2FETzi4xe1UIpJLsjMifCWw0Vq72VqbBnwO9D1nn3uBd6y1hwCstftyN6aIiDNV4puH29Gyekn+OHElf5iwgpT0TLdjSVEXWgJu/BBu+Aj2rXOmSiwdrcszixQB2SnCFYEdZzxP8G870xXAFcaYn4wxC40x3XMroIjImUoWC2bE3VfyyNU1+WJJAje+N5/tB5LdjiWBoNHNMOQnqNAUJg2FcXdA0n63U4nIZcitk+V8QC2gE3Ab8KExJurcnYwx9xlj4o0x8YmJibn00SISaLwew+NdazN8YBw7DibT6625zFynP0RJPoiqBHdOgq7/gA3fw7utYf00t1OJyCXKThHeCVQ643msf9uZEoBJ1tp0a+0WYD1OMT6LtfYDa22ctTaudOnSl5pZRASAq+uU5duH2xMbHc7dIxbz6vT1ZGqJNclrHg+0GQr3zYKIMjD2Fvj2/yAtye1kIpJD2SnCi4Faxphqxphg4FZg0jn7/A9nNBhjTAzOVAldlkdE8lzlUuFMfLANNzeP5c0ZG7h7xGItsSb5o2x9uPdHaPMIxH8Cw9pDQrzbqUQkBy5ahK21GcBQYBqwFhhvrV1tjHnBGNPHv9s04IAxZg0wE3jKWnsgr0KLiJwpNMjLf25qxEs3NGThpgP0fnseq3bqIgiSD3wh0PXvMPBbyEyDj7vCzJcgM93tZCKSDcat5Yfi4uJsfLz+y1lEcteyHYd58NMlHEhK48XrGnBzXKWL/5BIbkg5AlP+ACs+h4rN4foPIKam26lEBDDGLLHWxp27XVeWE5EipYl/ibXmVaJ5asIKnvtqJakZWmJN8kFoCbjhfbh5BBzYBO+3h8Ufa5k1kQJMRVhEipxSESGMuudK7u9YnTGLttPv/YXsPnLC7VgSKOpfDw8ugMqtYPLjMOZmOLzd7VQi8jtUhEWkSPJ5PfyxR13e69+MDXuP0futeSzYpFMXJJ9EVoD+X0KP/8C2n+DtK2HOfyEj1e1kInIGFWERKdJ6NCzP10PbUiIsiDs+XsSHczbr0sySPzweaHk/DF0MtbrAj3+H99rAph/dTiYifirCIlLk1SxTnK+HtqNrvbL8Y8pahn72C0mpGW7HkkBRIhb6jYY7vnTmC4++HsbfBUfOXZJfRPKbirCIBISIEB/v9m/GMz3qMHXlbm54dz5b9+sCCJKPanZ25g5f9SdY/x283QJ+egMytO61iFtUhEUkYBhjeKBjDUbecyV7j6XQ++15/Lhur9uxJJD4QqDjU/DQz1C9I0z/CwxrB1vmuJ1MJCCpCItIwGlfqzTfDG1HpehwBo2M540fNpClSzNLfoquArd9BreNg4wUGNkbJgyCY3vcTiYSUFSERSQgVSoZzpdD2nBdk4q89sN67hu9hKMpuhqY5LPa3eGhRdDxGVj7DbwVBwvegUzNYRfJDyrCIhKwwoK9vHpLY/7aux6zft1H37d/YsPeY27HkkATFAZX/fH02sPTnoX3WsO6yboYh0geUxEWkYBmjGFg22qMGdySYynp9H3nJ6as3O12LAlEpWpA/y/g1s+cAvz57fBJD9ix2O1kIkWWirCICNCyeim+fbg9V5QtzoNjlvKvqevI1LxhyW/GQJ2e8OBC6PUaHNwMH3eGcQNg/0a304kUOSrCIiJ+5UqEMu7+VtzesjLDZm/iruE/czBJS1uJC7w+iLsHHl4KnZ51LsLxbkuY/AQc3+d2OpEiw7h1haW4uDgbHx/vymeLiFzMuMXb+fP/VlO6eAjvD2hOg4ol3I4kgez4Ppj9b1gyAnyh0PZRaP0QBBdzO5lIoWCMWWKtjTt3u0aERUR+R78WlfnigdZkWcuN783nyyUJbkeSQBZRBq59BR5cBDWuhpn/gDebws8f6oIcIpdBRVhE5DwaV4rim4fb0bRyFE98sZy/fL2KtIwst2NJIIup6VyuedB0KFULpjwJbzeHZWMhK9PtdCKFjoqwiMgFxESE8OmglgxuV41RC7bR/6OF7DuW4nYsCXSVroSB38IdEyGsJPxvCLzbGtZM0pJrIjmgIiwichE+r4c/9arHG7c2YeXOI/R+ax5Ltx9yO5YEOmOg5jVw3yy4ZRRgYfwA+KATbJyhQiySDSrCIiLZ1LdJRSYOaUuwz0O/9xcwdtF2tyOJOIW4Xl8YsgD6vgvJB+HTG2BEL9i+yO10IgWairCISA7UqxDJN0Pb0ap6KZ79aiV/nLiC1AzNzZQCwOuDpv3h4Xjo8TLsXw/Du8KYW2DXL26nEymQtHyaiMglyMyyvPL9r7w7axNNKkUx7I7mlCsR6nYskdPSkmDR+/DT65ByBKq0dZZcu6I7eLxupxPJV+dbPk1FWETkMkxduZsnvlhOeLCPd/s348pqJd2OJHK2lCOwdDQsGgZHdkDJ6tDqQWjSH4LD3U4nki+0jrCISB7o0bA8/3uoLcVDfdz+4UJGzt+KWwMMIr8rtAS0GQqPLIObPoGwaGfZtdfqw8yXdKU6CWgaERYRyQVHTqTz+LhlzFi3jxuaVeSf1zckNEh/fpYCyFrYvhB+egPWTwVvMDS4CVo9AOUbu51OJE9oaoSISB7LyrK8MWMDb8zYQIOKkQy7ozmx0frTsxRg+zc6UyaWjYX0JKjcGloNgTq9NI9YihQVYRGRfDJ9zV4eH7eMIJ+Ht29rSpuaMW5HErmwE4dh2Rjn5LrD2yC6KrR6CBrfCqGRbqcTuWwqwiIi+WhT4nHuH72EzYnHebZnXQa1q4Yxxu1YIheWlQnrvoWf3oSd8RAcAY1ugbhBUK6B2+lELpmKsIhIPjuemsGT45fz3eo99GlcgX/f2IiwYP25WQoBa2HnUoj/GFZ9CRkpUKkVtBgM9fqAL8TthCI5oiIsIuICay3vztrEf7//ldpli/PBgDgql9K8YSlEkg86c4jjP4aDmyE8BprcBo1u1SixFBoqwiIiLpr16z4e+ewXjDG8eVtTOl5R2u1IIjmTlQVbZsHij2H9d5CVAWXqO1MnGt4EJWLdTihyXirCIiIu23YgiftHL+HXvcd47JorePjqmng8mjcshVDSAVjzFawYDzsWAQaqtnNKcd0+EBbldkKRs6gIi4gUACfSMnnuq5VM/GUnnWqX5rVbmhBdLNjtWCKX7uBmWDkBln8OBzeBNwRqd4dG/aBmF/Dp+y3uUxEWESkgrLWMWbSdF75ZQ+niIQy7ozkNY0u4HUvk8lgLu5Y6o8QrJ0DyfucqdvX6Qp3eUK29TrIT16gIi4gUMMt2HOahMUtJPJbK3/rW59YWlbTEmhQNmemweZYzSrz+O0g7DsHFoVZn52Idtbo4l34WyScqwiIiBdDBpDQe/fwX5m7Yz03NY3nxuga6NLMULekpsGWOsz7xr1MgKRE8Qc4Ice2eTimOrup2SiniVIRFRAqoTP+lmd+csYG65SMZdkczqpQq5nYskdyXlQkJ8fDrZFj7rTOnGCDmCmc+ca3OUKWtplBIrlMRFhEp4Gau28dj45aRZS2v3tKELvXKuh1JJO9YCwc2wobpsHE6bP0JMlMhKByqdXBGimt2gegqbieVIkBFWESkENhxMJkHxyxl5c4jPNipBo93uQKf1+N2LJG8l5YEW+edLsaHtjrbT44W17gKKl2pucVySVSERUQKiZT0TP72zWo++3kHbWqU4s3bmhIToT8VSwCxFg5sgg3fnz1ajIGy9aFyK6jc2rnXhTwkG1SERUQKmfHxO/jz/1YRHR7MO/2b0bxKtNuRRNyRlgw742H7Qti+AHb87KxEARAZ6y/G/nJcpi54dMKpnE1FWESkEFq96whDPl3KrsMn+NO1dbmrTVUtsSaSmQH7Vp8uxtsXwrHdzmshkc4UikqtoGJTKN8EisW4GlfcpyIsIlJIHUlO54kvlvHD2n30blyBf93QkGIhPrdjiRQc1sLh7WcX48S1p1+PjIXyjaFCU6jYzLmF6S8sgURFWESkEMvKsrw3exOvfP8rNUpH8N4dzalZJsLtWCIF14nDsGcF7F7u3HYtgwMbTr8eXQ3KNfTfGjlFuXg50F9ciiQVYRGRImDehv088vkvpKZn8p+bGnNto/JuRxIpPFKOwK5fnLWMdy+Hvavg4ObTrwcXh1I1oFRN/60GlKzhLOEWXkoluRBTERYRKSJ2HznBg2OW8sv2wwxqV41netQhSEusiVya1GOwdzXsXuGsa3zydng7cEZHCo6AqMoQVcUpxlGVTz+PqgxhUW79BpINKsIiIkVIWkYW/5yylhHzt9KiajRv396MspGhbscSKTrSU5y1jA9ugkPb4PA2pxwf3u48Tzt29v4hJSD6jGIcVdlZ2i2yIpSo5JywpxFl16gIi4gUQV8v28kzX66kWIiPt29vSqvqpdyOJFL0WQsnDp0uxidL8qFtp5+nJ5/9M94QKFHRX45jnfsSsc62YmWcC4WERTnTMzz6C09uUxEWESmi1u89xgOjl7DtYDJ/6Fab+zpU1xJrIm6yFpIPwtEEOHKe2/E9YLN++7PG45Ti8BgoVtoZSS5W+ozHMf7XYpx5y75Q8AaDL0QjzhegIiwiUoQdS0nn6S9XMGXlHrrVL8vLNzcmMjTI7Vgicj6Z6c7ax0cSIGm/cyLfyduJg862pP2QlAhJ+5wR6AsyEFzMuYUUd8p0SCSERp5+7AuFoFDncVhJZ7/gcP/PRDrPQyIhKKzIlWoVYRGRIs5ay8fztvDS1HXERofx9m3NaBhbwu1YIpIbMjMg+QAk+wty8n5n1DkjBTJSnVtakjN3OfWYv1QfhdSjzuPU45Bx4vdHoc/l8TmFOLiYU4p9oc59UBj4ws54fMb2U6+FQlC4/7Vw5/mZPxNVGbz5/x/pKsIiIgFi8daDPPLZLxw4nsazPevoanQi4rDWGYlOPeaU6rRjzuWr05KcS1anHPEXZ3+BTj/hzHVOT3HuM1JOPz/zcXoyZ62wcSGPrYKoSnn6a/6e8xVhXZpIRKSIaVG1JFMeac+TXyznr9+sYf6mA7x8U2NKhGuqhEhAMwZ8weArBcVy8cRaayEz7XdK8+8U6AJ2uWuNCIuIFFEnp0r8a+o6ykaG8tbtTWlWWZeVFZHAc74R4Wytz2GM6W6M+dUYs9EY88wF9rvRGGONMb/5IBERyV/GGAa3r86EIW0wBm4ZtoAP5mwiK8udARARkYLmokXYGOMF3gF6APWA24wx9X5nv+LAo8Ci3A4pIiKXrkmlKCY/0p7OdcvyzynruGfkYhKPpbodS0TEddkZEb4S2Git3WytTQM+B/r+zn5/B/4NpORiPhERyQUlwoJ4745mvNC3PvM3HaDHG3OY+es+t2OJiLgqO0W4IrDjjOcJ/m2nGGOaAZWstZNzMZuIiOQiYwx3tq7KN0PbUapYCHd/spi/fbOalPRMt6OJiLjisq/hZ4zxAK8CT2Rj3/uMMfHGmPjExMTL/WgREbkEtcsV5+uhbRnYpiqf/LSV6975ifV7j7kdS0Qk32WnCO8EzlzwLda/7aTiQANgljFmK9AKmPR7J8xZaz+w1sZZa+NKly596alFROSyhAZ5+Wuf+nwysAWJx1Lp/dY8Ri/YilsrCYmIuCE7RXgxUMsYU80YEwzcCkw6+aK19oi1NsZaW9VaWxVYCPSx1mptNBGRAu6qOmWY+lh7WlUvxZ+/Xs29o+I5cFwn0olIYLhoEbbWZgBDgWnAWmC8tXa1MeYFY0yfvA4oIiJ5q0zxUD4Z2IK/9KrHnPX76f7GXOZu0PQ1ESn6dEENERE5Zc2uozz6+S9s2Hece9tX48lutQnxed2OJSJyWS7rghoiIhIY6lWIZNLQdtzRqjIfzt3C9e/MZ+O+427HEhHJEyrCIiJylrBgLy9e15AP74xj95ET9HprLmMXbdeJdCJS5KgIi4jI7+pSryzfPdaBuColefarlTzw6RIOJaW5HUtEJNeoCIuIyHmVjQxl1D1X8lzPuvy4bh893pjL/I373Y4lIpIrVIRFROSCPB7DvR2q89WDbQkP8dL/40X8a+o60jKy3I4mInJZVIRFRCRbGlQswbcPt+PWFpUZNnsTN743n82JOpFORAovFWEREcm28GAfL93QkGF3NGfHoWR6vTWP8Yt36EQ6ESmUVIRFRCTHujcox9RH29M4Noo/fLmCoWN/4UhyutuxRERyREVYREQuSfkSYXw6uCVPd6/DtNV76P7GHGav1xXpRKTwUBEWEZFL5vUYhnSqwcQH21AsxMddw3/m6QkrOJqi0WERKfhUhEVE5LI1io3i24fb8UDHGnyxZAfdXpvDrF/3uR1LROSCVIRFRCRXhAZ5eaZHHSY+2JZiIT4GfrKYP0xYzpETGh0WkYJJRVhERHJVk0rO6PCQTjWYsCSBbq/NYaZGh0WkAFIRFhGRXBca5OXp7nX46sG2FA/1cfcni3nqC40Oi0jBoiIsIiJ5pnGlKL59pB0PXVWDib/spOtrs5m2eo/bsUREABVhERHJYyE+L091q8NXD7YhOjyY+0cv4f7R8ew9muJ2NBEJcCrCIiKSLxrFRvHNw+14unsdZv2aSOdXZjN64TaysnRVOhFxh4qwiIjkmyCvhyGdajDtsQ40qlSCP/9vFTe/v4ANe4+5HU1EApCKsIiI5LuqMcX4dFBL/ntzYzYlHqfnm3N5dfp6UjMy3Y4mIgFERVhERFxhjOGm5rHMeLwj1zYsz5szNtDjjbks2nzA7WgiEiBUhEVExFWlIkJ4/damjLznStIysuj3wUL+OHGFlloTkTynIiwiIgVCxytK8/3/deDe9tUYt3gHnV+dzeQVu7FWJ9OJSN5QERYRkQIjPNjHc9fWY9LQdpQpHsJDY5cyeGQ82w8kux1NRIogFWERESlwGlQswdcPteW5nnVZsPkAnV+bzavT15OSrpPpRCT3qAiLiEiB5PN6uLdDdX58ohPd65fjzRkb6Pyqc2U6TZcQkdygIiwiIgVauRKhvHlbUz67txXhwV7uH72EgZ8sZnPicbejiUghpyIsIiKFQusapZj8SHv+3KseS7cdovvrc/nPd+tITstwO5qIFFIqwiIiUmgEeT0MaleNGU92pHfjCrw7axPXvKLVJUTk0qgIi4hIoVOmeCiv3NKYCQ+0Jjo8mIfGLuW2DxeyaucRt6OJSCGiIiwiIoVWXNWSfPNwO/5+XQPW7z1Or7fm8fi4Zew8fMLtaCJSCBi3/pQUFxdn4+PjXflsEREpeo6mpPPerE18PG8LBhjUrhpDOtWgeGiQ29FExGXGmCXW2rhzt2tEWEREioTI0CCe7l6HmU92omfD8rw7axOdXp7F6AVbSc/McjueiBRAKsIiIlKkVIwK47V+TfhmaDtqlongz1+vptvrc5i6UifUicjZVIRFRKRIahhbgs/va8VHd8bhMYYhY5bS5+2fmL0+UYVYRAAVYRERKcKMMXSuV5Zpj3Xgvzc35mBSGncN/5l+HywkfutBt+OJiMt0spyIiASM1IxMxi3ewZszNrL/eCpX1S7Nk91qU79CCbejiUgeOt/JcirCIiIScJLTMhg5fxvDZm/iyIl0rm1YnqFX16Ru+Ui3o4lIHlARFhEROceRE+l8OGczI+Zv5XhqBl3qleXhq2vSKDbK7WgikotUhEVERM7jcHIaI+ZvZfi8LRxNyaDjFaV5+OqaxFUt6XY0EckFKsIiIiIXcSwlndELt/HR3C0cTEqjVfWSPHJ1LVrXKIUxxu14InKJVIRFRESyKTktg7GLtvPBnM3sO5ZKs8pRPHRVTa6qXQaPR4VYpLBRERYREcmhlPRMvojfwbDZm9l5+ATVY4pxd9uq3Ng8lvBgn9vxRCSbVIRFREQuUXpmFlNW7mb4vC0sTzhCZKiP21pW5q7WVakQFeZ2PBG5CBVhERGRy2StZen2Q3w8bwvfrdqDMYYeDcpxT7tqNKsc7XY8ETmP8xVh/V1HREQkm4wxNK9SkuZVSpJwKJlRC7bx2c/b+XbFbppUimJQu2r0aFAOn1cXbhUpDDQiLCIichmOp2bw5ZIEPvlpC1sPJFOhRCh3tqnKbS0qUyI8yO14IoKmRoiIiOSprCzLj+v2MfynLczfdICwIC83NY9lYNuq1Cgd4XY8kYCmIiwiIpJP1uw6yvCftjBp2S7SMrO4uk4Z+resTMcrSmvahIgLVIRFRETyWeKxVMYs2sanC7ex/3gapYuHcEOzitzcvBI1y2iUWCS/qAiLiIi4JD0zix/X7eOL+ARm/rqPzCxL08pR3Ny8Ej0alCO6WLDbEUWKNBVhERGRAiDxWCr/+2Un4+N3sGHfcbweQ5sapejRoDxd65clJiLE7YgiRY6KsIiISAFirWX1rqNMWbmbKSt3s/VAMh4DLauVomfDcnSrX44ykaFuxxQpElSERURECihrLev2HGPqyt1MXrmbTYlJGAMtqpSkR8NydG9QjvIldAU7kUulIiwiIlJIbNh7jCkr9zB11W7W7TkGQLPKUfRsWJ7uDcoRGx3uckKRwuWyirAxpjvwBuAFPrLW/uuc1x8HBgMZQCJwj7V224XeU0VYRETk4jYlHue7VXuYsnI3q3cdBaBRbAl6NChPjwblqBpTzOWEIgXfJRdhY4wXWA90ARKAxcBt1to1Z+xzFbDIWptsjBkCdLLW9rvQ+6oIi4iI5My2A0lMXbWHqav2sHzHYQBqlong6jpluKp2GeKqRhOkdYpFfuNyinBr4K/W2m7+538EsNa+dJ79mwJvW2vbXuh9VYRFREQuXcKhZKat3svMdftYtOUA6ZmW4iE+2l8Rw1W1y9CpdhlKF9cKFCJw/iLsy8bPVgR2nPE8AWh5gf0HAVNzFk9ERERyIjY6nEHtqjGoXTWOp2bw08b9zPp1Hz+u28eUlXsAZwpFp9plaFOjFE0qRREa5HU5tUjBkp0inG3GmDuAOKDjeV6/D7gPoHLlyrn50SIiIgErIsRHt/rOkmvWWtbsPsqsXxP5cd0+3v5xA2/O2ECw10OTSlG0rF6S5lWiaVo5mhJhQW5HF3FVrk2NMMZ0Bt4COlpr913sgzU1QkREJO8dOZFO/NaDLNpykEWbD7By5xGyLBgDV5QpTrMq0cRViaZ5lWiqlArHGON2ZJFcdzlzhH04J8tdA+zEOVnudmvt6jP2aQpMALpbazdkJ5CKsIiISP47nprB8h2HWbLtEEu2HWLp9kMcS8kAICYimGaVnVIcVzWa+hVKaDqFFAmXPEfYWpthjBkKTMNZPm24tXa1MeYFIN5aOwl4GYgAvvD/l+R2a22fXP0NRERE5LJFhPhoWzOGtjVjAMjKsmzYd/xUMV6y7SDfr9kLQLDXQ70KkdSvEEmDiiWoXyGSK8oWVzmWIkMX1BAREZGz7D+eylJ/MV6ecJjVu46eGjX2eQw1y0RQv0IJGlSMpH6FEtSrEElESK6ediSSq3RlOREREbkk1lp2HDzB6l1HWLXrCKt2HmX1riPsP552ap+qpcKpWSaC6qUjqFG6GNVLR1C1VDFiIoI171hcdznLp4mIiEgAM8ZQuVQ4lUuF06NhecApx/uOpTrleOdR1u4+yubEJOas309aZtapnw0P9lK5ZPipW5VS4VQuVYzKJcOpGBVGsE8XABH3qAiLiIhIjhljKBsZStnIUK6uU/bU9swsy85DJ9i0/zjb9iex7WAyOw4ms2V/ErPXJ5KacbokewyUjQylQlSYcytxxuOoUCqUCCMqPEgjypJnVIRFREQk13g9p0ePqX32a1lZlsTjqWw7kMz2g8lsP5DEzsMp7Dp8gpUJh5m2KuWs0WSAsCAvpYuHEBMRTExECDHFQ4iJCKG0/3mpiBCiw4OICg+mRFiQRpglR1SERUREJF94PKdHka+sVvI3r2dlWQ4kpbHr8Al2HzlxqiQnHktlv79AL9l2iIPJaZzvFKeIEB8lwoKICg8iOjyYEuFBTlEOCybKX5ijw4MoFuKjWLCPsGAvxUK8hAf7CA/2EuRVkQ4kKsIiIiJSIHg8htLFQyhdPITGlaLOu19GZhYHk9PYfyyNA0mpHE5O5/CJdA4npXH4RDqHktM4kuzc7zpywnk9OY2sbKwPEOz1EB7iJTzIS3iIj2LBXsKCnaIc7PXg8xqCvB6CvAaf10OQx3nuO7nN4yHIZwjynLOvx0OQz9nf53+fYK8Hn//56ff+7b5B/vfxeQxej9FUkVykIiwiIiKFis/roUzxUMoUD832z2RlWY6lZpwqyElpGSSnZpKUlsGJtEyS0jJJTs0gKS2TE2nOfXJaBslpmSSnZrL3aArpmVlkZFrSs7JIz7BkZGWRnmnP2p4fi3GdLM0+jyHY58FjDB5jMAY8/pLs8YDB4DHOfG5jwMBv9zPmrH0xBv8dgP+xOeOxs+/JDScr+cntp37unOf43+fVWxoTExGSh0cnZ1SERUREpMjzeAwlwoIoERbkzF/OI5lZTjE+VY4zs0jPsmRk/rY0p2dkkZFlz7Ovs39GprNPmn+fjMws0s7ZnpVlsRayrMXi3HPWc2eVD2ezJSvLf29xtln7m31POvnQ4v/5c547j8FmgSXr1M9YTr+PPfN93Fm197xUhEVERERyiddj8Hq8uvpeIaEZ4SIiIiISkFSERURERCQgqQiLiIiISEBSERYRERGRgKQiLCIiIiIBSUVYRERERAKSirCIiIiIBCQVYREREREJSCrCIiIiIhKQVIRFREREJCCpCIuIiIhIQFIRFhEREZGApCIsIiIiIgFJRVhEREREApKKsIiIiIgEJBVhEREREQlIKsIiIiIiEpBUhEVEREQkIBlrrTsfbEwisM2VD4cYYL9Lnx0odIzzno5x3tMxzh86znlPxzjv6Rjnvcs5xlWstaXP3ehaEXaTMSbeWhvndo6iTMc47+kY5z0d4/yh45z3dIzzno5x3suLY6ypESIiIiISkFSERURERCQgBWoR/sDtAAFAxzjv6RjnPR3j/KHjnPd0jPOejnHey/VjHJBzhEVEREREAnVEWEREREQCXEAVYWNMd2PMr8aYjcaYZ9zOU1gZYyoZY2YaY9YYY1YbYx71by9pjJlujNngv4/2bzfGmDf9x32FMaaZu79B4WGM8RpjfjHGfOt/Xs0Ys8h/LMcZY4L920P8zzf6X6/qavBCxBgTZYyZYIxZZ4xZa4xpre9y7jLG/J//34pVxpjPjDGh+i5fHmPMcGPMPmPMqjO25fh7a4y5y7//BmPMXW78LgXZeY7zy/5/L1YYY74yxkSd8dof/cf5V2NMtzO2q3+cx+8d4zNee8IYY40xMf7nuf5dDpgibIzxAu8APYB6wG3GmHrupiq0MoAnrLX1gFbAQ/5j+Qwww1pbC5jhfw7OMa/lv90HvJf/kQutR4G1Zzz/N/CatbYmcAgY5N8+CDjk3/6afz/JnjeA76y1dYDGOMdb3+VcYoypCDwCxFlrGwBe4Fb0Xb5cI4Du52zL0ffWGFMSeB5oCVwJPH+yPMspI/jtcZ4ONLDWNgLWA38E8P//4K1Aff/PvOsfzFD/uLAR/PYYY4ypBHQFtp+xOde/ywFThHEOzEZr7WZrbRrwOdDX5UyFkrV2t7V2qf/xMZziUBHneI707zYSuM7/uC8wyjoWAlHGmPL5m7rwMcbEAtcCH/mfG+BqYIJ/l3OP8cljPwG4xr+/XIAxpgTQAfgYwFqbZq09jL7Luc0HhBljfEA4sBt9ly+LtXYOcPCczTn93nYDpltrD1prD+EUvN8UkkD2e8fZWvu9tTbD/3QhEOt/3Bf43Fqbaq3dAmzE6R7qHxdwnu8yOP8h/AfgzJPZcv27HEhFuCKw44znCf5tchn8f7ZsCiwCylprd/tf2gOU9T/Wsb80r+P8I5Dlf14KOHzGP8BnHsdTx9j/+hH//nJh1YBE4BPjTEH5yBhTDH2Xc421difwX5xRnd04380l6LucF3L6vdX3+fLdA0z1P9ZxziXGmL7ATmvt8nNeyvVjHEhFWHKZMSYC+BJ4zFp79MzXrLMciZYkuUTGmF7APmvtErezFHE+oBnwnrW2KZDE6T8nA/ouXy7/nyf74vxHRwWgGBp1zHP63uY9Y8xzOFMFx7idpSgxxoQDzwJ/yY/PC6QivBOodMbzWP82uQTGmCCcEjzGWjvRv3nvyT8T++/3+bfr2OdcW6CPMWYrzp/RrsaZyxrl//MynH0cTx1j/+slgAP5GbiQSgASrLWL/M8n4BRjfZdzT2dgi7U20VqbDkzE+X7ru5z7cvq91ff5EhljBgK9gP729Dq0Os65owbOfzgv9/9/YCyw1BhTjjw4xoFUhBcDtfxnKgfjTGif5HKmQsk/X+9jYK219tUzXpoEnDxT8y7g6zO23+k/27MVcOSMP9/J77DW/tFaG2utrYrzXf3RWtsfmAnc5N/t3GN88tjf5N9fo0EXYa3dA+wwxtT2b7oGWIO+y7lpO9DKGBPu/7fj5DHWdzn35fR7Ow3oaoyJ9o/cd/VvkwswxnTHmbbWx1qbfMZLk4BbjbPySTWcE7p+Rv0jR6y1K621Zay1Vf3/H5gANPP/e53732VrbcDcgJ44Z3huAp5zO09hvQHtcP7ktgJY5r/1xJnHNwPYAPwAlPTvb3DOmN0ErMQ5e9z136Ow3IBOwLf+x9Vx/mHdCHwBhPi3h/qfb/S/Xt3t3IXlBjQB4v3f5/8B0fou5/ox/huwDlgFjAZC9F2+7GP6Gc6c63R/URh0Kd9bnDmuG/23u93+vQra7TzHeSPOfNST//837Iz9n/Mf51+BHmdsV//IwTE+5/WtQIz/ca5/l3VlOREREREJSIE0NUJERERE5BQVYREREREJSCrCIiIiIhKQVIRFREREJCCpCIuIiIhIQFIRFhEREZGApCIsIiIiIgFJRVhEREREAtL/A9Km7VH2UOAPAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.plot(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 345605.3125\n",
      "MSE: 372212777965.97784\n",
      "RMSE: 610092.4339524118\n",
      "VarScore: 2.220446049250313e-16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x217930cd370>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "teste = pd.DataFrame(y_Test)\n",
    "teste['previsão_KeNN'] = model.predict(X_Test)\n",
    "y_pred = model.predict(X_Test)\n",
    "from sklearn import metrics\n",
    "print('MAE:', metrics.mean_absolute_error(y_Test.iloc[:,0], y_pred ))  \n",
    "print('MSE:', metrics.mean_squared_error(y_Test.iloc[:,0], y_pred))  \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_Test.iloc[:,0], y_pred)))\n",
    "print('VarScore:',metrics.explained_variance_score(y_Test.iloc[:,0],y_pred))\n",
    "# Visualizing Our predictions\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.scatter(y_Test.iloc[:,0],y_pred)\n",
    "# Perfect predictions\n",
    "plt.plot(y_Test.iloc[:,0],y_Test.iloc[:,0],'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faturamento</th>\n",
       "      <th>previsão_LR</th>\n",
       "      <th>previsão_NN</th>\n",
       "      <th>previsão_KeNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>832018.0</td>\n",
       "      <td>8.310170e+05</td>\n",
       "      <td>806674.0</td>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>808082.0</td>\n",
       "      <td>8.489861e+05</td>\n",
       "      <td>856901.0</td>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2157079.0</td>\n",
       "      <td>2.666615e+06</td>\n",
       "      <td>2384494.0</td>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>641865.0</td>\n",
       "      <td>7.579680e+05</td>\n",
       "      <td>736698.0</td>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>978197.0</td>\n",
       "      <td>9.372361e+05</td>\n",
       "      <td>1041359.0</td>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>488021.0</td>\n",
       "      <td>5.709785e+05</td>\n",
       "      <td>720444.0</td>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>744303.0</td>\n",
       "      <td>8.107426e+05</td>\n",
       "      <td>795430.0</td>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>796321.0</td>\n",
       "      <td>8.301544e+05</td>\n",
       "      <td>798206.0</td>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>630075.0</td>\n",
       "      <td>7.003768e+05</td>\n",
       "      <td>711591.0</td>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1200769.0</td>\n",
       "      <td>1.120245e+06</td>\n",
       "      <td>1073403.0</td>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>635348.0</td>\n",
       "      <td>5.966175e+05</td>\n",
       "      <td>711591.0</td>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>932622.0</td>\n",
       "      <td>8.481998e+05</td>\n",
       "      <td>778067.0</td>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2211985.0</td>\n",
       "      <td>2.270449e+06</td>\n",
       "      <td>1596252.0</td>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>688001.0</td>\n",
       "      <td>6.308364e+05</td>\n",
       "      <td>536367.0</td>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>796395.0</td>\n",
       "      <td>8.208047e+05</td>\n",
       "      <td>858291.0</td>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>837355.0</td>\n",
       "      <td>8.582479e+05</td>\n",
       "      <td>818442.0</td>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>703465.0</td>\n",
       "      <td>8.112232e+05</td>\n",
       "      <td>932007.0</td>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>560631.0</td>\n",
       "      <td>7.219548e+05</td>\n",
       "      <td>711591.0</td>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>629794.0</td>\n",
       "      <td>7.275233e+05</td>\n",
       "      <td>726430.0</td>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>755073.0</td>\n",
       "      <td>7.498245e+05</td>\n",
       "      <td>908998.0</td>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1491476.0</td>\n",
       "      <td>1.407192e+06</td>\n",
       "      <td>1430429.0</td>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>852714.0</td>\n",
       "      <td>8.542552e+05</td>\n",
       "      <td>808554.0</td>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>662520.0</td>\n",
       "      <td>7.029213e+05</td>\n",
       "      <td>738591.0</td>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2915612.0</td>\n",
       "      <td>4.192409e+06</td>\n",
       "      <td>1596252.0</td>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     faturamento   previsão_LR  previsão_NN  previsão_KeNN\n",
       "105     832018.0  8.310170e+05     806674.0    845417.5625\n",
       "108     808082.0  8.489861e+05     856901.0    845417.5625\n",
       "141    2157079.0  2.666615e+06    2384494.0    845417.5625\n",
       "55      641865.0  7.579680e+05     736698.0    845417.5625\n",
       "94      978197.0  9.372361e+05    1041359.0    845417.5625\n",
       "29      488021.0  5.709785e+05     720444.0    845417.5625\n",
       "101     744303.0  8.107426e+05     795430.0    845417.5625\n",
       "51      796321.0  8.301544e+05     798206.0    845417.5625\n",
       "100     630075.0  7.003768e+05     711591.0    845417.5625\n",
       "142    1200769.0  1.120245e+06    1073403.0    845417.5625\n",
       "19      635348.0  5.966175e+05     711591.0    845417.5625\n",
       "84      932622.0  8.481998e+05     778067.0    845417.5625\n",
       "15     2211985.0  2.270449e+06    1596252.0    845417.5625\n",
       "66      688001.0  6.308364e+05     536367.0    845417.5625\n",
       "24      796395.0  8.208047e+05     858291.0    845417.5625\n",
       "30      837355.0  8.582479e+05     818442.0    845417.5625\n",
       "128     703465.0  8.112232e+05     932007.0    845417.5625\n",
       "147     560631.0  7.219548e+05     711591.0    845417.5625\n",
       "98      629794.0  7.275233e+05     726430.0    845417.5625\n",
       "16      755073.0  7.498245e+05     908998.0    845417.5625\n",
       "75     1491476.0  1.407192e+06    1430429.0    845417.5625\n",
       "18      852714.0  8.542552e+05     808554.0    845417.5625\n",
       "12      662520.0  7.029213e+05     738591.0    845417.5625\n",
       "9      2915612.0  4.192409e+06    1596252.0    845417.5625"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Modelos/KeNN0.0\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(f'Modelos/KeNN{np.round(metrics.explained_variance_score(y_Test.iloc[:,0],y_pred),3)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicar o modelo aos dados de SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 18)                342       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 36)                684       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 72)                2664      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 36)                2628      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 18)                666       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 18)                342       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 19        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,345\n",
      "Trainable params: 7,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "new_model = tf.keras.models.load_model(f'Modelos/KeNN{np.round(metrics.explained_variance_score(y_Test.iloc[:,0],y_pred),3)}')\n",
    "new_model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_SP = Abre_DB(f'{out}/Teste','Base_SP.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>845417.5625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>296 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "0    845417.5625\n",
       "1    845417.5625\n",
       "2    845417.5625\n",
       "3    845417.5625\n",
       "4    845417.5625\n",
       "..           ...\n",
       "291  845417.5625\n",
       "292  845417.5625\n",
       "293  845417.5625\n",
       "294  845417.5625\n",
       "295  845417.5625\n",
       "\n",
       "[296 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faturamento = pd.DataFrame(new_model.predict(Base_SP))\n",
    "faturamento"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ffa7516ed6f29c8ec66f5fe36abdbb00b5a0b396b200a29e7dab09afceb1c3a9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
